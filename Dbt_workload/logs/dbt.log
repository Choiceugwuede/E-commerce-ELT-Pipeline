[0m00:04:20.239530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025327BD0830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002532588D1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025328C37D90>]}


============================== 00:04:20.277217 | b3ba6ec8-e8c3-4b06-bed2-064c1aea33ab ==============================
[0m00:04:20.277217 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:04:20.280610 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt init', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'None', 'log_cache_events': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\Bluechip\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m00:04:20.477432 [info ] [MainThread]: Creating dbt configuration folder at C:\Users\Bluechip\.dbt
[0m00:05:59.348277 [debug] [MainThread]: Starter project path: C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\include\starter_project
[0m00:05:59.739436 [info ] [MainThread]: 
Your new dbt project "dbt_household_stats" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m00:05:59.757923 [info ] [MainThread]: Setting up your profile.
[0m00:19:12.579423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2D39B0830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2D16791D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2D49FFD90>]}


============================== 00:19:12.605840 | 41b1e9b0-9cc2-4a7b-8baa-e4d4617aefc3 ==============================
[0m00:19:12.605840 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:19:12.615570 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt init', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'None', 'printer_width': '80', 'log_path': 'logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\Bluechip\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m00:19:41.405414 [debug] [MainThread]: Starter project path: C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\include\starter_project
[0m00:19:41.486599 [info ] [MainThread]: 
Your new dbt project "dbt_transform" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m00:19:41.491766 [info ] [MainThread]: Setting up your profile.
[0m00:27:10.433884 [error] [MainThread]: Encountered an error:

[0m00:27:10.498043 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\cli\requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\cli\requires.py", line 128, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\cli\main.py", line 483, in init
    results = task.run()
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\task\init.py", line 346, in run
    self.setup_profile(profile_name)
    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\task\init.py", line 262, in setup_profile
    self.create_profile_from_target(adapter, profile_name=profile_name)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\task\init.py", line 179, in create_profile_from_target
    self.create_profile_from_profile_template(profile_template, profile_name)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\task\init.py", line 163, in create_profile_from_profile_template
    target = self.generate_target_from_input(prompts, initial_target)
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\task\init.py", line 129, in generate_target_from_input
    target[key] = click.prompt(
                  ~~~~~~~~~~~~^
        text, default=default, hide_input=hide_input, type=type
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\click\termui.py", line 168, in prompt
    value = prompt_func(prompt)
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\click\termui.py", line 151, in prompt_func
    raise Abort() from None
click.exceptions.Abort

[0m00:27:10.527147 [debug] [MainThread]: Command `dbt init` failed at 00:27:10.518798 after 481.71 seconds
[0m00:27:10.530189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2D4A7BA80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2D4A8ED50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2D5C40160>]}
[0m00:27:10.532686 [debug] [MainThread]: Flushing usage events
[0m00:27:14.218443 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:29:48.962694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CD5560830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CD32191D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CD65AFC50>]}


============================== 00:29:48.994026 | c677a625-c253-4ee3-a72e-20c6cc43891d ==============================
[0m00:29:48.994026 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:29:48.997787 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt init', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\Bluechip\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m00:30:00.755086 [debug] [MainThread]: Starter project path: C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\include\starter_project
[0m00:30:00.831064 [info ] [MainThread]: 
Your new dbt project "dbt_transform" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m00:30:00.839016 [info ] [MainThread]: Setting up your profile.
[0m00:31:36.359246 [info ] [MainThread]: Profile dbt_transform written to C:\Users\Bluechip\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m00:31:36.384535 [debug] [MainThread]: Command `dbt init` succeeded at 00:31:36.363652 after 109.03 seconds
[0m00:31:36.387034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CD662B950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CD663EE70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CD6451F20>]}
[0m00:31:36.389381 [debug] [MainThread]: Flushing usage events
[0m00:31:39.804338 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:32:22.177391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE165C4830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE142791D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE1760FD90>]}


============================== 00:32:22.199927 | 6f5b687b-06bd-4814-9e80-1b73b80784b8 ==============================
[0m00:32:22.199927 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:32:22.230411 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt debug', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'printer_width': '80', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_path': 'logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\Bluechip\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m00:32:22.685506 [info ] [MainThread]: dbt version: 1.10.13
[0m00:32:22.690458 [info ] [MainThread]: python version: 3.13.4
[0m00:32:22.704080 [info ] [MainThread]: python path: C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Scripts\python.exe
[0m00:32:22.708246 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m00:32:23.533975 [info ] [MainThread]: Using profiles dir at C:\Users\Bluechip\.dbt
[0m00:32:23.536797 [info ] [MainThread]: Using profiles.yml file at C:\Users\Bluechip\.dbt\profiles.yml
[0m00:32:23.551264 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_project.yml
[0m00:32:23.603935 [info ] [MainThread]: adapter type: postgres
[0m00:32:23.637684 [info ] [MainThread]: adapter version: 1.9.1
[0m00:32:23.650813 [info ] [MainThread]: Configuration:
[0m00:32:23.671271 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m00:32:23.707816 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m00:32:23.721710 [info ] [MainThread]: Required dependencies:
[0m00:32:23.739272 [debug] [MainThread]: Executing "git --help"
[0m00:32:24.092535 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m00:32:24.101110 [debug] [MainThread]: STDERR: "b''"
[0m00:32:24.103813 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m00:32:24.108338 [info ] [MainThread]: Connection:
[0m00:32:24.116677 [info ] [MainThread]:   host: postgres
[0m00:32:24.168128 [info ] [MainThread]:   port: 1
[0m00:32:24.187165 [info ] [MainThread]:   user: postgres
[0m00:32:24.215714 [info ] [MainThread]:   database: staging
[0m00:32:24.311833 [info ] [MainThread]:   schema: household
[0m00:32:24.341825 [info ] [MainThread]:   connect_timeout: 10
[0m00:32:24.389590 [info ] [MainThread]:   role: None
[0m00:32:24.430043 [info ] [MainThread]:   search_path: None
[0m00:32:24.475886 [info ] [MainThread]:   keepalives_idle: 0
[0m00:32:24.551370 [info ] [MainThread]:   sslmode: None
[0m00:32:24.634355 [info ] [MainThread]:   sslcert: None
[0m00:32:24.651872 [info ] [MainThread]:   sslkey: None
[0m00:32:24.667934 [info ] [MainThread]:   sslrootcert: None
[0m00:32:24.676751 [info ] [MainThread]:   application_name: dbt
[0m00:32:24.706242 [info ] [MainThread]:   retries: 1
[0m00:32:24.722253 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m00:32:29.252574 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m00:33:05.865977 [debug] [MainThread]: Using postgres connection "debug"
[0m00:33:05.868202 [debug] [MainThread]: On debug: select 1 as id
[0m00:33:05.870148 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:33:09.706012 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "postgres" to address: Name or service not known

[0m00:33:12.439095 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m00:33:12.445957 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m00:33:12.449806 [debug] [MainThread]: On debug: No close available on handle
[0m00:33:12.451887 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m00:33:12.454914 [info ] [MainThread]: [31m2 checks failed:[0m
[0m00:33:12.456949 [info ] [MainThread]: Project loading failed for the following reason:
 project path <C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_project.yml> not found

[0m00:33:12.465588 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  could not translate host name "postgres" to address: Name or service not known
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m00:33:12.470731 [debug] [MainThread]: Command `dbt debug` failed at 00:33:12.469293 after 52.06 seconds
[0m00:33:12.473603 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m00:33:12.504609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE17801E00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE17819C70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE17754AF0>]}
[0m00:33:12.517898 [debug] [MainThread]: Flushing usage events
[0m00:33:17.628239 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:54:10.364926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C48B0830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C25791D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C58FFD90>]}


============================== 09:54:10.374795 | e1d6cf00-38da-40d9-bd35-537433188738 ==============================
[0m09:54:10.374795 [info ] [MainThread]: Running with dbt=1.10.13
[0m09:54:10.377489 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt init', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\Bluechip\\.dbt'}
[0m09:54:20.934672 [debug] [MainThread]: Starter project path: C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\include\starter_project
[0m09:54:21.007809 [info ] [MainThread]: 
Your new dbt project "dbt_transform" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m09:54:21.013472 [info ] [MainThread]: Setting up your profile.
[0m09:55:29.126323 [info ] [MainThread]: Profile dbt_transform written to C:\Users\Bluechip\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m09:55:29.129806 [debug] [MainThread]: Command `dbt init` succeeded at 09:55:29.129474 after 79.23 seconds
[0m09:55:29.131723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C597F950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C598AD50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C57A1F20>]}
[0m09:55:29.135401 [debug] [MainThread]: Flushing usage events
[0m09:55:31.650698 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:09:26.476305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002851C570830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002851A2391D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002851D5BFD90>]}


============================== 11:09:26.490963 | 69f283c7-bbdd-42f4-b7ef-50424675e70b ==============================
[0m11:09:26.490963 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:09:26.493229 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt init', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'printer_width': '80', 'empty': 'None', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\Bluechip\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m11:09:53.718166 [debug] [MainThread]: Starter project path: C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\include\starter_project
[0m11:09:53.760326 [info ] [MainThread]: 
Your new dbt project "dbt_transform" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m11:09:53.762012 [info ] [MainThread]: Setting up your profile.
[0m11:10:30.598327 [error] [MainThread]: Encountered an error:

[0m11:10:30.607692 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\cli\requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\cli\requires.py", line 128, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\cli\main.py", line 483, in init
    results = task.run()
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\task\init.py", line 346, in run
    self.setup_profile(profile_name)
    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\task\init.py", line 262, in setup_profile
    self.create_profile_from_target(adapter, profile_name=profile_name)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\task\init.py", line 179, in create_profile_from_target
    self.create_profile_from_profile_template(profile_template, profile_name)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\task\init.py", line 163, in create_profile_from_profile_template
    target = self.generate_target_from_input(prompts, initial_target)
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\task\init.py", line 129, in generate_target_from_input
    target[key] = click.prompt(
                  ~~~~~~~~~~~~^
        text, default=default, hide_input=hide_input, type=type
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\click\termui.py", line 168, in prompt
    value = prompt_func(prompt)
  File "C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\click\termui.py", line 151, in prompt_func
    raise Abort() from None
click.exceptions.Abort

[0m11:10:30.633649 [debug] [MainThread]: Command `dbt init` failed at 11:10:30.633330 after 65.11 seconds
[0m11:10:30.634841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002851D63FA80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002851D64B0B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002851D710160>]}
[0m11:10:30.639009 [debug] [MainThread]: Flushing usage events
[0m11:10:43.199367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BAF7B0830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BAD4791D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BB07FFD90>]}


============================== 11:10:43.217914 | 188a5b8f-1c3b-43b8-a9be-34c0e82caf4e ==============================
[0m11:10:43.217914 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:10:43.237001 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt init', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'printer_width': '80', 'log_path': 'logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\Bluechip\\.dbt'}
[0m11:10:54.181107 [debug] [MainThread]: Starter project path: C:\Users\Bluechip\CDE\ETL_PIPELINE\Dbt_workload\dbt_venv\Lib\site-packages\dbt\include\starter_project
[0m11:10:54.224752 [info ] [MainThread]: 
Your new dbt project "dbt_transform" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m11:10:54.226984 [info ] [MainThread]: Setting up your profile.
[0m11:11:23.867793 [info ] [MainThread]: Profile dbt_transform written to C:\Users\Bluechip\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m11:11:23.878474 [debug] [MainThread]: Command `dbt init` succeeded at 11:11:23.877291 after 42.18 seconds
[0m11:11:23.879756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BB087F950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BB088ED50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BB06A1F20>]}
[0m11:11:23.881090 [debug] [MainThread]: Flushing usage events
[0m11:11:26.991091 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:48:15.582027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f591497a830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5913909450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f591390bfd0>]}


============================== 14:48:15.659279 | 0499b688-0356-4158-a18a-81687b2617c8 ==============================
[0m14:48:15.659279 [info ] [MainThread]: Running with dbt=1.10.13
[0m14:48:15.711923 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'quiet': 'False', 'fail_fast': 'False', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run', 'use_colors': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'debug': 'False', 'introspect': 'True', 'empty': 'False', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False', 'target_path': 'None', 'log_path': 'logs', 'version_check': 'True', 'no_print': 'None', 'write_json': 'True', 'partial_parse': 'True', 'profiles_dir': '/dbt'}
[0m14:48:15.730949 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path /dbt/dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m14:48:15.769907 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.32331637, "process_in_blocks": "1984", "process_kernel_time": 2.639603, "process_mem_max_rss": "98112", "process_out_blocks": "1416", "process_user_time": 8.107354}
[0m14:48:15.779217 [debug] [MainThread]: Command `dbt run` failed at 14:48:15.778532 after 0.33 seconds
[0m14:48:15.781888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f591497a830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59136db820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59136db880>]}
[0m14:48:15.793050 [debug] [MainThread]: Flushing usage events
[0m14:48:17.514518 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:55:54.870511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea054c2830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea04709450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea0470bfa0>]}


============================== 14:55:54.887314 | e71ce210-1b61-41c1-9ac6-663edac445d6 ==============================
[0m14:55:54.887314 [info ] [MainThread]: Running with dbt=1.10.13
[0m14:55:54.898148 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'log_path': 'logs', 'invocation_command': 'dbt run', 'warn_error': 'None', 'cache_selected_only': 'False', 'profiles_dir': '/dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'empty': 'False', 'static_parser': 'True', 'target_path': 'None', 'partial_parse': 'True', 'fail_fast': 'False', 'printer_width': '80', 'log_format': 'default', 'introspect': 'True', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'version_check': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'debug': 'False'}
[0m14:55:54.901908 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path /dbt/dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m14:55:54.914825 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.06863509, "process_in_blocks": "0", "process_kernel_time": 0.988042, "process_mem_max_rss": "98144", "process_out_blocks": "1416", "process_user_time": 6.057999}
[0m14:55:54.931084 [debug] [MainThread]: Command `dbt run` failed at 14:55:54.930644 after 0.09 seconds
[0m14:55:54.936019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea054c2830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea044d3820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea044d3880>]}
[0m14:55:54.939508 [debug] [MainThread]: Flushing usage events
[0m14:55:57.022484 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:07:30.427526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7647d5a860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7646d7b640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7646d7b5e0>]}


============================== 15:07:30.452485 | f14ded58-5f2c-41e5-ba41-f39388961053 ==============================
[0m15:07:30.452485 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:07:30.464985 [debug] [MainThread]: running dbt with arguments {'log_path': '/dbt/logs', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'quiet': 'False', 'indirect_selection': 'eager', 'no_print': 'None', 'version_check': 'True', 'static_parser': 'True', 'warn_error': 'None', 'introspect': 'True', 'invocation_command': 'dbt run', 'use_colors': 'True', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'debug': 'False', 'log_format': 'default', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'profiles_dir': '/dbt', 'target_path': 'None', 'fail_fast': 'False', 'printer_width': '80'}
[0m15:07:31.595406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f14ded58-5f2c-41e5-ba41-f39388961053', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7646d7b5e0>]}
[0m15:07:32.015121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f14ded58-5f2c-41e5-ba41-f39388961053', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f764762e380>]}
[0m15:07:32.017737 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m15:07:32.545602 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:07:32.553259 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m15:07:32.555711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f14ded58-5f2c-41e5-ba41-f39388961053', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7645f7d960>]}
[0m15:07:37.618364 [error] [MainThread]: Encountered an error:
Compilation Error in model sales_summary (models/sales_summary.sql)
  expected token ',', got ':'
    line 1
      {{ config(materialized: 'table')}}
[0m15:07:37.622832 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.5050564, "process_in_blocks": "176", "process_kernel_time": 1.119256, "process_mem_max_rss": "109772", "process_out_blocks": "1432", "process_user_time": 11.103415}
[0m15:07:37.638056 [debug] [MainThread]: Command `dbt run` failed at 15:07:37.637199 after 7.52 seconds
[0m15:07:37.642428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7647d5a860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7644f36410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7644f356f0>]}
[0m15:07:37.690058 [debug] [MainThread]: Flushing usage events
[0m15:07:39.034874 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:14:17.404133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3f2267a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3e26b4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3e26b460>]}


============================== 15:14:17.548656 | a3a58cd8-0120-4dc7-83ba-da6ac81a7b40 ==============================
[0m15:14:17.548656 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:14:17.581856 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'invocation_command': 'dbt run', 'static_parser': 'True', 'write_json': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'partial_parse': 'True', 'quiet': 'False', 'log_format': 'default', 'empty': 'False', 'fail_fast': 'False', 'version_check': 'True', 'printer_width': '80', 'use_colors': 'True', 'debug': 'False', 'log_cache_events': 'False', 'log_path': '/dbt/logs', 'profiles_dir': '/dbt', 'no_print': 'None'}
[0m15:14:19.516519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3a58cd8-0120-4dc7-83ba-da6ac81a7b40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3eac3df0>]}
[0m15:14:20.075281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a3a58cd8-0120-4dc7-83ba-da6ac81a7b40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3ea97970>]}
[0m15:14:20.095251 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m15:14:20.981677 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:14:21.016633 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m15:14:21.034305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a3a58cd8-0120-4dc7-83ba-da6ac81a7b40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3d799810>]}
[0m15:14:42.518719 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m15:14:42.783229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3a58cd8-0120-4dc7-83ba-da6ac81a7b40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3b3d19f0>]}
[0m15:14:45.024942 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m15:14:45.086926 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m15:14:45.295951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a3a58cd8-0120-4dc7-83ba-da6ac81a7b40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3d7099f0>]}
[0m15:14:45.302330 [info ] [MainThread]: Found 2 models, 5 data tests, 1 source, 447 macros
[0m15:14:45.315133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3a58cd8-0120-4dc7-83ba-da6ac81a7b40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3db4f910>]}
[0m15:14:45.350548 [info ] [MainThread]: 
[0m15:14:45.367911 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:14:45.383165 [info ] [MainThread]: 
[0m15:14:45.456251 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:14:45.599229 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m15:14:46.334205 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m15:14:46.337699 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m15:14:46.349877 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:14:46.447275 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.097 seconds
[0m15:14:46.454132 [debug] [ThreadPool]: On list_staging: Close
[0m15:14:46.469599 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m15:14:46.519544 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m15:14:46.525507 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m15:14:46.530115 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:14:46.569220 [debug] [ThreadPool]: SQL status: BEGIN in 0.037 seconds
[0m15:14:46.578016 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m15:14:46.581403 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m15:14:46.617282 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.032 seconds
[0m15:14:46.627812 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m15:14:46.633524 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m15:14:46.696744 [debug] [MainThread]: Using postgres connection "master"
[0m15:14:46.700004 [debug] [MainThread]: On master: BEGIN
[0m15:14:46.703052 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:14:46.744854 [debug] [MainThread]: SQL status: BEGIN in 0.042 seconds
[0m15:14:46.748569 [debug] [MainThread]: Using postgres connection "master"
[0m15:14:46.759191 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m15:14:46.825630 [debug] [MainThread]: SQL status: SELECT 0 in 0.062 seconds
[0m15:14:46.844201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3a58cd8-0120-4dc7-83ba-da6ac81a7b40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3e4b77f0>]}
[0m15:14:46.858573 [debug] [MainThread]: On master: ROLLBACK
[0m15:14:46.868781 [debug] [MainThread]: Using postgres connection "master"
[0m15:14:46.875293 [debug] [MainThread]: On master: BEGIN
[0m15:14:46.880528 [debug] [MainThread]: SQL status: BEGIN in 0.002 seconds
[0m15:14:46.901792 [debug] [MainThread]: On master: COMMIT
[0m15:14:46.930465 [debug] [MainThread]: Using postgres connection "master"
[0m15:14:46.950512 [debug] [MainThread]: On master: COMMIT
[0m15:14:46.966140 [debug] [MainThread]: SQL status: COMMIT in 0.012 seconds
[0m15:14:46.994840 [debug] [MainThread]: On master: Close
[0m15:14:47.083591 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m15:14:47.098850 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m15:14:47.115085 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m15:14:47.131746 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m15:14:47.226040 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m15:14:47.433819 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m15:14:47.887290 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m15:14:48.188727 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m15:14:48.200713 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m15:14:48.206495 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:14:48.362602 [debug] [Thread-1 (]: SQL status: BEGIN in 0.158 seconds
[0m15:14:48.424851 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m15:14:48.491965 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."staging"."bankole_store"
),

select
InvoiceNo as invoie_no,
trim(StockCode) as stock_code,
upper(Description) as description,
cast(Quantity as int) as quantity,
cast(to_timestamp(InvoiceDate, 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp(InvoiceDate, 'MM/DD/YYYY HH24:MI') 'HH24:MI') as invoice_time
UnitPrice as unit_price,
CustomerID AS customer_id,
Upper(Country) as Country
from source
  );
[0m15:14:48.513412 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "select"
LINE 14: select
         ^

[0m15:14:48.583457 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: ROLLBACK
[0m15:14:48.639147 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m15:14:48.761953 [debug] [Thread-1 (]: Database Error in model stg_sales (models/stg_sales.sql)
  syntax error at or near "select"
  LINE 14: select
           ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m15:14:48.888985 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3a58cd8-0120-4dc7-83ba-da6ac81a7b40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3cb218d0>]}
[0m15:14:48.938992 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model bankole_store.stg_sales ................... [[31mERROR[0m in 1.75s]
[0m15:14:48.986969 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m15:14:49.034382 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.stg_sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_sales (models/stg_sales.sql)
  syntax error at or near "select"
  LINE 14: select
           ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql.
[0m15:14:49.128556 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m15:14:49.176790 [info ] [Thread-1 (]: 2 of 2 SKIP relation bankole_store.sales_summary ............................... [[33mSKIP[0m]
[0m15:14:49.225006 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m15:14:49.289527 [debug] [MainThread]: Using postgres connection "master"
[0m15:14:49.305722 [debug] [MainThread]: On master: BEGIN
[0m15:14:49.332477 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:14:49.512654 [debug] [MainThread]: SQL status: BEGIN in 0.190 seconds
[0m15:14:49.624664 [debug] [MainThread]: On master: COMMIT
[0m15:14:49.688838 [debug] [MainThread]: Using postgres connection "master"
[0m15:14:49.704506 [debug] [MainThread]: On master: COMMIT
[0m15:14:49.717399 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m15:14:49.723977 [debug] [MainThread]: On master: Close
[0m15:14:49.753153 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:14:49.766704 [debug] [MainThread]: Connection 'model.dbt_transform.stg_sales' was properly closed.
[0m15:14:49.792720 [info ] [MainThread]: 
[0m15:14:49.815607 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.34 seconds (4.34s).
[0m15:14:49.842769 [debug] [MainThread]: Command end result
[0m15:14:50.582465 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m15:14:50.635212 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m15:14:50.722514 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m15:14:50.737675 [info ] [MainThread]: 
[0m15:14:50.751773 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:14:50.756085 [info ] [MainThread]: 
[0m15:14:50.786835 [error] [MainThread]: [31mFailure in model stg_sales (models/stg_sales.sql)[0m
[0m15:14:50.823817 [error] [MainThread]:   Database Error in model stg_sales (models/stg_sales.sql)
  syntax error at or near "select"
  LINE 14: select
           ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m15:14:50.836170 [info ] [MainThread]: 
[0m15:14:50.856951 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/stg_sales.sql
[0m15:14:50.887107 [info ] [MainThread]: 
[0m15:14:50.968605 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m15:14:51.066605 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 34.656754, "process_in_blocks": "96", "process_kernel_time": 4.813376, "process_mem_max_rss": "126884", "process_out_blocks": "1504", "process_user_time": 33.389637}
[0m15:14:51.113892 [debug] [MainThread]: Command `dbt run` failed at 15:14:51.113117 after 34.70 seconds
[0m15:14:51.159869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3f2267a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3f17b340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d3d708400>]}
[0m15:14:51.207998 [debug] [MainThread]: Flushing usage events
[0m15:14:53.517680 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:34:37.114752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57384c27d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57374df490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57374df430>]}


============================== 22:34:37.131491 | 24985f6f-0a79-48b3-bd11-5b051844d543 ==============================
[0m22:34:37.131491 [info ] [MainThread]: Running with dbt=1.10.13
[0m22:34:37.134586 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'indirect_selection': 'eager', 'quiet': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'version_check': 'True', 'no_print': 'None', 'introspect': 'True', 'static_parser': 'True', 'profiles_dir': '/dbt', 'log_path': '/dbt/logs', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'printer_width': '80', 'empty': 'False', 'invocation_command': 'dbt run', 'cache_selected_only': 'False', 'debug': 'False'}
[0m22:34:37.764489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '24985f6f-0a79-48b3-bd11-5b051844d543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57382e7430>]}
[0m22:34:38.045077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '24985f6f-0a79-48b3-bd11-5b051844d543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5737d13dc0>]}
[0m22:34:38.048232 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m22:34:38.374095 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m22:34:39.008360 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m22:34:39.010886 [debug] [MainThread]: Partial parsing: updated file: dbt_transform://models/stg_sales.sql
[0m22:34:39.012930 [debug] [MainThread]: Partial parsing: updated file: dbt_transform://models/sales_summary.sql
[0m22:34:41.088158 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m22:34:41.199829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '24985f6f-0a79-48b3-bd11-5b051844d543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57357e8400>]}
[0m22:34:41.711184 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:34:41.746660 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:34:41.920697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '24985f6f-0a79-48b3-bd11-5b051844d543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5734799240>]}
[0m22:34:41.930451 [info ] [MainThread]: Found 2 models, 5 data tests, 1 source, 447 macros
[0m22:34:41.933942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24985f6f-0a79-48b3-bd11-5b051844d543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5734799180>]}
[0m22:34:41.985493 [info ] [MainThread]: 
[0m22:34:42.005800 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:34:42.014945 [info ] [MainThread]: 
[0m22:34:42.023681 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:34:42.079466 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m22:34:42.425657 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m22:34:42.427875 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m22:34:42.444296 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:34:42.549369 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.110 seconds
[0m22:34:42.554150 [debug] [ThreadPool]: On list_staging: Close
[0m22:34:42.560284 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m22:34:42.596985 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:34:42.600460 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m22:34:42.603394 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:34:42.631369 [debug] [ThreadPool]: SQL status: BEGIN in 0.028 seconds
[0m22:34:42.645880 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:34:42.648674 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m22:34:42.691695 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.039 seconds
[0m22:34:42.696813 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m22:34:42.699958 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m22:34:42.759710 [debug] [MainThread]: Using postgres connection "master"
[0m22:34:42.774636 [debug] [MainThread]: On master: BEGIN
[0m22:34:42.776688 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:34:42.825434 [debug] [MainThread]: SQL status: BEGIN in 0.042 seconds
[0m22:34:42.836398 [debug] [MainThread]: Using postgres connection "master"
[0m22:34:42.848086 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m22:34:42.889724 [debug] [MainThread]: SQL status: SELECT 0 in 0.038 seconds
[0m22:34:42.896531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24985f6f-0a79-48b3-bd11-5b051844d543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57347083d0>]}
[0m22:34:42.898882 [debug] [MainThread]: On master: ROLLBACK
[0m22:34:42.901389 [debug] [MainThread]: Using postgres connection "master"
[0m22:34:42.903308 [debug] [MainThread]: On master: BEGIN
[0m22:34:42.905974 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m22:34:42.908578 [debug] [MainThread]: On master: COMMIT
[0m22:34:42.910617 [debug] [MainThread]: Using postgres connection "master"
[0m22:34:42.914079 [debug] [MainThread]: On master: COMMIT
[0m22:34:42.925937 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:34:42.927895 [debug] [MainThread]: On master: Close
[0m22:34:42.953650 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m22:34:42.957490 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m22:34:42.962360 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m22:34:42.965281 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m22:34:43.044835 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m22:34:43.067607 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m22:34:43.265626 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m22:34:43.315917 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:34:43.324311 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m22:34:43.330665 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:34:43.357542 [debug] [Thread-1 (]: SQL status: BEGIN in 0.024 seconds
[0m22:34:43.361107 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:34:43.364609 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."staging"."bankole_store"
),

select
InvoiceNo as invoie_no,
trim(StockCode) as stock_code,
upper(Description) as description,
cast(Quantity as int) as quantity,
cast(to_timestamp(InvoiceDate, 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp(InvoiceDate, 'MM/DD/YYYY HH24:MI') 'HH24:MI') as invoice_time,
UnitPrice as unit_price,
CustomerID AS customer_id,
Upper(Country) as Country
from source
  );
[0m22:34:43.373295 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "select"
LINE 14: select
         ^

[0m22:34:43.377838 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: ROLLBACK
[0m22:34:43.394789 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m22:34:43.480161 [debug] [Thread-1 (]: Database Error in model stg_sales (models/stg_sales.sql)
  syntax error at or near "select"
  LINE 14: select
           ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m22:34:43.499644 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24985f6f-0a79-48b3-bd11-5b051844d543', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5738804d30>]}
[0m22:34:43.504597 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model bankole_store.stg_sales ................... [[31mERROR[0m in 0.53s]
[0m22:34:43.520307 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m22:34:43.538902 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.stg_sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_sales (models/stg_sales.sql)
  syntax error at or near "select"
  LINE 14: select
           ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql.
[0m22:34:43.556744 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m22:34:43.565694 [info ] [Thread-1 (]: 2 of 2 SKIP relation bankole_store.sales_summary ............................... [[33mSKIP[0m]
[0m22:34:43.569726 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m22:34:43.584096 [debug] [MainThread]: Using postgres connection "master"
[0m22:34:43.592931 [debug] [MainThread]: On master: BEGIN
[0m22:34:43.601343 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:34:43.638429 [debug] [MainThread]: SQL status: BEGIN in 0.038 seconds
[0m22:34:43.644805 [debug] [MainThread]: On master: COMMIT
[0m22:34:43.647705 [debug] [MainThread]: Using postgres connection "master"
[0m22:34:43.651244 [debug] [MainThread]: On master: COMMIT
[0m22:34:43.654948 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:34:43.665624 [debug] [MainThread]: On master: Close
[0m22:34:43.668514 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:34:43.670700 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m22:34:43.672704 [debug] [MainThread]: Connection 'model.dbt_transform.stg_sales' was properly closed.
[0m22:34:43.683271 [info ] [MainThread]: 
[0m22:34:43.688695 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.66 seconds (1.66s).
[0m22:34:43.704270 [debug] [MainThread]: Command end result
[0m22:34:44.198736 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:34:44.228138 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:34:44.274301 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m22:34:44.276241 [info ] [MainThread]: 
[0m22:34:44.290965 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m22:34:44.305756 [info ] [MainThread]: 
[0m22:34:44.318815 [error] [MainThread]: [31mFailure in model stg_sales (models/stg_sales.sql)[0m
[0m22:34:44.331203 [error] [MainThread]:   Database Error in model stg_sales (models/stg_sales.sql)
  syntax error at or near "select"
  LINE 14: select
           ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m22:34:44.334612 [info ] [MainThread]: 
[0m22:34:44.351710 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/stg_sales.sql
[0m22:34:44.364128 [info ] [MainThread]: 
[0m22:34:44.367391 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m22:34:44.381882 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.641938, "process_in_blocks": "2504", "process_kernel_time": 1.603032, "process_mem_max_rss": "126068", "process_out_blocks": "1504", "process_user_time": 8.470344}
[0m22:34:44.387612 [debug] [MainThread]: Command `dbt run` failed at 22:34:44.387181 after 7.65 seconds
[0m22:34:44.399981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57384c27d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57398039a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5738411ab0>]}
[0m22:34:44.403043 [debug] [MainThread]: Flushing usage events
[0m22:34:45.794127 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:41:22.213185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57f95e830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57e97f580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57e97f520>]}


============================== 22:41:22.230670 | f7b6aa29-81f6-4dd1-9ca8-1da2edc51825 ==============================
[0m22:41:22.230670 [info ] [MainThread]: Running with dbt=1.10.13
[0m22:41:22.243689 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'printer_width': '80', 'empty': 'False', 'write_json': 'True', 'profiles_dir': '/dbt', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'static_parser': 'True', 'log_format': 'default', 'log_path': '/dbt/logs', 'use_colors': 'True', 'quiet': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'indirect_selection': 'eager', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'debug': 'False', 'version_check': 'True', 'introspect': 'True', 'no_print': 'None', 'warn_error': 'None', 'cache_selected_only': 'False'}
[0m22:41:23.096654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f7b6aa29-81f6-4dd1-9ca8-1da2edc51825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57f1d82b0>]}
[0m22:41:23.462103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f7b6aa29-81f6-4dd1-9ca8-1da2edc51825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57e7d2290>]}
[0m22:41:23.475226 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m22:41:24.037984 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m22:41:25.113592 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m22:41:25.130588 [debug] [MainThread]: Partial parsing: updated file: dbt_transform://models/stg_sales.sql
[0m22:41:25.133165 [debug] [MainThread]: Partial parsing: updated file: dbt_transform://models/sales_summary.sql
[0m22:41:27.668964 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m22:41:27.815392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f7b6aa29-81f6-4dd1-9ca8-1da2edc51825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57c7c8070>]}
[0m22:41:28.387601 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:41:28.422812 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:41:28.512482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f7b6aa29-81f6-4dd1-9ca8-1da2edc51825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57c16ef20>]}
[0m22:41:28.515060 [info ] [MainThread]: Found 2 models, 5 data tests, 1 source, 447 macros
[0m22:41:28.518842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7b6aa29-81f6-4dd1-9ca8-1da2edc51825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57c16efe0>]}
[0m22:41:28.552371 [info ] [MainThread]: 
[0m22:41:28.561728 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:41:28.567651 [info ] [MainThread]: 
[0m22:41:28.630324 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:41:28.716093 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m22:41:29.002347 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m22:41:29.004841 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m22:41:29.007967 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:41:29.052942 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.045 seconds
[0m22:41:29.057486 [debug] [ThreadPool]: On list_staging: Close
[0m22:41:29.062898 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m22:41:29.151291 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:41:29.176653 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m22:41:29.179158 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:41:29.252114 [debug] [ThreadPool]: SQL status: BEGIN in 0.072 seconds
[0m22:41:29.257709 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:41:29.261858 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m22:41:29.321538 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.052 seconds
[0m22:41:29.328942 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m22:41:29.339915 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m22:41:29.392846 [debug] [MainThread]: Using postgres connection "master"
[0m22:41:29.394943 [debug] [MainThread]: On master: BEGIN
[0m22:41:29.398507 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:41:29.448209 [debug] [MainThread]: SQL status: BEGIN in 0.050 seconds
[0m22:41:29.506193 [debug] [MainThread]: Using postgres connection "master"
[0m22:41:29.509890 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m22:41:29.538020 [debug] [MainThread]: SQL status: SELECT 0 in 0.018 seconds
[0m22:41:29.555357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7b6aa29-81f6-4dd1-9ca8-1da2edc51825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57c10a8c0>]}
[0m22:41:29.568756 [debug] [MainThread]: On master: ROLLBACK
[0m22:41:29.574231 [debug] [MainThread]: Using postgres connection "master"
[0m22:41:29.576542 [debug] [MainThread]: On master: BEGIN
[0m22:41:29.583295 [debug] [MainThread]: SQL status: BEGIN in 0.004 seconds
[0m22:41:29.589636 [debug] [MainThread]: On master: COMMIT
[0m22:41:29.592546 [debug] [MainThread]: Using postgres connection "master"
[0m22:41:29.597106 [debug] [MainThread]: On master: COMMIT
[0m22:41:29.602274 [debug] [MainThread]: SQL status: COMMIT in 0.003 seconds
[0m22:41:29.604507 [debug] [MainThread]: On master: Close
[0m22:41:29.629180 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m22:41:29.633343 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m22:41:29.645049 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m22:41:29.647893 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m22:41:29.724752 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m22:41:29.754137 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m22:41:29.912001 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m22:41:29.930096 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:41:29.932530 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m22:41:29.935232 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:41:29.963897 [debug] [Thread-1 (]: SQL status: BEGIN in 0.028 seconds
[0m22:41:29.966546 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:41:29.970297 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."staging"."bankole_store"
),

staged as 
(
select
InvoiceNo as invoie_no,
trim(StockCode) as stock_code,
upper(Description) as description,
cast(Quantity as int) as quantity,
cast(to_timestamp(InvoiceDate, 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp(InvoiceDate, 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
UnitPrice as unit_price,
CustomerID AS customer_id,
Upper(Country) as Country
from source
)

select * from staged
  );
[0m22:41:29.980807 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "staging.bankole_store" does not exist
LINE 11:     select * from "staging"."staging"."bankole_store"
                           ^

[0m22:41:29.986600 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: ROLLBACK
[0m22:41:29.990007 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m22:41:30.067149 [debug] [Thread-1 (]: Database Error in model stg_sales (models/stg_sales.sql)
  relation "staging.bankole_store" does not exist
  LINE 11:     select * from "staging"."staging"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m22:41:30.138524 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7b6aa29-81f6-4dd1-9ca8-1da2edc51825', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57fca0460>]}
[0m22:41:30.142826 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model bankole_store.stg_sales ................... [[31mERROR[0m in 0.46s]
[0m22:41:30.147261 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m22:41:30.168479 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.stg_sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_sales (models/stg_sales.sql)
  relation "staging.bankole_store" does not exist
  LINE 11:     select * from "staging"."staging"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql.
[0m22:41:30.184588 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m22:41:30.198368 [info ] [Thread-1 (]: 2 of 2 SKIP relation bankole_store.sales_summary ............................... [[33mSKIP[0m]
[0m22:41:30.201469 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m22:41:30.224453 [debug] [MainThread]: Using postgres connection "master"
[0m22:41:30.233973 [debug] [MainThread]: On master: BEGIN
[0m22:41:30.254618 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:41:30.342920 [debug] [MainThread]: SQL status: BEGIN in 0.088 seconds
[0m22:41:30.362478 [debug] [MainThread]: On master: COMMIT
[0m22:41:30.376725 [debug] [MainThread]: Using postgres connection "master"
[0m22:41:30.379165 [debug] [MainThread]: On master: COMMIT
[0m22:41:30.406443 [debug] [MainThread]: SQL status: COMMIT in 0.012 seconds
[0m22:41:30.410603 [debug] [MainThread]: On master: Close
[0m22:41:30.426413 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:41:30.428780 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m22:41:30.442746 [debug] [MainThread]: Connection 'model.dbt_transform.stg_sales' was properly closed.
[0m22:41:30.445311 [info ] [MainThread]: 
[0m22:41:30.459998 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.82 seconds (1.82s).
[0m22:41:30.478291 [debug] [MainThread]: Command end result
[0m22:41:30.975887 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:41:31.013414 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:41:31.071834 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m22:41:31.075614 [info ] [MainThread]: 
[0m22:41:31.097401 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m22:41:31.114996 [info ] [MainThread]: 
[0m22:41:31.129026 [error] [MainThread]: [31mFailure in model stg_sales (models/stg_sales.sql)[0m
[0m22:41:31.131827 [error] [MainThread]:   Database Error in model stg_sales (models/stg_sales.sql)
  relation "staging.bankole_store" does not exist
  LINE 11:     select * from "staging"."staging"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m22:41:31.134523 [info ] [MainThread]: 
[0m22:41:31.148785 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/stg_sales.sql
[0m22:41:31.170456 [info ] [MainThread]: 
[0m22:41:31.190846 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m22:41:31.202728 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.2980995, "process_in_blocks": "0", "process_kernel_time": 1.291093, "process_mem_max_rss": "128336", "process_out_blocks": "1504", "process_user_time": 9.603745}
[0m22:41:31.206295 [debug] [MainThread]: Command `dbt run` failed at 22:41:31.205849 after 9.30 seconds
[0m22:41:31.208482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57f95e830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57e7d2290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57f8aa9e0>]}
[0m22:41:31.222184 [debug] [MainThread]: Flushing usage events
[0m22:41:32.280225 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:58:19.006131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a92e4e800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a91e97880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a91e97820>]}


============================== 22:58:19.047720 | c7409ca4-788b-4abf-ae50-74889962f411 ==============================
[0m22:58:19.047720 [info ] [MainThread]: Running with dbt=1.10.13
[0m22:58:19.073183 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'empty': 'None', 'profiles_dir': '/dbt', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_path': '/dbt/logs', 'printer_width': '80', 'write_json': 'True', 'invocation_command': 'dbt test', 'no_print': 'None', 'debug': 'False', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'version_check': 'True'}
[0m22:58:20.106774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c7409ca4-788b-4abf-ae50-74889962f411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9119f5e0>]}
[0m22:58:20.399386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c7409ca4-788b-4abf-ae50-74889962f411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a91dc8bb0>]}
[0m22:58:20.414196 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m22:58:20.886477 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m22:58:21.704001 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m22:58:21.707846 [debug] [MainThread]: Partial parsing: updated file: dbt_transform://models/schema.yml
[0m22:58:21.710283 [debug] [MainThread]: Partial parsing: updated file: dbt_transform://models/sales_summary.sql
[0m22:58:21.713058 [debug] [MainThread]: Partial parsing: updated file: dbt_transform://models/stg_sales.sql
[0m22:58:23.999634 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m22:58:24.082025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c7409ca4-788b-4abf-ae50-74889962f411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8ef47eb0>]}
[0m22:58:24.474886 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:58:24.497115 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:58:24.656412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c7409ca4-788b-4abf-ae50-74889962f411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8eef1ea0>]}
[0m22:58:24.660185 [info ] [MainThread]: Found 2 models, 5 data tests, 1 source, 447 macros
[0m22:58:24.693201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c7409ca4-788b-4abf-ae50-74889962f411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8eef1e40>]}
[0m22:58:24.716156 [info ] [MainThread]: 
[0m22:58:24.720056 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:58:24.724858 [info ] [MainThread]: 
[0m22:58:24.738366 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:58:24.778547 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m22:58:24.931306 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:58:24.933478 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m22:58:24.935640 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:58:24.955420 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m22:58:24.958181 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:58:24.962349 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m22:58:24.970843 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m22:58:24.974094 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m22:58:24.978526 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m22:58:25.016701 [debug] [MainThread]: Using postgres connection "master"
[0m22:58:25.023284 [debug] [MainThread]: On master: BEGIN
[0m22:58:25.028041 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:58:25.065425 [debug] [MainThread]: SQL status: BEGIN in 0.037 seconds
[0m22:58:25.081962 [debug] [MainThread]: Using postgres connection "master"
[0m22:58:25.084690 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m22:58:25.110167 [debug] [MainThread]: SQL status: SELECT 0 in 0.013 seconds
[0m22:58:25.115143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c7409ca4-788b-4abf-ae50-74889962f411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a91cd1cc0>]}
[0m22:58:25.119263 [debug] [MainThread]: On master: ROLLBACK
[0m22:58:25.122086 [debug] [MainThread]: Using postgres connection "master"
[0m22:58:25.126153 [debug] [MainThread]: On master: BEGIN
[0m22:58:25.136047 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m22:58:25.138501 [debug] [MainThread]: On master: COMMIT
[0m22:58:25.140434 [debug] [MainThread]: Using postgres connection "master"
[0m22:58:25.142349 [debug] [MainThread]: On master: COMMIT
[0m22:58:25.146556 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m22:58:25.148706 [debug] [MainThread]: On master: Close
[0m22:58:25.158921 [debug] [Thread-1 (]: Began running node test.dbt_transform.date_stg_sales_invoice_date.f0a30d1196
[0m22:58:25.161906 [info ] [Thread-1 (]: 1 of 5 START test date_stg_sales_invoice_date .................................. [RUN]
[0m22:58:25.170520 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now test.dbt_transform.date_stg_sales_invoice_date.f0a30d1196)
[0m22:58:25.173079 [debug] [Thread-1 (]: Began compiling node test.dbt_transform.date_stg_sales_invoice_date.f0a30d1196
[0m22:58:25.221042 [debug] [Thread-1 (]: Compilation Error in test date_stg_sales_invoice_date (models/schema.yml)
  'test_date' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m22:58:25.223712 [error] [Thread-1 (]: 1 of 5 ERROR date_stg_sales_invoice_date ....................................... [[31mERROR[0m in 0.05s]
[0m22:58:25.232743 [debug] [Thread-1 (]: Finished running node test.dbt_transform.date_stg_sales_invoice_date.f0a30d1196
[0m22:58:25.235396 [debug] [Thread-1 (]: Began running node test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793
[0m22:58:25.237459 [debug] [Thread-4 (]: Marking all children of 'test.dbt_transform.date_stg_sales_invoice_date.f0a30d1196' to be skipped because of status 'error'.  Reason: Compilation Error in test date_stg_sales_invoice_date (models/schema.yml)
  'test_date' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m22:58:25.239424 [info ] [Thread-1 (]: 2 of 5 START test not_null_stg_sales_customer_id ............................... [RUN]
[0m22:58:25.255238 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_transform.date_stg_sales_invoice_date.f0a30d1196, now test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793)
[0m22:58:25.261996 [debug] [Thread-1 (]: Began compiling node test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793
[0m22:58:25.292694 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793"
[0m22:58:25.360527 [debug] [Thread-1 (]: Began executing node test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793
[0m22:58:25.431972 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793"
[0m22:58:25.456739 [debug] [Thread-1 (]: Using postgres connection "test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793"
[0m22:58:25.459624 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793: BEGIN
[0m22:58:25.463097 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:58:25.484071 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m22:58:25.487279 [debug] [Thread-1 (]: Using postgres connection "test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793"
[0m22:58:25.489734 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_id
from "staging"."bankole_store"."stg_sales"
where customer_id is null



  
  
      
    ) dbt_internal_test
[0m22:58:25.494332 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bankole_store.stg_sales" does not exist
LINE 17: from "staging"."bankole_store"."stg_sales"
              ^

[0m22:58:25.505366 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793: ROLLBACK
[0m22:58:25.508453 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793: Close
[0m22:58:25.520217 [debug] [Thread-1 (]: Database Error in test not_null_stg_sales_customer_id (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 17: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/not_null_stg_sales_customer_id.sql
[0m22:58:25.527102 [error] [Thread-1 (]: 2 of 5 ERROR not_null_stg_sales_customer_id .................................... [[31mERROR[0m in 0.27s]
[0m22:58:25.536987 [debug] [Thread-1 (]: Finished running node test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793
[0m22:58:25.540221 [debug] [Thread-1 (]: Began running node test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586
[0m22:58:25.543339 [debug] [Thread-4 (]: Marking all children of 'test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793' to be skipped because of status 'error'.  Reason: Database Error in test not_null_stg_sales_customer_id (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 17: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/not_null_stg_sales_customer_id.sql.
[0m22:58:25.553421 [info ] [Thread-1 (]: 3 of 5 START test not_null_stg_sales_invoice_no ................................ [RUN]
[0m22:58:25.560884 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_transform.not_null_stg_sales_customer_id.af88ce3793, now test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586)
[0m22:58:25.565603 [debug] [Thread-1 (]: Began compiling node test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586
[0m22:58:25.606245 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586"
[0m22:58:25.844516 [debug] [Thread-1 (]: Began executing node test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586
[0m22:58:25.871351 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586"
[0m22:58:25.993025 [debug] [Thread-1 (]: Using postgres connection "test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586"
[0m22:58:25.995617 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586: BEGIN
[0m22:58:25.998079 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:58:26.042986 [debug] [Thread-1 (]: SQL status: BEGIN in 0.038 seconds
[0m22:58:26.048630 [debug] [Thread-1 (]: Using postgres connection "test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586"
[0m22:58:26.051615 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select invoice_no
from "staging"."bankole_store"."stg_sales"
where invoice_no is null



  
  
      
    ) dbt_internal_test
[0m22:58:26.065088 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bankole_store.stg_sales" does not exist
LINE 17: from "staging"."bankole_store"."stg_sales"
              ^

[0m22:58:26.068866 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586: ROLLBACK
[0m22:58:26.086534 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586: Close
[0m22:58:26.107993 [debug] [Thread-1 (]: Database Error in test not_null_stg_sales_invoice_no (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 17: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/not_null_stg_sales_invoice_no.sql
[0m22:58:26.123466 [error] [Thread-1 (]: 3 of 5 ERROR not_null_stg_sales_invoice_no ..................................... [[31mERROR[0m in 0.55s]
[0m22:58:26.128336 [debug] [Thread-1 (]: Finished running node test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586
[0m22:58:26.131558 [debug] [Thread-1 (]: Began running node test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d
[0m22:58:26.134495 [debug] [Thread-4 (]: Marking all children of 'test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586' to be skipped because of status 'error'.  Reason: Database Error in test not_null_stg_sales_invoice_no (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 17: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/not_null_stg_sales_invoice_no.sql.
[0m22:58:26.144315 [info ] [Thread-1 (]: 4 of 5 START test not_null_stg_sales_stock_code ................................ [RUN]
[0m22:58:26.149270 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_transform.not_null_stg_sales_invoice_no.be04f07586, now test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d)
[0m22:58:26.158011 [debug] [Thread-1 (]: Began compiling node test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d
[0m22:58:26.192479 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d"
[0m22:58:26.235020 [debug] [Thread-1 (]: Began executing node test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d
[0m22:58:26.262097 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d"
[0m22:58:26.293021 [debug] [Thread-1 (]: Using postgres connection "test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d"
[0m22:58:26.295731 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d: BEGIN
[0m22:58:26.308840 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:58:26.343419 [debug] [Thread-1 (]: SQL status: BEGIN in 0.031 seconds
[0m22:58:26.349357 [debug] [Thread-1 (]: Using postgres connection "test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d"
[0m22:58:26.351681 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select stock_code
from "staging"."bankole_store"."stg_sales"
where stock_code is null



  
  
      
    ) dbt_internal_test
[0m22:58:26.361352 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bankole_store.stg_sales" does not exist
LINE 17: from "staging"."bankole_store"."stg_sales"
              ^

[0m22:58:26.367800 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d: ROLLBACK
[0m22:58:26.371683 [debug] [Thread-1 (]: On test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d: Close
[0m22:58:26.387880 [debug] [Thread-1 (]: Database Error in test not_null_stg_sales_stock_code (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 17: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/not_null_stg_sales_stock_code.sql
[0m22:58:26.391169 [error] [Thread-1 (]: 4 of 5 ERROR not_null_stg_sales_stock_code ..................................... [[31mERROR[0m in 0.24s]
[0m22:58:26.406009 [debug] [Thread-1 (]: Finished running node test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d
[0m22:58:26.409420 [debug] [Thread-1 (]: Began running node test.dbt_transform.unique_stg_sales_invoice_no.035341740f
[0m22:58:26.422895 [info ] [Thread-1 (]: 5 of 5 START test unique_stg_sales_invoice_no .................................. [RUN]
[0m22:58:26.426099 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d, now test.dbt_transform.unique_stg_sales_invoice_no.035341740f)
[0m22:58:26.433860 [debug] [Thread-1 (]: Began compiling node test.dbt_transform.unique_stg_sales_invoice_no.035341740f
[0m22:58:26.416814 [debug] [Thread-4 (]: Marking all children of 'test.dbt_transform.not_null_stg_sales_stock_code.5cf83acd5d' to be skipped because of status 'error'.  Reason: Database Error in test not_null_stg_sales_stock_code (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 17: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/not_null_stg_sales_stock_code.sql.
[0m22:58:26.484971 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_transform.unique_stg_sales_invoice_no.035341740f"
[0m22:58:26.509049 [debug] [Thread-1 (]: Began executing node test.dbt_transform.unique_stg_sales_invoice_no.035341740f
[0m22:58:26.537164 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_transform.unique_stg_sales_invoice_no.035341740f"
[0m22:58:26.575259 [debug] [Thread-1 (]: Using postgres connection "test.dbt_transform.unique_stg_sales_invoice_no.035341740f"
[0m22:58:26.577653 [debug] [Thread-1 (]: On test.dbt_transform.unique_stg_sales_invoice_no.035341740f: BEGIN
[0m22:58:26.585260 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:58:26.617748 [debug] [Thread-1 (]: SQL status: BEGIN in 0.032 seconds
[0m22:58:26.630876 [debug] [Thread-1 (]: Using postgres connection "test.dbt_transform.unique_stg_sales_invoice_no.035341740f"
[0m22:58:26.637906 [debug] [Thread-1 (]: On test.dbt_transform.unique_stg_sales_invoice_no.035341740f: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "test.dbt_transform.unique_stg_sales_invoice_no.035341740f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    invoice_no as unique_field,
    count(*) as n_records

from "staging"."bankole_store"."stg_sales"
where invoice_no is not null
group by invoice_no
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m22:58:26.650215 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "bankole_store.stg_sales" does not exist
LINE 18: from "staging"."bankole_store"."stg_sales"
              ^

[0m22:58:26.654161 [debug] [Thread-1 (]: On test.dbt_transform.unique_stg_sales_invoice_no.035341740f: ROLLBACK
[0m22:58:26.660066 [debug] [Thread-1 (]: On test.dbt_transform.unique_stg_sales_invoice_no.035341740f: Close
[0m22:58:26.689968 [debug] [Thread-1 (]: Database Error in test unique_stg_sales_invoice_no (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 18: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/unique_stg_sales_invoice_no.sql
[0m22:58:26.706913 [error] [Thread-1 (]: 5 of 5 ERROR unique_stg_sales_invoice_no ....................................... [[31mERROR[0m in 0.28s]
[0m22:58:26.710852 [debug] [Thread-1 (]: Finished running node test.dbt_transform.unique_stg_sales_invoice_no.035341740f
[0m22:58:26.718144 [debug] [Thread-4 (]: Marking all children of 'test.dbt_transform.unique_stg_sales_invoice_no.035341740f' to be skipped because of status 'error'.  Reason: Database Error in test unique_stg_sales_invoice_no (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 18: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/unique_stg_sales_invoice_no.sql.
[0m22:58:26.730955 [debug] [MainThread]: Using postgres connection "master"
[0m22:58:26.738765 [debug] [MainThread]: On master: BEGIN
[0m22:58:26.787477 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:58:26.813697 [debug] [MainThread]: SQL status: BEGIN in 0.026 seconds
[0m22:58:26.819038 [debug] [MainThread]: On master: COMMIT
[0m22:58:26.822470 [debug] [MainThread]: Using postgres connection "master"
[0m22:58:26.827276 [debug] [MainThread]: On master: COMMIT
[0m22:58:26.844850 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:58:26.852767 [debug] [MainThread]: On master: Close
[0m22:58:26.860565 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:58:26.880091 [debug] [MainThread]: Connection 'test.dbt_transform.unique_stg_sales_invoice_no.035341740f' was properly closed.
[0m22:58:26.896106 [info ] [MainThread]: 
[0m22:58:26.914772 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 2.16 seconds (2.16s).
[0m22:58:26.925286 [debug] [MainThread]: Command end result
[0m22:58:27.082926 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:58:27.112584 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:58:27.146725 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m22:58:27.148884 [info ] [MainThread]: 
[0m22:58:27.154092 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m22:58:27.160610 [info ] [MainThread]: 
[0m22:58:27.164324 [error] [MainThread]: [31mFailure in test date_stg_sales_invoice_date (models/schema.yml)[0m
[0m22:58:27.180946 [error] [MainThread]:   Compilation Error in test date_stg_sales_invoice_date (models/schema.yml)
  'test_date' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m22:58:27.193125 [info ] [MainThread]: 
[0m22:58:27.206348 [error] [MainThread]: [31mFailure in test not_null_stg_sales_customer_id (models/schema.yml)[0m
[0m22:58:27.220667 [error] [MainThread]:   Database Error in test not_null_stg_sales_customer_id (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 17: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/not_null_stg_sales_customer_id.sql
[0m22:58:27.224810 [info ] [MainThread]: 
[0m22:58:27.240156 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/schema.yml/not_null_stg_sales_customer_id.sql
[0m22:58:27.245460 [info ] [MainThread]: 
[0m22:58:27.258417 [error] [MainThread]: [31mFailure in test not_null_stg_sales_invoice_no (models/schema.yml)[0m
[0m22:58:27.270828 [error] [MainThread]:   Database Error in test not_null_stg_sales_invoice_no (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 17: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/not_null_stg_sales_invoice_no.sql
[0m22:58:27.291035 [info ] [MainThread]: 
[0m22:58:27.303524 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/schema.yml/not_null_stg_sales_invoice_no.sql
[0m22:58:27.307788 [info ] [MainThread]: 
[0m22:58:27.337905 [error] [MainThread]: [31mFailure in test not_null_stg_sales_stock_code (models/schema.yml)[0m
[0m22:58:27.341319 [error] [MainThread]:   Database Error in test not_null_stg_sales_stock_code (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 17: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/not_null_stg_sales_stock_code.sql
[0m22:58:27.356593 [info ] [MainThread]: 
[0m22:58:27.361538 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/schema.yml/not_null_stg_sales_stock_code.sql
[0m22:58:27.365303 [info ] [MainThread]: 
[0m22:58:27.374241 [error] [MainThread]: [31mFailure in test unique_stg_sales_invoice_no (models/schema.yml)[0m
[0m22:58:27.385385 [error] [MainThread]:   Database Error in test unique_stg_sales_invoice_no (models/schema.yml)
  relation "bankole_store.stg_sales" does not exist
  LINE 18: from "staging"."bankole_store"."stg_sales"
                ^
  compiled code at target/run/dbt_transform/models/schema.yml/unique_stg_sales_invoice_no.sql
[0m22:58:27.401050 [info ] [MainThread]: 
[0m22:58:27.405076 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/schema.yml/unique_stg_sales_invoice_no.sql
[0m22:58:27.409127 [info ] [MainThread]: 
[0m22:58:27.412812 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 NO-OP=0 TOTAL=5
[0m22:58:27.427841 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 8.811146, "process_in_blocks": "0", "process_kernel_time": 1.120536, "process_mem_max_rss": "127908", "process_out_blocks": "1504", "process_user_time": 10.0248}
[0m22:58:27.439411 [debug] [MainThread]: Command `dbt test` failed at 22:58:27.438941 after 8.82 seconds
[0m22:58:27.461763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a92e4e800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a94196d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a8eef2a70>]}
[0m22:58:27.471270 [debug] [MainThread]: Flushing usage events
[0m22:58:28.492016 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:08:32.332322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80d15e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80bedf730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80bedf6d0>]}


============================== 23:08:32.345185 | 7dc7d5a2-b0e3-4cba-b1bb-0d200d069041 ==============================
[0m23:08:32.345185 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:08:32.350043 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'indirect_selection': 'eager', 'introspect': 'True', 'static_parser': 'True', 'empty': 'None', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default', 'quiet': 'False', 'printer_width': '80', 'log_path': '/dbt/logs', 'debug': 'False', 'profiles_dir': '/dbt', 'write_json': 'True', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'use_colors': 'True', 'fail_fast': 'False', 'warn_error': 'None'}
[0m23:08:32.811042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7dc7d5a2-b0e3-4cba-b1bb-0d200d069041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80e9910c0>]}
[0m23:08:33.007269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7dc7d5a2-b0e3-4cba-b1bb-0d200d069041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80bd3bb80>]}
[0m23:08:33.010370 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:08:33.388658 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:08:33.742925 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m23:08:33.752461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7dc7d5a2-b0e3-4cba-b1bb-0d200d069041', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80c732380>]}
[0m23:08:38.531989 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_transform.stg_sales' (models/stg_sales.sql) depends on a source named 'public.bankole_store' which was not found
[0m23:08:38.548308 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 6.386651, "process_in_blocks": "0", "process_kernel_time": 0.440729, "process_mem_max_rss": "116476", "process_out_blocks": "1432", "process_user_time": 9.325443}
[0m23:08:38.568128 [debug] [MainThread]: Command `dbt test` failed at 23:08:38.567687 after 6.41 seconds
[0m23:08:38.597862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80d15e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc809d1d480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80a5374c0>]}
[0m23:08:38.603280 [debug] [MainThread]: Flushing usage events
[0m23:08:39.598790 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:12:16.121463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375ba62800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375aaab550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375aaab4f0>]}


============================== 23:12:16.137599 | 0ed0e6bb-0474-4597-9e5f-b3d96290737b ==============================
[0m23:12:16.137599 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:12:16.142500 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'cache_selected_only': 'False', 'introspect': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'use_colors': 'True', 'profiles_dir': '/dbt', 'log_path': '/dbt/logs', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'quiet': 'False', 'use_experimental_parser': 'False', 'target_path': 'None', 'warn_error': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'write_json': 'True', 'invocation_command': 'dbt run', 'debug': 'False', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'static_parser': 'True'}
[0m23:12:16.780358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0ed0e6bb-0474-4597-9e5f-b3d96290737b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375b9e47f0>]}
[0m23:12:17.028733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0ed0e6bb-0474-4597-9e5f-b3d96290737b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375b2cc790>]}
[0m23:12:17.040316 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:12:17.369319 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:12:17.982373 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m23:12:17.988424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0ed0e6bb-0474-4597-9e5f-b3d96290737b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375b296d10>]}
[0m23:12:22.398061 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_transform.stg_sales' (models/stg_sales.sql) depends on a source named 'public.bankole_store' which was not found
[0m23:12:22.405109 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.533292, "process_in_blocks": "0", "process_kernel_time": 0.740636, "process_mem_max_rss": "116708", "process_out_blocks": "1432", "process_user_time": 10.191162}
[0m23:12:22.408495 [debug] [MainThread]: Command `dbt run` failed at 23:12:22.408021 after 6.54 seconds
[0m23:12:22.410674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375ba62800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f375c772710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3757cbf760>]}
[0m23:12:22.412743 [debug] [MainThread]: Flushing usage events
[0m23:12:23.323119 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:20:58.335195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c377a530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c2798b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c2798af0>]}


============================== 23:20:58.343269 | f3c34a40-2730-4086-b23b-a35e551e2120 ==============================
[0m23:20:58.343269 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:20:58.345946 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'printer_width': '80', 'version_check': 'True', 'target_path': 'None', 'debug': 'False', 'invocation_command': 'dbt run', 'write_json': 'True', 'log_format': 'default', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'empty': 'False', 'cache_selected_only': 'False', 'log_path': '/dbt/logs', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'quiet': 'False', 'profiles_dir': '/dbt', 'static_parser': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'use_colors': 'True'}
[0m23:20:58.795348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f3c34a40-2730-4086-b23b-a35e551e2120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c2652a10>]}
[0m23:20:59.014332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f3c34a40-2730-4086-b23b-a35e551e2120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c2653a60>]}
[0m23:20:59.018221 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:20:59.301591 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:20:59.640485 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m23:20:59.653490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f3c34a40-2730-4086-b23b-a35e551e2120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c15c3be0>]}
[0m23:21:03.564387 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m23:21:03.614390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f3c34a40-2730-4086-b23b-a35e551e2120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89bf87e740>]}
[0m23:21:04.009498 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:21:04.024128 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:21:04.082647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f3c34a40-2730-4086-b23b-a35e551e2120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c1948910>]}
[0m23:21:04.085431 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m23:21:04.088672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f3c34a40-2730-4086-b23b-a35e551e2120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c09b13f0>]}
[0m23:21:04.102363 [info ] [MainThread]: 
[0m23:21:04.105809 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:21:04.109891 [info ] [MainThread]: 
[0m23:21:04.113908 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:21:04.143907 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m23:21:04.276616 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m23:21:04.278515 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:21:04.280954 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:21:04.301335 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.020 seconds
[0m23:21:04.307083 [debug] [ThreadPool]: On list_staging: Close
[0m23:21:04.312986 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m23:21:04.330051 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:21:04.332319 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m23:21:04.334383 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:21:04.349462 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m23:21:04.352056 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:21:04.354485 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m23:21:04.364117 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m23:21:04.368607 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m23:21:04.370986 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m23:21:04.385330 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:04.388625 [debug] [MainThread]: On master: BEGIN
[0m23:21:04.391002 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:21:04.412262 [debug] [MainThread]: SQL status: BEGIN in 0.021 seconds
[0m23:21:04.418024 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:04.424414 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m23:21:04.436848 [debug] [MainThread]: SQL status: SELECT 0 in 0.008 seconds
[0m23:21:04.441808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f3c34a40-2730-4086-b23b-a35e551e2120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c0d60850>]}
[0m23:21:04.445139 [debug] [MainThread]: On master: ROLLBACK
[0m23:21:04.448296 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:04.453301 [debug] [MainThread]: On master: BEGIN
[0m23:21:04.463514 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m23:21:04.468143 [debug] [MainThread]: On master: COMMIT
[0m23:21:04.478709 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:04.481081 [debug] [MainThread]: On master: COMMIT
[0m23:21:04.484136 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:21:04.486704 [debug] [MainThread]: On master: Close
[0m23:21:04.507365 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m23:21:04.510334 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m23:21:04.513370 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m23:21:04.516121 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m23:21:04.546555 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m23:21:04.558783 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m23:21:04.705718 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m23:21:04.719504 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:21:04.722136 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m23:21:04.724822 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:21:04.741866 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m23:21:04.745130 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:21:04.747921 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
InvoiceNo as invoie_no,
trim(StockCode) as stock_code,
upper(Description) as description,
cast(Quantity as int) as quantity,
cast(to_timestamp(InvoiceDate, 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp(InvoiceDate, 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
UnitPrice as unit_price,
CustomerID AS customer_id,
Upper(Country) as Country
from source
)

select * from staged
  );
[0m23:21:04.752659 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "invoiceno" does not exist
LINE 17: InvoiceNo as invoie_no,
         ^
HINT:  Perhaps you meant to reference the column "source.InvoiceNo".

[0m23:21:04.755235 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: ROLLBACK
[0m23:21:04.758738 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m23:21:04.772909 [debug] [Thread-1 (]: Database Error in model stg_sales (models/stg_sales.sql)
  column "invoiceno" does not exist
  LINE 17: InvoiceNo as invoie_no,
           ^
  HINT:  Perhaps you meant to reference the column "source.InvoiceNo".
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:21:04.783126 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3c34a40-2730-4086-b23b-a35e551e2120', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c09d4f70>]}
[0m23:21:04.787524 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model bankole_store.stg_sales ................... [[31mERROR[0m in 0.26s]
[0m23:21:04.796236 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m23:21:04.800365 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.stg_sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_sales (models/stg_sales.sql)
  column "invoiceno" does not exist
  LINE 17: InvoiceNo as invoie_no,
           ^
  HINT:  Perhaps you meant to reference the column "source.InvoiceNo".
  compiled code at target/run/dbt_transform/models/stg_sales.sql.
[0m23:21:04.806888 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m23:21:04.811498 [info ] [Thread-1 (]: 2 of 2 SKIP relation bankole_store.sales_summary ............................... [[33mSKIP[0m]
[0m23:21:04.820569 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m23:21:04.826732 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:04.832954 [debug] [MainThread]: On master: BEGIN
[0m23:21:04.837258 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:21:04.869065 [debug] [MainThread]: SQL status: BEGIN in 0.032 seconds
[0m23:21:04.875658 [debug] [MainThread]: On master: COMMIT
[0m23:21:04.878668 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:04.881353 [debug] [MainThread]: On master: COMMIT
[0m23:21:04.887311 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:21:04.892404 [debug] [MainThread]: On master: Close
[0m23:21:04.895910 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:21:04.899704 [debug] [MainThread]: Connection 'model.dbt_transform.stg_sales' was properly closed.
[0m23:21:04.902334 [info ] [MainThread]: 
[0m23:21:04.907186 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.79 seconds (0.79s).
[0m23:21:04.914187 [debug] [MainThread]: Command end result
[0m23:21:05.118751 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:21:05.138800 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:21:05.181438 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m23:21:05.183950 [info ] [MainThread]: 
[0m23:21:05.189619 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:21:05.197008 [info ] [MainThread]: 
[0m23:21:05.200764 [error] [MainThread]: [31mFailure in model stg_sales (models/stg_sales.sql)[0m
[0m23:21:05.216143 [error] [MainThread]:   Database Error in model stg_sales (models/stg_sales.sql)
  column "invoiceno" does not exist
  LINE 17: InvoiceNo as invoie_no,
           ^
  HINT:  Perhaps you meant to reference the column "source.InvoiceNo".
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:21:05.219727 [info ] [MainThread]: 
[0m23:21:05.225687 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/stg_sales.sql
[0m23:21:05.231571 [info ] [MainThread]: 
[0m23:21:05.235006 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m23:21:05.240115 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.0592594, "process_in_blocks": "0", "process_kernel_time": 0.58128, "process_mem_max_rss": "126988", "process_out_blocks": "72", "process_user_time": 9.290459}
[0m23:21:05.243279 [debug] [MainThread]: Command `dbt run` failed at 23:21:05.242821 after 7.06 seconds
[0m23:21:05.246775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c377a530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c2652a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89c36fef20>]}
[0m23:21:05.249710 [debug] [MainThread]: Flushing usage events
[0m23:21:06.226897 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:31:19.898058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff241e8c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff1467670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff1467610>]}


============================== 23:31:19.915030 | be4dccae-f3d8-4c03-97cc-bf73e9f8ba99 ==============================
[0m23:31:19.915030 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:31:19.921876 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'empty': 'False', 'fail_fast': 'False', 'profiles_dir': '/dbt', 'debug': 'False', 'partial_parse': 'True', 'version_check': 'True', 'quiet': 'False', 'static_parser': 'True', 'write_json': 'True', 'indirect_selection': 'eager', 'log_path': '/dbt/logs', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'warn_error': 'None', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m23:31:20.454743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be4dccae-f3d8-4c03-97cc-bf73e9f8ba99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff0d465f0>]}
[0m23:31:20.589280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be4dccae-f3d8-4c03-97cc-bf73e9f8ba99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff222d0c0>]}
[0m23:31:20.592262 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:31:20.800610 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:31:21.249311 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:31:21.251915 [debug] [MainThread]: Partial parsing: updated file: dbt_transform://models/stg_sales.sql
[0m23:31:22.911086 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m23:31:23.000884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'be4dccae-f3d8-4c03-97cc-bf73e9f8ba99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fef5c8100>]}
[0m23:31:23.303063 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:31:23.316649 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:31:23.373850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'be4dccae-f3d8-4c03-97cc-bf73e9f8ba99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fef17e890>]}
[0m23:31:23.376801 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m23:31:23.384124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be4dccae-f3d8-4c03-97cc-bf73e9f8ba99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fef17e830>]}
[0m23:31:23.391335 [info ] [MainThread]: 
[0m23:31:23.394616 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:31:23.411862 [info ] [MainThread]: 
[0m23:31:23.415451 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:31:23.434729 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m23:31:23.579520 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m23:31:23.581242 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:31:23.583130 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:31:23.598859 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.016 seconds
[0m23:31:23.602233 [debug] [ThreadPool]: On list_staging: Close
[0m23:31:23.609187 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m23:31:23.628128 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:31:23.630048 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m23:31:23.631887 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:31:23.646772 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m23:31:23.655656 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:31:23.658030 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m23:31:23.666483 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m23:31:23.676959 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m23:31:23.680512 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m23:31:23.701142 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:23.703257 [debug] [MainThread]: On master: BEGIN
[0m23:31:23.705534 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:31:23.724297 [debug] [MainThread]: SQL status: BEGIN in 0.019 seconds
[0m23:31:23.727298 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:23.736033 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m23:31:23.756309 [debug] [MainThread]: SQL status: SELECT 0 in 0.016 seconds
[0m23:31:23.776960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be4dccae-f3d8-4c03-97cc-bf73e9f8ba99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fef14ec50>]}
[0m23:31:23.780079 [debug] [MainThread]: On master: ROLLBACK
[0m23:31:23.827559 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:23.846324 [debug] [MainThread]: On master: BEGIN
[0m23:31:23.880347 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m23:31:23.885487 [debug] [MainThread]: On master: COMMIT
[0m23:31:23.901163 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:23.907050 [debug] [MainThread]: On master: COMMIT
[0m23:31:23.944920 [debug] [MainThread]: SQL status: COMMIT in 0.006 seconds
[0m23:31:23.957233 [debug] [MainThread]: On master: Close
[0m23:31:24.008449 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m23:31:24.011986 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m23:31:24.028092 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m23:31:24.043215 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m23:31:24.082238 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m23:31:24.131662 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m23:31:24.298806 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m23:31:24.344428 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:31:24.349543 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m23:31:24.360205 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:31:24.398765 [debug] [Thread-1 (]: SQL status: BEGIN in 0.039 seconds
[0m23:31:24.428184 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:31:24.451789 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
CustomerID AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m23:31:24.488714 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "customerid" does not exist
LINE 24: CustomerID AS customer_id,
         ^
HINT:  Perhaps you meant to reference the column "source.CustomerID".

[0m23:31:24.493056 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: ROLLBACK
[0m23:31:24.497114 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m23:31:24.517029 [debug] [Thread-1 (]: Database Error in model stg_sales (models/stg_sales.sql)
  column "customerid" does not exist
  LINE 24: CustomerID AS customer_id,
           ^
  HINT:  Perhaps you meant to reference the column "source.CustomerID".
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:31:24.549185 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be4dccae-f3d8-4c03-97cc-bf73e9f8ba99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff27464d0>]}
[0m23:31:24.566135 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model bankole_store.stg_sales ................... [[31mERROR[0m in 0.50s]
[0m23:31:24.573424 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m23:31:24.584508 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.stg_sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_sales (models/stg_sales.sql)
  column "customerid" does not exist
  LINE 24: CustomerID AS customer_id,
           ^
  HINT:  Perhaps you meant to reference the column "source.CustomerID".
  compiled code at target/run/dbt_transform/models/stg_sales.sql.
[0m23:31:24.589548 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m23:31:24.604766 [info ] [Thread-1 (]: 2 of 2 SKIP relation bankole_store.sales_summary ............................... [[33mSKIP[0m]
[0m23:31:24.611672 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m23:31:24.616876 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:24.633024 [debug] [MainThread]: On master: BEGIN
[0m23:31:24.635552 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:31:24.688156 [debug] [MainThread]: SQL status: BEGIN in 0.053 seconds
[0m23:31:24.711938 [debug] [MainThread]: On master: COMMIT
[0m23:31:24.728530 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:24.730688 [debug] [MainThread]: On master: COMMIT
[0m23:31:24.733346 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:31:24.746456 [debug] [MainThread]: On master: Close
[0m23:31:24.753747 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:31:24.767481 [debug] [MainThread]: Connection 'model.dbt_transform.stg_sales' was properly closed.
[0m23:31:24.779476 [info ] [MainThread]: 
[0m23:31:24.782269 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.36 seconds (1.36s).
[0m23:31:24.786790 [debug] [MainThread]: Command end result
[0m23:31:25.077939 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:31:25.117109 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:31:25.246238 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m23:31:25.248624 [info ] [MainThread]: 
[0m23:31:25.253139 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:31:25.264108 [info ] [MainThread]: 
[0m23:31:25.280243 [error] [MainThread]: [31mFailure in model stg_sales (models/stg_sales.sql)[0m
[0m23:31:25.295813 [error] [MainThread]:   Database Error in model stg_sales (models/stg_sales.sql)
  column "customerid" does not exist
  LINE 24: CustomerID AS customer_id,
           ^
  HINT:  Perhaps you meant to reference the column "source.CustomerID".
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:31:25.306660 [info ] [MainThread]: 
[0m23:31:25.310822 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/stg_sales.sql
[0m23:31:25.329765 [info ] [MainThread]: 
[0m23:31:25.369474 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m23:31:25.398992 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.676061, "process_in_blocks": "0", "process_kernel_time": 0.801294, "process_mem_max_rss": "125828", "process_out_blocks": "1504", "process_user_time": 7.123701}
[0m23:31:25.408333 [debug] [MainThread]: Command `dbt run` failed at 23:31:25.403522 after 5.68 seconds
[0m23:31:25.416407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff241e8c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ff0d465f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fef17e4a0>]}
[0m23:31:25.439890 [debug] [MainThread]: Flushing usage events
[0m23:31:26.420212 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:34:20.518588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1406a800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd130b3550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd130b34f0>]}


============================== 23:34:20.535996 | 1aee67e2-8259-42a3-85a5-503921e4e3ec ==============================
[0m23:34:20.535996 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:34:20.545415 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'version_check': 'True', 'log_path': '/dbt/logs', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'write_json': 'True', 'printer_width': '80', 'profiles_dir': '/dbt', 'fail_fast': 'False', 'target_path': 'None', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'introspect': 'True', 'static_parser': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'empty': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'debug': 'False', 'no_print': 'None'}
[0m23:34:21.558992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1aee67e2-8259-42a3-85a5-503921e4e3ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd13ff07f0>]}
[0m23:34:21.878771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1aee67e2-8259-42a3-85a5-503921e4e3ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd138d4790>]}
[0m23:34:21.883469 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:34:22.409620 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:34:23.036494 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:34:23.040614 [debug] [MainThread]: Partial parsing: updated file: dbt_transform://models/stg_sales.sql
[0m23:34:25.498066 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m23:34:25.632854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1aee67e2-8259-42a3-85a5-503921e4e3ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd103c4100>]}
[0m23:34:26.195252 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:34:26.218611 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:34:26.310082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1aee67e2-8259-42a3-85a5-503921e4e3ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd102a7370>]}
[0m23:34:26.316178 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m23:34:26.319549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1aee67e2-8259-42a3-85a5-503921e4e3ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd102a7310>]}
[0m23:34:26.330524 [info ] [MainThread]: 
[0m23:34:26.341004 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:34:26.359934 [info ] [MainThread]: 
[0m23:34:26.363961 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:34:26.435932 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m23:34:26.620213 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m23:34:26.623060 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:34:26.625331 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:34:26.648371 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.023 seconds
[0m23:34:26.653167 [debug] [ThreadPool]: On list_staging: Close
[0m23:34:26.661764 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m23:34:26.684683 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:34:26.687109 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m23:34:26.689390 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:34:26.708897 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m23:34:26.723446 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:34:26.736110 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m23:34:26.745399 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m23:34:26.750627 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m23:34:26.753013 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m23:34:26.811176 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:26.813503 [debug] [MainThread]: On master: BEGIN
[0m23:34:26.815794 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:34:26.837891 [debug] [MainThread]: SQL status: BEGIN in 0.022 seconds
[0m23:34:26.844330 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:26.850056 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m23:34:26.866818 [debug] [MainThread]: SQL status: SELECT 0 in 0.014 seconds
[0m23:34:26.874078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1aee67e2-8259-42a3-85a5-503921e4e3ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd10224400>]}
[0m23:34:26.876892 [debug] [MainThread]: On master: ROLLBACK
[0m23:34:26.879239 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:26.881361 [debug] [MainThread]: On master: BEGIN
[0m23:34:26.889960 [debug] [MainThread]: SQL status: BEGIN in 0.002 seconds
[0m23:34:26.892672 [debug] [MainThread]: On master: COMMIT
[0m23:34:26.896218 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:26.901882 [debug] [MainThread]: On master: COMMIT
[0m23:34:26.912728 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:34:26.921876 [debug] [MainThread]: On master: Close
[0m23:34:26.955930 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m23:34:26.958873 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m23:34:26.968236 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m23:34:26.970760 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m23:34:27.051778 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m23:34:27.076675 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m23:34:27.212697 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m23:34:27.229472 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:34:27.232386 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m23:34:27.234857 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:27.265409 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m23:34:27.272284 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:34:27.275882 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m23:34:27.297706 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.019 seconds
[0m23:34:27.335924 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:34:27.343795 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m23:34:27.375241 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.005 seconds
[0m23:34:27.504210 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m23:34:27.514000 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:34:27.516754 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m23:34:27.522569 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m23:34:27.562074 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m23:34:27.610954 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:34:27.613232 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m23:34:27.616537 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m23:34:27.627457 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m23:34:27.643170 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aee67e2-8259-42a3-85a5-503921e4e3ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd15b37eb0>]}
[0m23:34:27.646078 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 0.67s]
[0m23:34:27.658928 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m23:34:27.661591 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m23:34:27.664102 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m23:34:27.666853 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m23:34:27.675512 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m23:34:27.729709 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m23:34:27.754138 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m23:34:27.863708 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m23:34:27.879842 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m23:34:27.885091 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m23:34:27.901796 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:27.945010 [debug] [Thread-1 (]: SQL status: BEGIN in 0.043 seconds
[0m23:34:27.958165 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m23:34:27.963584 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
sum(quantity * unit_price) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m23:34:32.768856 [debug] [Thread-1 (]: SQL status: SELECT 1716 in 4.784 seconds
[0m23:34:32.791530 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m23:34:32.794000 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m23:34:32.797362 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:34:32.802540 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m23:34:32.805000 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m23:34:32.807757 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m23:34:32.811595 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m23:34:32.820714 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m23:34:32.830218 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m23:34:32.832453 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m23:34:32.836742 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m23:34:32.841589 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m23:34:32.845637 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aee67e2-8259-42a3-85a5-503921e4e3ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd0348ef50>]}
[0m23:34:32.851315 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 1716[0m in 5.18s]
[0m23:34:32.860894 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m23:34:32.870016 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:32.872464 [debug] [MainThread]: On master: BEGIN
[0m23:34:32.874495 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:34:32.901254 [debug] [MainThread]: SQL status: BEGIN in 0.027 seconds
[0m23:34:32.903513 [debug] [MainThread]: On master: COMMIT
[0m23:34:32.917735 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:32.919770 [debug] [MainThread]: On master: COMMIT
[0m23:34:32.922152 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:34:32.926619 [debug] [MainThread]: On master: Close
[0m23:34:32.929177 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:34:32.934545 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m23:34:32.936460 [info ] [MainThread]: 
[0m23:34:32.940027 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 6.57 seconds (6.57s).
[0m23:34:32.955106 [debug] [MainThread]: Command end result
[0m23:34:33.119861 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:34:33.135439 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:34:33.175312 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m23:34:33.179437 [info ] [MainThread]: 
[0m23:34:33.192301 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:34:33.195544 [info ] [MainThread]: 
[0m23:34:33.198625 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m23:34:33.214651 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.944664, "process_in_blocks": "0", "process_kernel_time": 0.956332, "process_mem_max_rss": "128056", "process_out_blocks": "1504", "process_user_time": 9.593526}
[0m23:34:33.217656 [debug] [MainThread]: Command `dbt run` succeeded at 23:34:33.217062 after 12.95 seconds
[0m23:34:33.220165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd1406a800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd13fbc820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd153abc10>]}
[0m23:34:33.226814 [debug] [MainThread]: Flushing usage events
[0m23:34:34.181424 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:56:56.876832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f958451a7a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95835374c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9583537460>]}


============================== 23:56:56.892242 | 975f1676-cf32-4f4d-a8ae-e61d8c0699c5 ==============================
[0m23:56:56.892242 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:56:56.898362 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'static_parser': 'True', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run', 'partial_parse': 'True', 'profiles_dir': '/dbt', 'printer_width': '80', 'log_format': 'default', 'fail_fast': 'False', 'debug': 'False', 'target_path': 'None', 'warn_error': 'None', 'empty': 'False', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'version_check': 'True', 'use_colors': 'True', 'log_path': '/dbt/logs'}
[0m23:56:57.811217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '975f1676-cf32-4f4d-a8ae-e61d8c0699c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9583d97df0>]}
[0m23:56:58.138218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '975f1676-cf32-4f4d-a8ae-e61d8c0699c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9583d67970>]}
[0m23:56:58.141155 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:56:58.406818 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:56:58.903125 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:56:58.905695 [debug] [MainThread]: Partial parsing: updated file: dbt_transform://models/sales_summary.sql
[0m23:57:00.012186 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m23:57:00.116033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '975f1676-cf32-4f4d-a8ae-e61d8c0699c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f958133d7e0>]}
[0m23:57:00.470668 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:57:00.496093 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:57:00.556105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '975f1676-cf32-4f4d-a8ae-e61d8c0699c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9580b24880>]}
[0m23:57:00.558708 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m23:57:00.568542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '975f1676-cf32-4f4d-a8ae-e61d8c0699c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9580b248e0>]}
[0m23:57:00.577390 [info ] [MainThread]: 
[0m23:57:00.580365 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:57:00.590385 [info ] [MainThread]: 
[0m23:57:00.594288 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:57:00.618947 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m23:57:00.758227 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m23:57:00.759942 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:57:00.761665 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:57:00.779108 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.017 seconds
[0m23:57:00.783220 [debug] [ThreadPool]: On list_staging: Close
[0m23:57:00.788303 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m23:57:00.806491 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:57:00.808214 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m23:57:00.809930 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:57:00.828005 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m23:57:00.834515 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:57:00.837072 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m23:57:00.846831 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m23:57:00.858937 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m23:57:00.861709 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m23:57:00.885906 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:00.888835 [debug] [MainThread]: On master: BEGIN
[0m23:57:00.890701 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:57:00.909189 [debug] [MainThread]: SQL status: BEGIN in 0.018 seconds
[0m23:57:00.917030 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:00.920516 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m23:57:00.930373 [debug] [MainThread]: SQL status: SELECT 1 in 0.007 seconds
[0m23:57:00.937079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '975f1676-cf32-4f4d-a8ae-e61d8c0699c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95813adea0>]}
[0m23:57:00.941968 [debug] [MainThread]: On master: ROLLBACK
[0m23:57:00.950408 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:00.953198 [debug] [MainThread]: On master: BEGIN
[0m23:57:00.956732 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m23:57:00.975380 [debug] [MainThread]: On master: COMMIT
[0m23:57:00.977767 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:00.981192 [debug] [MainThread]: On master: COMMIT
[0m23:57:00.986615 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:57:00.988952 [debug] [MainThread]: On master: Close
[0m23:57:01.002380 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m23:57:01.007814 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m23:57:01.012353 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m23:57:01.022987 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m23:57:01.073973 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m23:57:01.089049 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m23:57:01.227927 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m23:57:01.242489 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:57:01.244857 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m23:57:01.246991 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:57:01.265690 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m23:57:01.274320 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:57:01.278402 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m23:57:01.286909 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m23:57:01.309751 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:57:01.312008 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales" rename to "stg_sales__dbt_backup"
[0m23:57:01.315267 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:57:01.326259 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:57:01.329076 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m23:57:01.332190 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:57:01.395418 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m23:57:01.397779 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:57:01.400128 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m23:57:01.406505 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m23:57:01.433873 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m23:57:01.451997 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:57:01.457806 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m23:57:01.472397 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.003 seconds
[0m23:57:01.491321 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m23:57:01.504104 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '975f1676-cf32-4f4d-a8ae-e61d8c0699c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f957bf8a680>]}
[0m23:57:01.508137 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 0.49s]
[0m23:57:01.515959 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m23:57:01.520630 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m23:57:01.526203 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m23:57:01.533206 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m23:57:01.536685 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m23:57:01.576005 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m23:57:01.622031 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m23:57:01.697223 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m23:57:01.719080 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m23:57:01.725136 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m23:57:01.727832 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:57:01.749666 [debug] [Thread-1 (]: SQL status: BEGIN in 0.022 seconds
[0m23:57:01.760959 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m23:57:01.764065 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(sum(quantity * unit_price), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m23:57:01.777387 [debug] [Thread-1 (]: Postgres adapter: Postgres error: function round(double precision, integer) does not exist
LINE 23: round(sum(quantity * unit_price), 2) as total_sales,
         ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m23:57:01.784324 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: ROLLBACK
[0m23:57:01.790856 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m23:57:01.807689 [debug] [Thread-1 (]: Database Error in model sales_summary (models/sales_summary.sql)
  function round(double precision, integer) does not exist
  LINE 23: round(sum(quantity * unit_price), 2) as total_sales,
           ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/dbt_transform/models/sales_summary.sql
[0m23:57:01.820552 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '975f1676-cf32-4f4d-a8ae-e61d8c0699c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f957bea6440>]}
[0m23:57:01.828762 [error] [Thread-1 (]: 2 of 2 ERROR creating sql table model bankole_store.sales_summary .............. [[31mERROR[0m in 0.29s]
[0m23:57:01.838790 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m23:57:01.843177 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.sales_summary' to be skipped because of status 'error'.  Reason: Database Error in model sales_summary (models/sales_summary.sql)
  function round(double precision, integer) does not exist
  LINE 23: round(sum(quantity * unit_price), 2) as total_sales,
           ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/dbt_transform/models/sales_summary.sql.
[0m23:57:01.859928 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:01.863281 [debug] [MainThread]: On master: BEGIN
[0m23:57:01.866187 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:57:01.892987 [debug] [MainThread]: SQL status: BEGIN in 0.027 seconds
[0m23:57:01.895602 [debug] [MainThread]: On master: COMMIT
[0m23:57:01.898169 [debug] [MainThread]: Using postgres connection "master"
[0m23:57:01.902752 [debug] [MainThread]: On master: COMMIT
[0m23:57:01.906215 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:57:01.910529 [debug] [MainThread]: On master: Close
[0m23:57:01.913287 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:57:01.915579 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m23:57:01.926462 [info ] [MainThread]: 
[0m23:57:01.930008 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.33 seconds (1.33s).
[0m23:57:01.936121 [debug] [MainThread]: Command end result
[0m23:57:02.149133 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:57:02.181044 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:57:02.229650 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m23:57:02.232104 [info ] [MainThread]: 
[0m23:57:02.235968 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:57:02.256153 [info ] [MainThread]: 
[0m23:57:02.269698 [error] [MainThread]: [31mFailure in model sales_summary (models/sales_summary.sql)[0m
[0m23:57:02.276185 [error] [MainThread]:   Database Error in model sales_summary (models/sales_summary.sql)
  function round(double precision, integer) does not exist
  LINE 23: round(sum(quantity * unit_price), 2) as total_sales,
           ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/dbt_transform/models/sales_summary.sql
[0m23:57:02.279082 [info ] [MainThread]: 
[0m23:57:02.284071 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/sales_summary.sql
[0m23:57:02.293545 [info ] [MainThread]: 
[0m23:57:02.296736 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[0m23:57:02.301790 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.62135, "process_in_blocks": "0", "process_kernel_time": 0.851829, "process_mem_max_rss": "126744", "process_out_blocks": "1504", "process_user_time": 8.023042}
[0m23:57:02.310364 [debug] [MainThread]: Command `dbt run` failed at 23:57:02.309881 after 5.63 seconds
[0m23:57:02.312952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f958451a7a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9583d67970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95813d7a30>]}
[0m23:57:02.315790 [debug] [MainThread]: Flushing usage events
[0m23:57:03.346326 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:01:59.218286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5693c7e530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5692cacb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5692cacaf0>]}


============================== 00:01:59.227223 | 53085396-d5a6-4efb-8cba-d42881d3bb66 ==============================
[0m00:01:59.227223 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:01:59.230185 [debug] [MainThread]: running dbt with arguments {'log_path': '/dbt/logs', 'printer_width': '80', 'profiles_dir': '/dbt', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'warn_error': 'None', 'fail_fast': 'False', 'target_path': 'None', 'use_colors': 'True', 'static_parser': 'True', 'introspect': 'True', 'write_json': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'invocation_command': 'dbt run', 'version_check': 'True'}
[0m00:01:59.720978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '53085396-d5a6-4efb-8cba-d42881d3bb66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5692b740d0>]}
[0m00:01:59.877782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '53085396-d5a6-4efb-8cba-d42881d3bb66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5692b77a60>]}
[0m00:01:59.880480 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m00:02:00.088896 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:02:00.478165 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m00:02:00.481121 [debug] [MainThread]: Partial parsing: updated file: dbt_transform://models/sales_summary.sql
[0m00:02:01.662106 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m00:02:01.724006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '53085396-d5a6-4efb-8cba-d42881d3bb66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5690180130>]}
[0m00:02:02.145364 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m00:02:02.161280 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m00:02:02.215544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '53085396-d5a6-4efb-8cba-d42881d3bb66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56901556f0>]}
[0m00:02:02.218479 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m00:02:02.222262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53085396-d5a6-4efb-8cba-d42881d3bb66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5690f5bac0>]}
[0m00:02:02.233372 [info ] [MainThread]: 
[0m00:02:02.238238 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:02:02.241485 [info ] [MainThread]: 
[0m00:02:02.253140 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:02:02.277920 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m00:02:02.440362 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m00:02:02.441896 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m00:02:02.443467 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:02:02.463822 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.020 seconds
[0m00:02:02.468100 [debug] [ThreadPool]: On list_staging: Close
[0m00:02:02.474577 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m00:02:02.490472 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m00:02:02.492065 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m00:02:02.493796 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:02:02.508642 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m00:02:02.511353 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m00:02:02.516842 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m00:02:02.525119 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.006 seconds
[0m00:02:02.529386 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m00:02:02.531790 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m00:02:02.556668 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:02.560424 [debug] [MainThread]: On master: BEGIN
[0m00:02:02.563822 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:02:02.585100 [debug] [MainThread]: SQL status: BEGIN in 0.021 seconds
[0m00:02:02.590832 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:02.593565 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m00:02:02.608439 [debug] [MainThread]: SQL status: SELECT 1 in 0.012 seconds
[0m00:02:02.613321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53085396-d5a6-4efb-8cba-d42881d3bb66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5692bb9a50>]}
[0m00:02:02.616403 [debug] [MainThread]: On master: ROLLBACK
[0m00:02:02.626349 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:02.632066 [debug] [MainThread]: On master: BEGIN
[0m00:02:02.636043 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m00:02:02.641647 [debug] [MainThread]: On master: COMMIT
[0m00:02:02.646727 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:02.655209 [debug] [MainThread]: On master: COMMIT
[0m00:02:02.658995 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:02:02.661121 [debug] [MainThread]: On master: Close
[0m00:02:02.673588 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m00:02:02.676460 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m00:02:02.680173 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m00:02:02.688084 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m00:02:02.730529 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m00:02:02.841398 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m00:02:02.972551 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m00:02:02.984250 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m00:02:02.986034 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m00:02:02.987723 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:02:03.003339 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m00:02:03.010235 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m00:02:03.013066 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m00:02:03.019465 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m00:02:03.058362 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m00:02:03.060757 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales" rename to "stg_sales__dbt_backup"
[0m00:02:03.064217 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:02:03.079602 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m00:02:03.089677 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m00:02:03.092843 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:02:03.148325 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m00:02:03.150964 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m00:02:03.153594 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m00:02:03.158547 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m00:02:03.177686 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m00:02:03.198770 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m00:02:03.208842 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m00:02:03.221038 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m00:02:03.242481 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m00:02:03.251479 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '53085396-d5a6-4efb-8cba-d42881d3bb66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f568b29ec50>]}
[0m00:02:03.255305 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 0.57s]
[0m00:02:03.269342 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m00:02:03.278576 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m00:02:03.302365 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m00:02:03.305307 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m00:02:03.318664 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m00:02:03.336119 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m00:02:03.374278 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m00:02:03.476594 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m00:02:03.497121 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m00:02:03.499370 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m00:02:03.501388 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:02:03.533075 [debug] [Thread-1 (]: SQL status: BEGIN in 0.032 seconds
[0m00:02:03.543892 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m00:02:03.547579 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m00:02:06.190028 [debug] [Thread-1 (]: SQL status: SELECT 1716 in 2.641 seconds
[0m00:02:06.210903 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m00:02:06.212810 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary" rename to "sales_summary__dbt_backup"
[0m00:02:06.215284 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:02:06.226687 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m00:02:06.230216 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m00:02:06.233443 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:02:06.239158 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m00:02:06.241985 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m00:02:06.247563 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m00:02:06.255282 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m00:02:06.265304 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m00:02:06.273031 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m00:02:06.275800 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m00:02:06.281622 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m00:02:06.286276 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m00:02:06.288879 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '53085396-d5a6-4efb-8cba-d42881d3bb66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f568b29ec50>]}
[0m00:02:06.291964 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 1716[0m in 2.98s]
[0m00:02:06.300030 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m00:02:06.305473 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:06.307273 [debug] [MainThread]: On master: BEGIN
[0m00:02:06.309167 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:02:06.339793 [debug] [MainThread]: SQL status: BEGIN in 0.031 seconds
[0m00:02:06.342251 [debug] [MainThread]: On master: COMMIT
[0m00:02:06.344551 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:06.347032 [debug] [MainThread]: On master: COMMIT
[0m00:02:06.350186 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:02:06.352658 [debug] [MainThread]: On master: Close
[0m00:02:06.355849 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:02:06.358371 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m00:02:06.360370 [info ] [MainThread]: 
[0m00:02:06.362906 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.11 seconds (4.11s).
[0m00:02:06.368228 [debug] [MainThread]: Command end result
[0m00:02:06.478985 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m00:02:06.490237 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m00:02:06.519534 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m00:02:06.521676 [info ] [MainThread]: 
[0m00:02:06.527094 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:02:06.531852 [info ] [MainThread]: 
[0m00:02:06.535054 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m00:02:06.548903 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.528866, "process_in_blocks": "0", "process_kernel_time": 0.44704, "process_mem_max_rss": "126428", "process_out_blocks": "0", "process_user_time": 6.785075}
[0m00:02:06.557810 [debug] [MainThread]: Command `dbt run` succeeded at 00:02:06.557327 after 7.54 seconds
[0m00:02:06.560613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5693c7e530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f568b1d8280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5692b741f0>]}
[0m00:02:06.563237 [debug] [MainThread]: Flushing usage events
[0m00:02:07.492176 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:41:09.423771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5ea06800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5da33550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5da334f0>]}


============================== 20:41:09.525731 | 7b4eb4f7-a220-47f6-bbc7-cb26c616ea9f ==============================
[0m20:41:09.525731 [info ] [MainThread]: Running with dbt=1.10.13
[0m20:41:09.530258 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/dbt', 'write_json': 'True', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'warn_error': 'None', 'target_path': 'None', 'invocation_command': 'dbt run', 'static_parser': 'True', 'printer_width': '80', 'log_path': '/dbt/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'False'}
[0m20:41:12.596865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7b4eb4f7-a220-47f6-bbc7-cb26c616ea9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5e98c7f0>]}
[0m20:41:13.711910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7b4eb4f7-a220-47f6-bbc7-cb26c616ea9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5e270790>]}
[0m20:41:13.752872 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m20:41:14.967287 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m20:41:18.380081 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:41:18.404901 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:41:18.447896 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m20:41:19.176527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7b4eb4f7-a220-47f6-bbc7-cb26c616ea9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5c3bcf10>]}
[0m20:41:21.522630 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m20:41:21.573112 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m20:41:21.843591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7b4eb4f7-a220-47f6-bbc7-cb26c616ea9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5bf748b0>]}
[0m20:41:21.845678 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m20:41:21.848804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b4eb4f7-a220-47f6-bbc7-cb26c616ea9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5bf74910>]}
[0m20:41:22.169334 [info ] [MainThread]: 
[0m20:41:22.183838 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:41:22.185964 [info ] [MainThread]: 
[0m20:41:22.188773 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:41:22.220011 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m20:41:23.651439 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m20:41:23.654291 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m20:41:23.656586 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:41:23.772695 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.116 seconds
[0m20:41:23.781303 [debug] [ThreadPool]: On list_staging: Close
[0m20:41:23.843819 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m20:41:23.901669 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m20:41:23.918024 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m20:41:23.936928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:41:24.068107 [debug] [ThreadPool]: SQL status: BEGIN in 0.131 seconds
[0m20:41:24.134585 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m20:41:24.149878 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m20:41:24.361464 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.139 seconds
[0m20:41:24.403401 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m20:41:24.408965 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m20:41:24.607587 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:24.652801 [debug] [MainThread]: On master: BEGIN
[0m20:41:24.694066 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:41:24.774798 [debug] [MainThread]: SQL status: BEGIN in 0.081 seconds
[0m20:41:24.820306 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:24.852505 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m20:41:24.958887 [debug] [MainThread]: SQL status: SELECT 1 in 0.070 seconds
[0m20:41:25.019272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b4eb4f7-a220-47f6-bbc7-cb26c616ea9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5bf746a0>]}
[0m20:41:25.056006 [debug] [MainThread]: On master: ROLLBACK
[0m20:41:25.081254 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:25.083417 [debug] [MainThread]: On master: BEGIN
[0m20:41:25.097035 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:41:25.100444 [debug] [MainThread]: On master: COMMIT
[0m20:41:25.102470 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:25.104891 [debug] [MainThread]: On master: COMMIT
[0m20:41:25.118474 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:41:25.120726 [debug] [MainThread]: On master: Close
[0m20:41:25.209907 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m20:41:25.219427 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m20:41:25.298718 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m20:41:25.300623 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m20:41:25.419380 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m20:41:25.519773 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m20:41:26.238220 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m20:41:26.302318 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m20:41:26.333722 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m20:41:26.335699 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:41:26.380991 [debug] [Thread-1 (]: SQL status: BEGIN in 0.045 seconds
[0m20:41:26.411162 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m20:41:26.413463 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m20:41:26.490770 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.061 seconds
[0m20:41:26.584681 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m20:41:26.589681 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales" rename to "stg_sales__dbt_backup"
[0m20:41:26.597584 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:41:26.680573 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m20:41:26.711726 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m20:41:26.746973 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.024 seconds
[0m20:41:26.969249 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m20:41:26.984195 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m20:41:26.986893 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m20:41:26.998603 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m20:41:27.054607 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m20:41:27.083291 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m20:41:27.089969 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m20:41:27.124943 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.030 seconds
[0m20:41:27.156282 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m20:41:27.209095 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b4eb4f7-a220-47f6-bbc7-cb26c616ea9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5c3a96f0>]}
[0m20:41:27.212049 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 1.89s]
[0m20:41:27.215100 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m20:41:27.218060 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m20:41:27.225301 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m20:41:27.229037 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m20:41:27.231285 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m20:41:27.270451 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m20:41:27.298934 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m20:41:27.572953 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m20:41:27.600199 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m20:41:27.603089 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m20:41:27.604960 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:41:27.658418 [debug] [Thread-1 (]: SQL status: BEGIN in 0.053 seconds
[0m20:41:27.667964 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m20:41:27.677475 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m20:41:44.866140 [debug] [Thread-1 (]: SQL status: SELECT 1716 in 17.184 seconds
[0m20:41:44.906084 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m20:41:44.923398 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary" rename to "sales_summary__dbt_backup"
[0m20:41:44.926571 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:41:44.941702 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m20:41:44.951221 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m20:41:44.953918 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:41:44.958670 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m20:41:44.961178 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m20:41:44.964668 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m20:41:44.968495 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:41:44.978082 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m20:41:45.009001 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m20:41:45.015077 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m20:41:45.020508 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m20:41:45.025596 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m20:41:45.028274 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b4eb4f7-a220-47f6-bbc7-cb26c616ea9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5ed44d60>]}
[0m20:41:45.035250 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 1716[0m in 17.80s]
[0m20:41:45.039059 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m20:41:45.043159 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:45.045550 [debug] [MainThread]: On master: BEGIN
[0m20:41:45.049629 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:41:45.084844 [debug] [MainThread]: SQL status: BEGIN in 0.035 seconds
[0m20:41:45.086895 [debug] [MainThread]: On master: COMMIT
[0m20:41:45.088825 [debug] [MainThread]: Using postgres connection "master"
[0m20:41:45.090675 [debug] [MainThread]: On master: COMMIT
[0m20:41:45.092868 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:41:45.095294 [debug] [MainThread]: On master: Close
[0m20:41:45.097748 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:41:45.102607 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m20:41:45.104781 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m20:41:45.106884 [info ] [MainThread]: 
[0m20:41:45.113807 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 22.92 seconds (22.92s).
[0m20:41:45.118518 [debug] [MainThread]: Command end result
[0m20:41:45.292601 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m20:41:45.315512 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m20:41:45.367122 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m20:41:45.368901 [info ] [MainThread]: 
[0m20:41:45.371777 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:41:45.373958 [info ] [MainThread]: 
[0m20:41:45.376267 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m20:41:45.399059 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 37.437916, "process_in_blocks": "75696", "process_kernel_time": 3.752121, "process_mem_max_rss": "120400", "process_out_blocks": "1504", "process_user_time": 12.657021}
[0m20:41:45.401838 [debug] [MainThread]: Command `dbt run` succeeded at 20:41:45.401438 after 37.44 seconds
[0m20:41:45.403805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5ea06800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5e98c7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5e958820>]}
[0m20:41:45.405778 [debug] [MainThread]: Flushing usage events
[0m20:41:45.644945 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:54:48.824579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c60cbe800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c5fd07550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c5fd074f0>]}


============================== 21:54:48.880668 | e838c394-5504-407e-973d-b16f45e3f1c6 ==============================
[0m21:54:48.880668 [info ] [MainThread]: Running with dbt=1.10.13
[0m21:54:48.890985 [debug] [MainThread]: running dbt with arguments {'log_path': '/dbt/logs', 'log_cache_events': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'profiles_dir': '/dbt', 'warn_error': 'None', 'log_format': 'default', 'debug': 'False', 'use_colors': 'True', 'fail_fast': 'False', 'target_path': 'None', 'version_check': 'True', 'printer_width': '80', 'invocation_command': 'dbt run'}
[0m21:54:49.871478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e838c394-5504-407e-973d-b16f45e3f1c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c60c447f0>]}
[0m21:54:50.224015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e838c394-5504-407e-973d-b16f45e3f1c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c6052c790>]}
[0m21:54:50.227259 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m21:54:50.829217 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m21:54:51.945550 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:54:51.948105 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:54:51.980302 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m21:54:52.269705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e838c394-5504-407e-973d-b16f45e3f1c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c5e3d4f10>]}
[0m21:54:52.968628 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m21:54:53.003048 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m21:54:53.160659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e838c394-5504-407e-973d-b16f45e3f1c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c5df908b0>]}
[0m21:54:53.173749 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m21:54:53.184459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e838c394-5504-407e-973d-b16f45e3f1c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c5df90910>]}
[0m21:54:53.348049 [info ] [MainThread]: 
[0m21:54:53.366817 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:54:53.369818 [info ] [MainThread]: 
[0m21:54:53.372232 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:54:53.409814 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m21:54:53.775901 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m21:54:53.791159 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m21:54:53.795508 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:54:53.874478 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.079 seconds
[0m21:54:53.892062 [debug] [ThreadPool]: On list_staging: Close
[0m21:54:53.910587 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m21:54:53.957480 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m21:54:53.959582 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m21:54:53.961487 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:54:53.987007 [debug] [ThreadPool]: SQL status: BEGIN in 0.025 seconds
[0m21:54:53.989798 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m21:54:53.992194 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m21:54:54.009815 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.014 seconds
[0m21:54:54.017978 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m21:54:54.020378 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m21:54:54.067734 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:54.073720 [debug] [MainThread]: On master: BEGIN
[0m21:54:54.075616 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:54:54.099854 [debug] [MainThread]: SQL status: BEGIN in 0.024 seconds
[0m21:54:54.102223 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:54.104872 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m21:54:54.123921 [debug] [MainThread]: SQL status: SELECT 1 in 0.016 seconds
[0m21:54:54.131909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e838c394-5504-407e-973d-b16f45e3f1c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c5df93c10>]}
[0m21:54:54.135347 [debug] [MainThread]: On master: ROLLBACK
[0m21:54:54.137695 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:54.139961 [debug] [MainThread]: On master: BEGIN
[0m21:54:54.142973 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:54:54.145015 [debug] [MainThread]: On master: COMMIT
[0m21:54:54.147128 [debug] [MainThread]: Using postgres connection "master"
[0m21:54:54.150536 [debug] [MainThread]: On master: COMMIT
[0m21:54:54.152835 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:54:54.154903 [debug] [MainThread]: On master: Close
[0m21:54:54.188638 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m21:54:54.191208 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m21:54:54.207782 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m21:54:54.209749 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m21:54:54.300754 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m21:54:54.320363 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m21:54:54.553273 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m21:54:54.600077 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:54:54.602384 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m21:54:54.605262 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:54:54.643056 [debug] [Thread-1 (]: SQL status: BEGIN in 0.038 seconds
[0m21:54:54.645379 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:54:54.649567 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m21:54:54.673734 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.021 seconds
[0m21:54:54.700966 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:54:54.707058 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales" rename to "stg_sales__dbt_backup"
[0m21:54:54.710709 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:54:54.724126 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:54:54.726458 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m21:54:54.731704 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:54:54.799500 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m21:54:54.802162 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:54:54.805333 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m21:54:54.809419 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:54:54.850281 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m21:54:54.889623 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:54:54.899417 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m21:54:54.927667 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.023 seconds
[0m21:54:54.936972 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m21:54:54.951851 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e838c394-5504-407e-973d-b16f45e3f1c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c5e3b1630>]}
[0m21:54:54.959258 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 0.74s]
[0m21:54:54.963140 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m21:54:54.973463 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m21:54:54.975792 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m21:54:54.980018 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m21:54:54.987283 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m21:54:55.004624 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m21:54:55.030659 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m21:54:55.290525 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m21:54:55.345658 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:54:55.374860 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m21:54:55.387690 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:54:55.443322 [debug] [Thread-1 (]: SQL status: BEGIN in 0.055 seconds
[0m21:54:55.448140 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:54:55.451588 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m21:55:03.570465 [debug] [Thread-1 (]: SQL status: SELECT 1716 in 8.117 seconds
[0m21:55:03.625164 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:55:03.627566 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary" rename to "sales_summary__dbt_backup"
[0m21:55:03.642005 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:55:03.658008 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:55:03.664690 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m21:55:03.673905 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:55:03.681271 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m21:55:03.695494 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:55:03.708135 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m21:55:03.711796 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:55:03.729341 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m21:55:03.757415 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:55:03.759633 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m21:55:03.766385 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:55:03.773129 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m21:55:03.788355 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e838c394-5504-407e-973d-b16f45e3f1c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c61000d60>]}
[0m21:55:03.799991 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 1716[0m in 8.81s]
[0m21:55:03.811510 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m21:55:03.820975 [debug] [MainThread]: Using postgres connection "master"
[0m21:55:03.824054 [debug] [MainThread]: On master: BEGIN
[0m21:55:03.826292 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:55:03.857581 [debug] [MainThread]: SQL status: BEGIN in 0.031 seconds
[0m21:55:03.859836 [debug] [MainThread]: On master: COMMIT
[0m21:55:03.862194 [debug] [MainThread]: Using postgres connection "master"
[0m21:55:03.864225 [debug] [MainThread]: On master: COMMIT
[0m21:55:03.869627 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:55:03.871800 [debug] [MainThread]: On master: Close
[0m21:55:03.877801 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:55:03.879833 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m21:55:03.882334 [info ] [MainThread]: 
[0m21:55:03.896893 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 10.51 seconds (10.51s).
[0m21:55:03.906012 [debug] [MainThread]: Command end result
[0m21:55:04.073463 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m21:55:04.091225 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m21:55:04.147291 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m21:55:04.150311 [info ] [MainThread]: 
[0m21:55:04.152939 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:55:04.156535 [info ] [MainThread]: 
[0m21:55:04.159115 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m21:55:04.171300 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 15.794672, "process_in_blocks": "0", "process_kernel_time": 2.298788, "process_mem_max_rss": "120104", "process_out_blocks": "1504", "process_user_time": 10.807289}
[0m21:55:04.177745 [debug] [MainThread]: Command `dbt run` succeeded at 21:55:04.177409 after 15.80 seconds
[0m21:55:04.180401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c60cbe800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c60c447f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c60c0f160>]}
[0m21:55:04.186118 [debug] [MainThread]: Flushing usage events
[0m21:55:04.443394 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:40:09.806491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42ba47a890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b94bf640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b94bf5e0>]}


============================== 22:40:09.820293 | 2c6263b9-30c2-4995-b284-c5cb9f76bc2a ==============================
[0m22:40:09.820293 [info ] [MainThread]: Running with dbt=1.10.13
[0m22:40:09.827659 [debug] [MainThread]: running dbt with arguments {'log_path': '/dbt/logs', 'fail_fast': 'False', 'cache_selected_only': 'False', 'use_colors': 'True', 'profiles_dir': '/dbt', 'log_format': 'default', 'static_parser': 'True', 'no_print': 'None', 'write_json': 'True', 'indirect_selection': 'eager', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'log_cache_events': 'False', 'warn_error': 'None', 'debug': 'False', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'printer_width': '80', 'version_check': 'True', 'empty': 'False', 'use_experimental_parser': 'False'}
[0m22:40:10.192704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c6263b9-30c2-4995-b284-c5cb9f76bc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42bbfbabf0>]}
[0m22:40:10.331018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c6263b9-30c2-4995-b284-c5cb9f76bc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b979cf70>]}
[0m22:40:10.334483 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m22:40:10.577861 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m22:40:11.120811 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:40:11.122686 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:40:11.148728 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m22:40:11.443145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c6263b9-30c2-4995-b284-c5cb9f76bc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b77d4fa0>]}
[0m22:40:11.849472 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:40:11.870791 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:40:11.932520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c6263b9-30c2-4995-b284-c5cb9f76bc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b7390820>]}
[0m22:40:11.935490 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m22:40:11.946320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c6263b9-30c2-4995-b284-c5cb9f76bc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b7390880>]}
[0m22:40:12.033197 [info ] [MainThread]: 
[0m22:40:12.035614 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:40:12.038108 [info ] [MainThread]: 
[0m22:40:12.041164 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:40:12.059652 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m22:40:12.196238 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m22:40:12.198798 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m22:40:12.200567 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:40:12.216296 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.016 seconds
[0m22:40:12.219577 [debug] [ThreadPool]: On list_staging: Close
[0m22:40:12.224288 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m22:40:12.243060 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:40:12.245006 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m22:40:12.247045 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:40:12.261065 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m22:40:12.264841 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:40:12.267218 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m22:40:12.277086 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.008 seconds
[0m22:40:12.285624 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m22:40:12.291768 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m22:40:12.315299 [debug] [MainThread]: Using postgres connection "master"
[0m22:40:12.334343 [debug] [MainThread]: On master: BEGIN
[0m22:40:12.336758 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:40:12.354841 [debug] [MainThread]: SQL status: BEGIN in 0.018 seconds
[0m22:40:12.357477 [debug] [MainThread]: Using postgres connection "master"
[0m22:40:12.360816 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m22:40:12.381016 [debug] [MainThread]: SQL status: SELECT 1 in 0.014 seconds
[0m22:40:12.388576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c6263b9-30c2-4995-b284-c5cb9f76bc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b87c7460>]}
[0m22:40:12.394140 [debug] [MainThread]: On master: ROLLBACK
[0m22:40:12.396436 [debug] [MainThread]: Using postgres connection "master"
[0m22:40:12.402935 [debug] [MainThread]: On master: BEGIN
[0m22:40:12.418408 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m22:40:12.421314 [debug] [MainThread]: On master: COMMIT
[0m22:40:12.424511 [debug] [MainThread]: Using postgres connection "master"
[0m22:40:12.427735 [debug] [MainThread]: On master: COMMIT
[0m22:40:12.430796 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:40:12.455822 [debug] [MainThread]: On master: Close
[0m22:40:12.474644 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m22:40:12.477475 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m22:40:12.480892 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m22:40:12.485877 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m22:40:12.606199 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m22:40:12.631667 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m22:40:12.785641 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m22:40:12.877948 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:40:12.886116 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m22:40:12.890615 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:40:12.915762 [debug] [Thread-1 (]: SQL status: BEGIN in 0.025 seconds
[0m22:40:12.919324 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:40:12.925137 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m22:40:12.970682 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.040 seconds
[0m22:40:13.011605 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:40:13.014489 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales" rename to "stg_sales__dbt_backup"
[0m22:40:13.026042 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.004 seconds
[0m22:40:13.050130 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:40:13.052510 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m22:40:13.064675 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m22:40:13.136629 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m22:40:13.140573 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:40:13.142782 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m22:40:13.156839 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m22:40:13.179418 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m22:40:13.196810 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:40:13.199191 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m22:40:13.206185 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.005 seconds
[0m22:40:13.217318 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m22:40:13.224320 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c6263b9-30c2-4995-b284-c5cb9f76bc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b77c15d0>]}
[0m22:40:13.228247 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 0.74s]
[0m22:40:13.237693 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m22:40:13.241419 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m22:40:13.244162 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m22:40:13.248404 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m22:40:13.256425 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m22:40:13.277745 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m22:40:13.292208 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m22:40:13.370872 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m22:40:13.384411 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:40:13.386677 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m22:40:13.388955 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:40:13.404130 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m22:40:13.407962 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:40:13.410517 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m22:40:17.096427 [debug] [Thread-1 (]: SQL status: SELECT 1716 in 3.683 seconds
[0m22:40:17.111769 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:40:17.113663 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary" rename to "sales_summary__dbt_backup"
[0m22:40:17.116324 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:40:17.124299 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:40:17.126102 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m22:40:17.128578 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:40:17.132262 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m22:40:17.134560 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:40:17.136400 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m22:40:17.139895 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m22:40:17.146816 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m22:40:17.154677 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:40:17.156694 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m22:40:17.161842 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m22:40:17.166283 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m22:40:17.168751 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c6263b9-30c2-4995-b284-c5cb9f76bc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42ba7e5b40>]}
[0m22:40:17.171529 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 1716[0m in 3.92s]
[0m22:40:17.179193 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m22:40:17.183692 [debug] [MainThread]: Using postgres connection "master"
[0m22:40:17.185988 [debug] [MainThread]: On master: BEGIN
[0m22:40:17.187612 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:40:17.205616 [debug] [MainThread]: SQL status: BEGIN in 0.018 seconds
[0m22:40:17.214559 [debug] [MainThread]: On master: COMMIT
[0m22:40:17.255020 [debug] [MainThread]: Using postgres connection "master"
[0m22:40:17.256964 [debug] [MainThread]: On master: COMMIT
[0m22:40:17.259373 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:40:17.261426 [debug] [MainThread]: On master: Close
[0m22:40:17.263585 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:40:17.273373 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m22:40:17.275774 [info ] [MainThread]: 
[0m22:40:17.280782 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 5.24 seconds (5.24s).
[0m22:40:17.290831 [debug] [MainThread]: Command end result
[0m22:40:17.596373 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:40:17.608140 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:40:17.658047 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m22:40:17.660987 [info ] [MainThread]: 
[0m22:40:17.673436 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:40:17.676758 [info ] [MainThread]: 
[0m22:40:17.710330 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m22:40:17.725650 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.1252575, "process_in_blocks": "0", "process_kernel_time": 0.622405, "process_mem_max_rss": "120428", "process_out_blocks": "1504", "process_user_time": 6.444908}
[0m22:40:17.730124 [debug] [MainThread]: Command `dbt run` succeeded at 22:40:17.729025 after 8.14 seconds
[0m22:40:17.745792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42ba47a890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b87757b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42ba3cd750>]}
[0m22:40:17.747942 [debug] [MainThread]: Flushing usage events
[0m22:40:18.790929 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:21:14.388828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb17c782830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb17b4ff580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb17b4ff520>]}


============================== 23:21:14.440243 | c12982af-106c-4a66-bdc1-10b66cbb474c ==============================
[0m23:21:14.440243 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:21:14.467671 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'introspect': 'True', 'quiet': 'False', 'printer_width': '80', 'log_format': 'default', 'fail_fast': 'False', 'log_cache_events': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'log_path': '/dbt/logs', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'empty': 'False', 'use_colors': 'True', 'cache_selected_only': 'False', 'partial_parse': 'True', 'no_print': 'None', 'write_json': 'True', 'profiles_dir': '/dbt', 'debug': 'False', 'indirect_selection': 'eager'}
[0m23:21:16.223910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c12982af-106c-4a66-bdc1-10b66cbb474c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb17bd542b0>]}
[0m23:21:16.840449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c12982af-106c-4a66-bdc1-10b66cbb474c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb17b356290>]}
[0m23:21:16.850761 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:21:17.473305 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:21:19.430561 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:21:19.432581 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:21:19.467962 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m23:21:19.905337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c12982af-106c-4a66-bdc1-10b66cbb474c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb179bb0f70>]}
[0m23:21:21.048549 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:21:21.078417 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:21:21.271298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c12982af-106c-4a66-bdc1-10b66cbb474c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb179768820>]}
[0m23:21:21.317528 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m23:21:21.333304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c12982af-106c-4a66-bdc1-10b66cbb474c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb179768880>]}
[0m23:21:21.506689 [info ] [MainThread]: 
[0m23:21:21.514418 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:21:21.546422 [info ] [MainThread]: 
[0m23:21:21.558829 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:21:21.597666 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m23:21:21.968587 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m23:21:22.011908 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:21:22.050267 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:21:22.214602 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.164 seconds
[0m23:21:22.261069 [debug] [ThreadPool]: On list_staging: Close
[0m23:21:22.277127 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now create_staging_bankole_store)
[0m23:21:22.287114 [debug] [ThreadPool]: Creating schema "database: "staging"
schema: "bankole_store"
"
[0m23:21:22.364346 [debug] [ThreadPool]: Using postgres connection "create_staging_bankole_store"
[0m23:21:22.376631 [debug] [ThreadPool]: On create_staging_bankole_store: BEGIN
[0m23:21:22.391157 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:21:22.460000 [debug] [ThreadPool]: SQL status: BEGIN in 0.069 seconds
[0m23:21:22.484381 [debug] [ThreadPool]: Using postgres connection "create_staging_bankole_store"
[0m23:21:22.492223 [debug] [ThreadPool]: On create_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "create_staging_bankole_store"} */
create schema if not exists "bankole_store"
[0m23:21:22.501324 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.006 seconds
[0m23:21:22.511295 [debug] [ThreadPool]: On create_staging_bankole_store: COMMIT
[0m23:21:22.513416 [debug] [ThreadPool]: Using postgres connection "create_staging_bankole_store"
[0m23:21:22.515393 [debug] [ThreadPool]: On create_staging_bankole_store: COMMIT
[0m23:21:22.530718 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m23:21:22.546912 [debug] [ThreadPool]: On create_staging_bankole_store: Close
[0m23:21:22.590177 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m23:21:22.622996 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:21:22.625182 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m23:21:22.638358 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:21:22.725085 [debug] [ThreadPool]: SQL status: BEGIN in 0.087 seconds
[0m23:21:22.754184 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:21:22.769429 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m23:21:22.784709 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.013 seconds
[0m23:21:22.788563 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m23:21:22.817590 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m23:21:22.851366 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:22.877139 [debug] [MainThread]: On master: BEGIN
[0m23:21:22.882913 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:21:22.911689 [debug] [MainThread]: SQL status: BEGIN in 0.029 seconds
[0m23:21:22.915692 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:22.918017 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m23:21:22.979261 [debug] [MainThread]: SQL status: SELECT 0 in 0.008 seconds
[0m23:21:22.992552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c12982af-106c-4a66-bdc1-10b66cbb474c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb179fdbcd0>]}
[0m23:21:23.006095 [debug] [MainThread]: On master: ROLLBACK
[0m23:21:23.030559 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:23.039821 [debug] [MainThread]: On master: BEGIN
[0m23:21:23.047780 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m23:21:23.064447 [debug] [MainThread]: On master: COMMIT
[0m23:21:23.076667 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:23.091610 [debug] [MainThread]: On master: COMMIT
[0m23:21:23.105519 [debug] [MainThread]: SQL status: COMMIT in 0.011 seconds
[0m23:21:23.108223 [debug] [MainThread]: On master: Close
[0m23:21:23.157081 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m23:21:23.160898 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m23:21:23.169338 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m23:21:23.177837 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m23:21:23.236230 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m23:21:23.328282 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m23:21:23.603018 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m23:21:23.649480 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:21:23.651551 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m23:21:23.661770 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:21:23.704752 [debug] [Thread-1 (]: SQL status: BEGIN in 0.043 seconds
[0m23:21:23.706864 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:21:23.709378 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m23:21:23.733674 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "public.bankole_store" does not exist
LINE 11:     select * from "staging"."public"."bankole_store"
                           ^

[0m23:21:23.738251 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: ROLLBACK
[0m23:21:23.741121 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m23:21:23.762572 [debug] [Thread-1 (]: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:21:23.775481 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c12982af-106c-4a66-bdc1-10b66cbb474c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb179bd9ba0>]}
[0m23:21:23.790671 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model bankole_store.stg_sales ................... [[31mERROR[0m in 0.60s]
[0m23:21:23.794068 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m23:21:23.796880 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.stg_sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql.
[0m23:21:23.808683 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m23:21:23.810924 [info ] [Thread-1 (]: 2 of 2 SKIP relation bankole_store.sales_summary ............................... [[33mSKIP[0m]
[0m23:21:23.820484 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m23:21:23.825341 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:23.827466 [debug] [MainThread]: On master: BEGIN
[0m23:21:23.831006 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:21:23.860370 [debug] [MainThread]: SQL status: BEGIN in 0.029 seconds
[0m23:21:23.865246 [debug] [MainThread]: On master: COMMIT
[0m23:21:23.875007 [debug] [MainThread]: Using postgres connection "master"
[0m23:21:23.878086 [debug] [MainThread]: On master: COMMIT
[0m23:21:23.880442 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:21:23.891317 [debug] [MainThread]: On master: Close
[0m23:21:23.905066 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:21:23.906752 [debug] [MainThread]: Connection 'create_staging_bankole_store' was properly closed.
[0m23:21:23.922245 [debug] [MainThread]: Connection 'model.dbt_transform.stg_sales' was properly closed.
[0m23:21:23.936387 [info ] [MainThread]: 
[0m23:21:23.944330 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 2.38 seconds (2.38s).
[0m23:21:23.955211 [debug] [MainThread]: Command end result
[0m23:21:24.710489 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:21:24.796893 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:21:24.877687 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m23:21:24.891515 [info ] [MainThread]: 
[0m23:21:24.905467 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:21:24.907934 [info ] [MainThread]: 
[0m23:21:24.911190 [error] [MainThread]: [31mFailure in model stg_sales (models/stg_sales.sql)[0m
[0m23:21:24.925087 [error] [MainThread]:   Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:21:24.927530 [info ] [MainThread]: 
[0m23:21:24.940087 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/stg_sales.sql
[0m23:21:24.951080 [info ] [MainThread]: 
[0m23:21:25.013438 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m23:21:25.048522 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 11.3343935, "process_in_blocks": "0", "process_kernel_time": 3.238476, "process_mem_max_rss": "121404", "process_out_blocks": "1504", "process_user_time": 13.665309}
[0m23:21:25.078153 [debug] [MainThread]: Command `dbt run` failed at 23:21:25.077731 after 11.36 seconds
[0m23:21:25.091591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb17c782830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb17c40a9e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb17b7de470>]}
[0m23:21:25.093675 [debug] [MainThread]: Flushing usage events
[0m23:21:27.292371 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:23:54.558103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3866c665f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3865c78c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3865c78bb0>]}


============================== 23:23:54.566720 | 7beecd13-fc62-4391-9e3c-763927a6db82 ==============================
[0m23:23:54.566720 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:23:54.569536 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'use_colors': 'True', 'static_parser': 'True', 'write_json': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'cache_selected_only': 'False', 'log_format': 'default', 'profiles_dir': '/dbt', 'log_path': '/dbt/logs', 'partial_parse': 'True', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'target_path': 'None', 'version_check': 'True', 'introspect': 'True', 'debug': 'False'}
[0m23:23:55.222576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7beecd13-fc62-4391-9e3c-763927a6db82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38684f01f0>]}
[0m23:23:55.683525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7beecd13-fc62-4391-9e3c-763927a6db82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3865bc6740>]}
[0m23:23:55.693037 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:23:56.179595 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:23:57.187216 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:23:57.189234 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:23:57.222956 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m23:23:57.482844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7beecd13-fc62-4391-9e3c-763927a6db82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3863fb4d60>]}
[0m23:23:57.995191 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:23:58.009036 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:23:58.151348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7beecd13-fc62-4391-9e3c-763927a6db82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3863fb4910>]}
[0m23:23:58.167433 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m23:23:58.180049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7beecd13-fc62-4391-9e3c-763927a6db82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3863fb4940>]}
[0m23:23:58.197574 [info ] [MainThread]: 
[0m23:23:58.203392 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:23:58.214651 [info ] [MainThread]: 
[0m23:23:58.233826 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:23:58.266482 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m23:23:58.596441 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m23:23:58.598496 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:23:58.600971 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:23:58.645561 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.044 seconds
[0m23:23:58.652282 [debug] [ThreadPool]: On list_staging: Close
[0m23:23:58.663304 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m23:23:58.681369 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:23:58.684364 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m23:23:58.686058 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:23:58.703035 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m23:23:58.705072 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:23:58.707088 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m23:23:58.715547 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m23:23:58.727314 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m23:23:58.735931 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m23:23:58.755526 [debug] [MainThread]: Using postgres connection "master"
[0m23:23:58.773011 [debug] [MainThread]: On master: BEGIN
[0m23:23:58.777473 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:23:58.799333 [debug] [MainThread]: SQL status: BEGIN in 0.022 seconds
[0m23:23:58.802475 [debug] [MainThread]: Using postgres connection "master"
[0m23:23:58.804816 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m23:23:58.825502 [debug] [MainThread]: SQL status: SELECT 0 in 0.011 seconds
[0m23:23:58.834242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7beecd13-fc62-4391-9e3c-763927a6db82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386877cfd0>]}
[0m23:23:58.836805 [debug] [MainThread]: On master: ROLLBACK
[0m23:23:58.839111 [debug] [MainThread]: Using postgres connection "master"
[0m23:23:58.842270 [debug] [MainThread]: On master: BEGIN
[0m23:23:58.844793 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m23:23:58.846877 [debug] [MainThread]: On master: COMMIT
[0m23:23:58.848893 [debug] [MainThread]: Using postgres connection "master"
[0m23:23:58.850925 [debug] [MainThread]: On master: COMMIT
[0m23:23:58.853585 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:23:58.855655 [debug] [MainThread]: On master: Close
[0m23:23:58.871605 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m23:23:58.874735 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m23:23:58.877254 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m23:23:58.879892 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m23:23:58.910827 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m23:23:58.941331 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m23:23:59.106026 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m23:23:59.163947 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:23:59.166181 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m23:23:59.168657 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:23:59.215013 [debug] [Thread-1 (]: SQL status: BEGIN in 0.046 seconds
[0m23:23:59.219891 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:23:59.226513 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m23:23:59.232556 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "public.bankole_store" does not exist
LINE 11:     select * from "staging"."public"."bankole_store"
                           ^

[0m23:23:59.234830 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: ROLLBACK
[0m23:23:59.238107 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m23:23:59.247936 [debug] [Thread-1 (]: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:23:59.255367 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7beecd13-fc62-4391-9e3c-763927a6db82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3863f3dba0>]}
[0m23:23:59.259733 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model bankole_store.stg_sales ................... [[31mERROR[0m in 0.37s]
[0m23:23:59.262978 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m23:23:59.265915 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.stg_sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql.
[0m23:23:59.270501 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m23:23:59.273069 [info ] [Thread-1 (]: 2 of 2 SKIP relation bankole_store.sales_summary ............................... [[33mSKIP[0m]
[0m23:23:59.276087 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m23:23:59.280405 [debug] [MainThread]: Using postgres connection "master"
[0m23:23:59.282526 [debug] [MainThread]: On master: BEGIN
[0m23:23:59.284376 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:23:59.303626 [debug] [MainThread]: SQL status: BEGIN in 0.019 seconds
[0m23:23:59.306008 [debug] [MainThread]: On master: COMMIT
[0m23:23:59.308039 [debug] [MainThread]: Using postgres connection "master"
[0m23:23:59.310246 [debug] [MainThread]: On master: COMMIT
[0m23:23:59.313195 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:23:59.315550 [debug] [MainThread]: On master: Close
[0m23:23:59.327876 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:23:59.334984 [debug] [MainThread]: Connection 'model.dbt_transform.stg_sales' was properly closed.
[0m23:23:59.337918 [info ] [MainThread]: 
[0m23:23:59.340327 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.11 seconds (1.11s).
[0m23:23:59.343725 [debug] [MainThread]: Command end result
[0m23:23:59.461236 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:23:59.475561 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:23:59.511173 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m23:23:59.517951 [info ] [MainThread]: 
[0m23:23:59.528205 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:23:59.533272 [info ] [MainThread]: 
[0m23:23:59.546410 [error] [MainThread]: [31mFailure in model stg_sales (models/stg_sales.sql)[0m
[0m23:23:59.558893 [error] [MainThread]:   Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:23:59.562016 [info ] [MainThread]: 
[0m23:23:59.568949 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/stg_sales.sql
[0m23:23:59.574945 [info ] [MainThread]: 
[0m23:23:59.578712 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m23:23:59.584887 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.470327, "process_in_blocks": "0", "process_kernel_time": 0.989211, "process_mem_max_rss": "119556", "process_out_blocks": "0", "process_user_time": 8.611342}
[0m23:23:59.596038 [debug] [MainThread]: Command `dbt run` failed at 23:23:59.595637 after 5.48 seconds
[0m23:23:59.599471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3866c665f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f386a2ebf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3863ffd780>]}
[0m23:23:59.603628 [debug] [MainThread]: Flushing usage events
[0m23:24:00.751444 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:25:53.843857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55832ee890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f558231f640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f558231f5e0>]}


============================== 23:25:53.869581 | b7a7884f-6eae-4570-bd4c-3dc7ee9e3507 ==============================
[0m23:25:53.869581 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:25:53.872854 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'write_json': 'True', 'printer_width': '80', 'introspect': 'True', 'static_parser': 'True', 'profiles_dir': '/dbt', 'warn_error': 'None', 'no_print': 'None', 'invocation_command': 'dbt run', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'use_colors': 'True', 'log_path': '/dbt/logs', 'indirect_selection': 'eager', 'target_path': 'None', 'empty': 'False', 'fail_fast': 'False', 'log_cache_events': 'False'}
[0m23:25:54.586983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b7a7884f-6eae-4570-bd4c-3dc7ee9e3507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55819597b0>]}
[0m23:25:55.064723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b7a7884f-6eae-4570-bd4c-3dc7ee9e3507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5582600f70>]}
[0m23:25:55.099335 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:25:55.639278 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:25:56.739298 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:25:56.742054 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:25:56.768390 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m23:25:57.072124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b7a7884f-6eae-4570-bd4c-3dc7ee9e3507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55809bcfd0>]}
[0m23:25:57.824154 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:25:57.848976 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:25:57.983680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b7a7884f-6eae-4570-bd4c-3dc7ee9e3507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5580570820>]}
[0m23:25:57.991566 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m23:25:57.997376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7a7884f-6eae-4570-bd4c-3dc7ee9e3507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5580570880>]}
[0m23:25:58.255077 [info ] [MainThread]: 
[0m23:25:58.261346 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:25:58.264625 [info ] [MainThread]: 
[0m23:25:58.267928 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:25:58.334985 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m23:25:58.623672 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m23:25:58.635587 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:25:58.642381 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:25:58.678048 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.033 seconds
[0m23:25:58.685896 [debug] [ThreadPool]: On list_staging: Close
[0m23:25:58.693341 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m23:25:58.732303 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:25:58.737380 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m23:25:58.743329 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:25:58.778394 [debug] [ThreadPool]: SQL status: BEGIN in 0.035 seconds
[0m23:25:58.782029 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:25:58.785506 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m23:25:58.823176 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.035 seconds
[0m23:25:58.831166 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m23:25:58.840296 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m23:25:58.864720 [debug] [MainThread]: Using postgres connection "master"
[0m23:25:58.868311 [debug] [MainThread]: On master: BEGIN
[0m23:25:58.870220 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:25:58.891307 [debug] [MainThread]: SQL status: BEGIN in 0.021 seconds
[0m23:25:58.893977 [debug] [MainThread]: Using postgres connection "master"
[0m23:25:58.896863 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m23:25:58.914514 [debug] [MainThread]: SQL status: SELECT 0 in 0.012 seconds
[0m23:25:58.922304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7a7884f-6eae-4570-bd4c-3dc7ee9e3507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5584db4520>]}
[0m23:25:58.930946 [debug] [MainThread]: On master: ROLLBACK
[0m23:25:58.941741 [debug] [MainThread]: Using postgres connection "master"
[0m23:25:58.965414 [debug] [MainThread]: On master: BEGIN
[0m23:25:58.974821 [debug] [MainThread]: SQL status: BEGIN in 0.004 seconds
[0m23:25:58.978529 [debug] [MainThread]: On master: COMMIT
[0m23:25:58.992203 [debug] [MainThread]: Using postgres connection "master"
[0m23:25:58.995695 [debug] [MainThread]: On master: COMMIT
[0m23:25:59.003628 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:25:59.010849 [debug] [MainThread]: On master: Close
[0m23:25:59.050066 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m23:25:59.072020 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m23:25:59.089478 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m23:25:59.101275 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m23:25:59.170298 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m23:25:59.185834 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m23:25:59.392103 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m23:25:59.411502 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:25:59.414055 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m23:25:59.416850 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:25:59.445492 [debug] [Thread-1 (]: SQL status: BEGIN in 0.029 seconds
[0m23:25:59.448515 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:25:59.452400 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m23:25:59.469005 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "public.bankole_store" does not exist
LINE 11:     select * from "staging"."public"."bankole_store"
                           ^

[0m23:25:59.487258 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: ROLLBACK
[0m23:25:59.504078 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m23:25:59.526853 [debug] [Thread-1 (]: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:25:59.540842 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7a7884f-6eae-4570-bd4c-3dc7ee9e3507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5583655b40>]}
[0m23:25:59.552059 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model bankole_store.stg_sales ................... [[31mERROR[0m in 0.44s]
[0m23:25:59.568960 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m23:25:59.586409 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.stg_sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql.
[0m23:25:59.596151 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m23:25:59.610556 [info ] [Thread-1 (]: 2 of 2 SKIP relation bankole_store.sales_summary ............................... [[33mSKIP[0m]
[0m23:25:59.613424 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m23:25:59.617561 [debug] [MainThread]: Using postgres connection "master"
[0m23:25:59.620292 [debug] [MainThread]: On master: BEGIN
[0m23:25:59.622216 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:25:59.671624 [debug] [MainThread]: SQL status: BEGIN in 0.049 seconds
[0m23:25:59.673745 [debug] [MainThread]: On master: COMMIT
[0m23:25:59.675808 [debug] [MainThread]: Using postgres connection "master"
[0m23:25:59.677960 [debug] [MainThread]: On master: COMMIT
[0m23:25:59.683067 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:25:59.686318 [debug] [MainThread]: On master: Close
[0m23:25:59.691698 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:25:59.704333 [debug] [MainThread]: Connection 'model.dbt_transform.stg_sales' was properly closed.
[0m23:25:59.709625 [info ] [MainThread]: 
[0m23:25:59.726368 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.44 seconds (1.44s).
[0m23:25:59.735909 [debug] [MainThread]: Command end result
[0m23:25:59.943226 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:25:59.972872 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:26:00.070550 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m23:26:00.073265 [info ] [MainThread]: 
[0m23:26:00.076598 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:26:00.128475 [info ] [MainThread]: 
[0m23:26:00.137376 [error] [MainThread]: [31mFailure in model stg_sales (models/stg_sales.sql)[0m
[0m23:26:00.144811 [error] [MainThread]:   Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:26:00.156396 [info ] [MainThread]: 
[0m23:26:00.165690 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/stg_sales.sql
[0m23:26:00.170771 [info ] [MainThread]: 
[0m23:26:00.183592 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m23:26:00.188446 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.6454754, "process_in_blocks": "0", "process_kernel_time": 1.23304, "process_mem_max_rss": "119004", "process_out_blocks": "1504", "process_user_time": 8.386715}
[0m23:26:00.204338 [debug] [MainThread]: Command `dbt run` failed at 23:26:00.203947 after 6.66 seconds
[0m23:26:00.215234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55832ee890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55819597b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5583241750>]}
[0m23:26:00.219704 [debug] [MainThread]: Flushing usage events
[0m23:26:01.631242 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:37:05.350162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f725c2a6500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f725b2d2fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f725b2d2f80>]}


============================== 23:37:05.391461 | d300e90d-a98c-49b8-8e36-84091770be18 ==============================
[0m23:37:05.391461 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:37:05.393679 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'log_path': '/dbt/logs', 'use_experimental_parser': 'False', 'printer_width': '80', 'introspect': 'True', 'quiet': 'False', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'partial_parse': 'True', 'log_format': 'default', 'empty': 'False', 'no_print': 'None', 'profiles_dir': '/dbt', 'debug': 'False', 'version_check': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'fail_fast': 'False', 'write_json': 'True', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False'}
[0m23:37:06.118485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd300e90d-a98c-49b8-8e36-84091770be18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f725c1f5ed0>]}
[0m23:37:06.387964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd300e90d-a98c-49b8-8e36-84091770be18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f725b196050>]}
[0m23:37:06.390903 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:37:06.715522 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:37:07.567446 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:37:07.579321 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:37:07.621090 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m23:37:07.939911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd300e90d-a98c-49b8-8e36-84091770be18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72595d4c70>]}
[0m23:37:08.460262 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:37:08.482600 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:37:08.552778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd300e90d-a98c-49b8-8e36-84091770be18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72595d4b50>]}
[0m23:37:08.555154 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m23:37:08.559614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd300e90d-a98c-49b8-8e36-84091770be18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72595d73a0>]}
[0m23:37:08.569500 [info ] [MainThread]: 
[0m23:37:08.573852 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:37:08.579117 [info ] [MainThread]: 
[0m23:37:08.592252 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:37:08.623665 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m23:37:08.928014 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m23:37:08.931714 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:37:08.933807 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:37:08.976056 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.042 seconds
[0m23:37:08.986027 [debug] [ThreadPool]: On list_staging: Close
[0m23:37:09.004276 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m23:37:09.052107 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:37:09.061294 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m23:37:09.063229 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:37:09.102977 [debug] [ThreadPool]: SQL status: BEGIN in 0.040 seconds
[0m23:37:09.106837 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:37:09.110762 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m23:37:09.126746 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m23:37:09.130718 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m23:37:09.134588 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m23:37:09.168911 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:09.188215 [debug] [MainThread]: On master: BEGIN
[0m23:37:09.190816 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:37:09.209186 [debug] [MainThread]: SQL status: BEGIN in 0.018 seconds
[0m23:37:09.212166 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:09.214501 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m23:37:09.227230 [debug] [MainThread]: SQL status: SELECT 0 in 0.010 seconds
[0m23:37:09.234053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd300e90d-a98c-49b8-8e36-84091770be18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72595b4f40>]}
[0m23:37:09.237429 [debug] [MainThread]: On master: ROLLBACK
[0m23:37:09.246720 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:09.253603 [debug] [MainThread]: On master: BEGIN
[0m23:37:09.260633 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m23:37:09.262653 [debug] [MainThread]: On master: COMMIT
[0m23:37:09.269333 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:09.271816 [debug] [MainThread]: On master: COMMIT
[0m23:37:09.274346 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:37:09.276308 [debug] [MainThread]: On master: Close
[0m23:37:09.287969 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m23:37:09.290498 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m23:37:09.294524 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m23:37:09.300733 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m23:37:09.338873 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m23:37:09.367886 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m23:37:09.532182 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m23:37:09.555301 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:37:09.562534 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m23:37:09.564329 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:37:09.583882 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m23:37:09.592726 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:37:09.595684 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m23:37:09.608363 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "public.bankole_store" does not exist
LINE 11:     select * from "staging"."public"."bankole_store"
                           ^

[0m23:37:09.610634 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: ROLLBACK
[0m23:37:09.623845 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m23:37:09.634501 [debug] [Thread-1 (]: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:37:09.642516 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd300e90d-a98c-49b8-8e36-84091770be18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f725c5e5de0>]}
[0m23:37:09.645296 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model bankole_store.stg_sales ................... [[31mERROR[0m in 0.34s]
[0m23:37:09.650729 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m23:37:09.673637 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.stg_sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql.
[0m23:37:09.679996 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m23:37:09.685818 [info ] [Thread-1 (]: 2 of 2 SKIP relation bankole_store.sales_summary ............................... [[33mSKIP[0m]
[0m23:37:09.689752 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m23:37:09.693408 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:09.713380 [debug] [MainThread]: On master: BEGIN
[0m23:37:09.716791 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:37:09.742919 [debug] [MainThread]: SQL status: BEGIN in 0.026 seconds
[0m23:37:09.745285 [debug] [MainThread]: On master: COMMIT
[0m23:37:09.747279 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:09.749158 [debug] [MainThread]: On master: COMMIT
[0m23:37:09.751594 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:37:09.753534 [debug] [MainThread]: On master: Close
[0m23:37:09.755927 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:37:09.786386 [debug] [MainThread]: Connection 'model.dbt_transform.stg_sales' was properly closed.
[0m23:37:09.793525 [info ] [MainThread]: 
[0m23:37:09.796350 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.20 seconds (1.20s).
[0m23:37:09.809422 [debug] [MainThread]: Command end result
[0m23:37:10.230403 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:37:10.291355 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:37:10.373418 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m23:37:10.378055 [info ] [MainThread]: 
[0m23:37:10.401322 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:37:10.414846 [info ] [MainThread]: 
[0m23:37:10.433733 [error] [MainThread]: [31mFailure in model stg_sales (models/stg_sales.sql)[0m
[0m23:37:10.470696 [error] [MainThread]:   Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:37:10.479894 [info ] [MainThread]: 
[0m23:37:10.483407 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/stg_sales.sql
[0m23:37:10.497700 [info ] [MainThread]: 
[0m23:37:10.502349 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m23:37:10.516539 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.5175877, "process_in_blocks": "0", "process_kernel_time": 0.997153, "process_mem_max_rss": "119352", "process_out_blocks": "0", "process_user_time": 7.432389}
[0m23:37:10.518935 [debug] [MainThread]: Command `dbt run` failed at 23:37:10.518573 after 5.52 seconds
[0m23:37:10.520685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f725c2a6500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f725ce80790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f725b196050>]}
[0m23:37:10.531582 [debug] [MainThread]: Flushing usage events
[0m23:37:11.627307 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:43:56.810351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6740ee2590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f673fc50be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f673fc50b80>]}


============================== 23:43:56.823811 | 3bc61358-bc04-4a19-949e-ffef8c801804 ==============================
[0m23:43:56.823811 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:43:56.827035 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'warn_error': 'None', 'no_print': 'None', 'use_experimental_parser': 'False', 'profiles_dir': '/dbt', 'partial_parse': 'True', 'cache_selected_only': 'False', 'quiet': 'False', 'version_check': 'True', 'write_json': 'True', 'use_colors': 'True', 'target_path': 'None', 'log_format': 'default', 'printer_width': '80', 'log_cache_events': 'False', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'indirect_selection': 'eager', 'empty': 'False', 'invocation_command': 'dbt run', 'log_path': '/dbt/logs', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m23:43:57.376347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3bc61358-bc04-4a19-949e-ffef8c801804', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6740a370d0>]}
[0m23:43:57.600138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3bc61358-bc04-4a19-949e-ffef8c801804', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67403f6bc0>]}
[0m23:43:57.603339 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:43:57.955381 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:43:58.547418 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m23:43:58.551065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3bc61358-bc04-4a19-949e-ffef8c801804', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f674046c370>]}
[0m23:44:07.936463 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m23:44:08.031587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3bc61358-bc04-4a19-949e-ffef8c801804', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f673cd968c0>]}
[0m23:44:08.659419 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:44:08.691268 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:44:08.836265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3bc61358-bc04-4a19-949e-ffef8c801804', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f673cd502e0>]}
[0m23:44:08.839064 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m23:44:08.841206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3bc61358-bc04-4a19-949e-ffef8c801804', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f673cd50310>]}
[0m23:44:08.856641 [info ] [MainThread]: 
[0m23:44:08.865149 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:44:08.870597 [info ] [MainThread]: 
[0m23:44:08.873255 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:44:08.908480 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m23:44:09.119374 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m23:44:09.121540 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:44:09.123624 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:44:09.134175 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "postgres" (172.18.0.2), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

[0m23:44:09.137649 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:44:09.150080 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m23:44:09.152250 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m23:44:09.154273 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m23:44:09.156389 [debug] [ThreadPool]: On list_staging: No close available on handle
[0m23:44:09.159320 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:44:09.162621 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m23:44:09.164609 [info ] [MainThread]: 
[0m23:44:09.168184 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.29 seconds (0.29s).
[0m23:44:09.171461 [error] [MainThread]: Encountered an error:
Database Error
  connection to server at "postgres" (172.18.0.2), port 5433 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  
[0m23:44:09.177686 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 10.284367, "process_in_blocks": "0", "process_kernel_time": 1.795854, "process_mem_max_rss": "123696", "process_out_blocks": "0", "process_user_time": 13.806277}
[0m23:44:09.181279 [debug] [MainThread]: Command `dbt run` failed at 23:44:09.179794 after 10.29 seconds
[0m23:44:09.185184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6740ee2590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f673cd50970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f673cfb5120>]}
[0m23:44:09.189389 [debug] [MainThread]: Flushing usage events
[0m23:44:10.325438 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:48:44.184099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500dfe2830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500d02b580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500d02b520>]}


============================== 23:48:44.202933 | 1cf6150d-a1af-4966-b78a-d0dd85fe52ec ==============================
[0m23:48:44.202933 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:48:44.208997 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'write_json': 'True', 'invocation_command': 'dbt run', 'printer_width': '80', 'version_check': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'profiles_dir': '/dbt', 'no_print': 'None', 'target_path': 'None', 'cache_selected_only': 'False', 'debug': 'False', 'log_path': '/dbt/logs', 'log_cache_events': 'False', 'quiet': 'False', 'static_parser': 'True', 'introspect': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True'}
[0m23:48:45.459768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1cf6150d-a1af-4966-b78a-d0dd85fe52ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500d87c2b0>]}
[0m23:48:45.930553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1cf6150d-a1af-4966-b78a-d0dd85fe52ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500ce7e290>]}
[0m23:48:45.940911 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:48:46.501274 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:48:47.385251 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m23:48:47.389211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1cf6150d-a1af-4966-b78a-d0dd85fe52ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500d87f2e0>]}
[0m23:48:56.827145 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m23:48:56.907676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1cf6150d-a1af-4966-b78a-d0dd85fe52ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500a15ffa0>]}
[0m23:48:57.715373 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:48:57.755097 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:48:57.929050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1cf6150d-a1af-4966-b78a-d0dd85fe52ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500a1b8f40>]}
[0m23:48:57.940846 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m23:48:57.943529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1cf6150d-a1af-4966-b78a-d0dd85fe52ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500a1b8fa0>]}
[0m23:48:57.971756 [info ] [MainThread]: 
[0m23:48:57.985607 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:48:58.000591 [info ] [MainThread]: 
[0m23:48:58.020623 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:48:58.064268 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m23:48:58.440974 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m23:48:58.471097 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:48:58.476383 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:48:58.523114 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.045 seconds
[0m23:48:58.529132 [debug] [ThreadPool]: On list_staging: Close
[0m23:48:58.540613 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m23:48:58.570872 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:48:58.576325 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m23:48:58.578390 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:48:58.616761 [debug] [ThreadPool]: SQL status: BEGIN in 0.038 seconds
[0m23:48:58.625100 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:48:58.632745 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m23:48:58.663671 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m23:48:58.682473 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m23:48:58.692869 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m23:48:58.757238 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:58.770804 [debug] [MainThread]: On master: BEGIN
[0m23:48:58.774006 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:48:58.810302 [debug] [MainThread]: SQL status: BEGIN in 0.036 seconds
[0m23:48:58.814044 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:58.836596 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m23:48:58.852535 [debug] [MainThread]: SQL status: SELECT 0 in 0.009 seconds
[0m23:48:58.859856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1cf6150d-a1af-4966-b78a-d0dd85fe52ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500b143940>]}
[0m23:48:58.866673 [debug] [MainThread]: On master: ROLLBACK
[0m23:48:58.869153 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:58.871278 [debug] [MainThread]: On master: BEGIN
[0m23:48:58.877327 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m23:48:58.879686 [debug] [MainThread]: On master: COMMIT
[0m23:48:58.881765 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:58.883856 [debug] [MainThread]: On master: COMMIT
[0m23:48:58.887426 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:48:58.890809 [debug] [MainThread]: On master: Close
[0m23:48:58.913794 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m23:48:58.919581 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m23:48:58.926135 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m23:48:58.929882 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m23:48:58.978237 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m23:48:59.006387 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m23:48:59.202092 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m23:48:59.219672 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:48:59.222480 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m23:48:59.225312 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:48:59.262530 [debug] [Thread-1 (]: SQL status: BEGIN in 0.037 seconds
[0m23:48:59.265816 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:48:59.269132 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m23:48:59.275843 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "public.bankole_store" does not exist
LINE 11:     select * from "staging"."public"."bankole_store"
                           ^

[0m23:48:59.280439 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: ROLLBACK
[0m23:48:59.293070 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m23:48:59.307381 [debug] [Thread-1 (]: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:48:59.318392 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1cf6150d-a1af-4966-b78a-d0dd85fe52ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500e324460>]}
[0m23:48:59.322378 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model bankole_store.stg_sales ................... [[31mERROR[0m in 0.39s]
[0m23:48:59.327645 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m23:48:59.332381 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.stg_sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql.
[0m23:48:59.339719 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m23:48:59.343365 [info ] [Thread-1 (]: 2 of 2 SKIP relation bankole_store.sales_summary ............................... [[33mSKIP[0m]
[0m23:48:59.367214 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m23:48:59.409370 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:59.421566 [debug] [MainThread]: On master: BEGIN
[0m23:48:59.439889 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:48:59.525897 [debug] [MainThread]: SQL status: BEGIN in 0.085 seconds
[0m23:48:59.531286 [debug] [MainThread]: On master: COMMIT
[0m23:48:59.547523 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:59.550880 [debug] [MainThread]: On master: COMMIT
[0m23:48:59.557060 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:48:59.564500 [debug] [MainThread]: On master: Close
[0m23:48:59.582628 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:48:59.585956 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m23:48:59.587935 [debug] [MainThread]: Connection 'model.dbt_transform.stg_sales' was properly closed.
[0m23:48:59.590304 [info ] [MainThread]: 
[0m23:48:59.608345 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.57 seconds (1.57s).
[0m23:48:59.624281 [debug] [MainThread]: Command end result
[0m23:49:00.084294 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:49:00.113552 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:49:00.153377 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m23:49:00.155542 [info ] [MainThread]: 
[0m23:49:00.158724 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:49:00.166781 [info ] [MainThread]: 
[0m23:49:00.170118 [error] [MainThread]: [31mFailure in model stg_sales (models/stg_sales.sql)[0m
[0m23:49:00.183817 [error] [MainThread]:   Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:49:00.189073 [info ] [MainThread]: 
[0m23:49:00.194192 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/stg_sales.sql
[0m23:49:00.201710 [info ] [MainThread]: 
[0m23:49:00.215907 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m23:49:00.224099 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 14.836512, "process_in_blocks": "0", "process_kernel_time": 2.181496, "process_mem_max_rss": "129404", "process_out_blocks": "1504", "process_user_time": 15.134783}
[0m23:49:00.226781 [debug] [MainThread]: Command `dbt run` failed at 23:49:00.226320 after 14.84 seconds
[0m23:49:00.231024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500dfe2830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500df329e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f500b11cca0>]}
[0m23:49:00.233670 [debug] [MainThread]: Flushing usage events
[0m23:49:03.412813 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:53:15.763227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f361927e590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3617fecbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3617fecb80>]}


============================== 23:53:15.792349 | 05073d43-fec3-4d7f-b90c-ee289bcd1d04 ==============================
[0m23:53:15.792349 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:53:15.798930 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'log_path': '/dbt/logs', 'debug': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'version_check': 'True', 'profiles_dir': '/dbt', 'printer_width': '80', 'fail_fast': 'False', 'warn_error': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'cache_selected_only': 'False', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'use_colors': 'True', 'partial_parse': 'True'}
[0m23:53:16.676458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '05073d43-fec3-4d7f-b90c-ee289bcd1d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3618dd30d0>]}
[0m23:53:17.088389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '05073d43-fec3-4d7f-b90c-ee289bcd1d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3618792bc0>]}
[0m23:53:17.094122 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m23:53:17.535649 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:53:18.553257 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:53:18.555018 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:53:18.575084 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m23:53:18.935153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '05073d43-fec3-4d7f-b90c-ee289bcd1d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f36163a8d00>]}
[0m23:53:19.526596 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:53:19.556628 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:53:19.668792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '05073d43-fec3-4d7f-b90c-ee289bcd1d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f36163aba00>]}
[0m23:53:19.674002 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m23:53:19.684732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '05073d43-fec3-4d7f-b90c-ee289bcd1d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f36163ab9a0>]}
[0m23:53:19.699757 [info ] [MainThread]: 
[0m23:53:19.712743 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:53:19.726396 [info ] [MainThread]: 
[0m23:53:19.739504 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:53:19.768832 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m23:53:20.179674 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m23:53:20.182505 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m23:53:20.184636 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:53:20.254899 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.070 seconds
[0m23:53:20.266632 [debug] [ThreadPool]: On list_staging: Close
[0m23:53:20.272170 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m23:53:20.348404 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:53:20.350721 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m23:53:20.359126 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:53:20.386010 [debug] [ThreadPool]: SQL status: BEGIN in 0.027 seconds
[0m23:53:20.389044 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m23:53:20.391160 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m23:53:20.402591 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.009 seconds
[0m23:53:20.419900 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m23:53:20.427534 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m23:53:20.465228 [debug] [MainThread]: Using postgres connection "master"
[0m23:53:20.472200 [debug] [MainThread]: On master: BEGIN
[0m23:53:20.474530 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:53:20.507433 [debug] [MainThread]: SQL status: BEGIN in 0.033 seconds
[0m23:53:20.520103 [debug] [MainThread]: Using postgres connection "master"
[0m23:53:20.526323 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m23:53:20.558126 [debug] [MainThread]: SQL status: SELECT 0 in 0.007 seconds
[0m23:53:20.563550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '05073d43-fec3-4d7f-b90c-ee289bcd1d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f361a642fe0>]}
[0m23:53:20.570883 [debug] [MainThread]: On master: ROLLBACK
[0m23:53:20.572922 [debug] [MainThread]: Using postgres connection "master"
[0m23:53:20.574538 [debug] [MainThread]: On master: BEGIN
[0m23:53:20.580900 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m23:53:20.586344 [debug] [MainThread]: On master: COMMIT
[0m23:53:20.591934 [debug] [MainThread]: Using postgres connection "master"
[0m23:53:20.600868 [debug] [MainThread]: On master: COMMIT
[0m23:53:20.604966 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:53:20.607748 [debug] [MainThread]: On master: Close
[0m23:53:20.624313 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m23:53:20.627734 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m23:53:20.641908 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m23:53:20.655682 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m23:53:20.724184 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m23:53:20.854975 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m23:53:21.180220 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m23:53:21.240389 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:53:21.242493 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m23:53:21.250979 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:53:21.279798 [debug] [Thread-1 (]: SQL status: BEGIN in 0.028 seconds
[0m23:53:21.300271 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m23:53:21.317447 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m23:53:21.337395 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "public.bankole_store" does not exist
LINE 11:     select * from "staging"."public"."bankole_store"
                           ^

[0m23:53:21.342953 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: ROLLBACK
[0m23:53:21.346002 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m23:53:21.373720 [debug] [Thread-1 (]: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:53:21.393796 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05073d43-fec3-4d7f-b90c-ee289bcd1d04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3618841a80>]}
[0m23:53:21.426079 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model bankole_store.stg_sales ................... [[31mERROR[0m in 0.74s]
[0m23:53:21.435451 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m23:53:21.441261 [debug] [Thread-4 (]: Marking all children of 'model.dbt_transform.stg_sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql.
[0m23:53:21.445360 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m23:53:21.460260 [info ] [Thread-1 (]: 2 of 2 SKIP relation bankole_store.sales_summary ............................... [[33mSKIP[0m]
[0m23:53:21.471695 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m23:53:21.475431 [debug] [MainThread]: Using postgres connection "master"
[0m23:53:21.489103 [debug] [MainThread]: On master: BEGIN
[0m23:53:21.491670 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:53:21.527207 [debug] [MainThread]: SQL status: BEGIN in 0.035 seconds
[0m23:53:21.536220 [debug] [MainThread]: On master: COMMIT
[0m23:53:21.538058 [debug] [MainThread]: Using postgres connection "master"
[0m23:53:21.540500 [debug] [MainThread]: On master: COMMIT
[0m23:53:21.543367 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:53:21.545336 [debug] [MainThread]: On master: Close
[0m23:53:21.559960 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:53:21.564489 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m23:53:21.568382 [debug] [MainThread]: Connection 'model.dbt_transform.stg_sales' was properly closed.
[0m23:53:21.570981 [info ] [MainThread]: 
[0m23:53:21.575097 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.83 seconds (1.83s).
[0m23:53:21.587465 [debug] [MainThread]: Command end result
[0m23:53:21.808910 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m23:53:21.853060 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m23:53:21.903841 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m23:53:21.912836 [info ] [MainThread]: 
[0m23:53:21.954385 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:53:21.973326 [info ] [MainThread]: 
[0m23:53:21.977773 [error] [MainThread]: [31mFailure in model stg_sales (models/stg_sales.sql)[0m
[0m23:53:21.993363 [error] [MainThread]:   Database Error in model stg_sales (models/stg_sales.sql)
  relation "public.bankole_store" does not exist
  LINE 11:     select * from "staging"."public"."bankole_store"
                             ^
  compiled code at target/run/dbt_transform/models/stg_sales.sql
[0m23:53:21.996300 [info ] [MainThread]: 
[0m23:53:22.000595 [info ] [MainThread]:   compiled code at target/compiled/dbt_transform/models/stg_sales.sql
[0m23:53:22.009439 [info ] [MainThread]: 
[0m23:53:22.014251 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m23:53:22.018373 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.8146877, "process_in_blocks": "0", "process_kernel_time": 1.427619, "process_mem_max_rss": "120152", "process_out_blocks": "0", "process_user_time": 8.366271}
[0m23:53:22.043920 [debug] [MainThread]: Command `dbt run` failed at 23:53:22.043573 after 6.84 seconds
[0m23:53:22.045799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f361927e590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f36192bb910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f36163ee950>]}
[0m23:53:22.047683 [debug] [MainThread]: Flushing usage events
[0m23:53:23.529452 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:02:39.912242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9a2a96530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9a1accb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9a1accaf0>]}


============================== 00:02:39.931471 | a8e6861d-8549-4db2-b548-41388dab353b ==============================
[0m00:02:39.931471 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:02:39.935179 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'use_colors': 'True', 'no_print': 'None', 'partial_parse': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'invocation_command': 'dbt run', 'empty': 'False', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'log_path': '/dbt/logs', 'log_cache_events': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_format': 'default', 'printer_width': '80', 'debug': 'False', 'write_json': 'True', 'static_parser': 'True', 'target_path': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': '/dbt', 'warn_error': 'None'}
[0m00:02:40.648492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a8e6861d-8549-4db2-b548-41388dab353b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9a4318160>]}
[0m00:02:40.842293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a8e6861d-8549-4db2-b548-41388dab353b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9a219db40>]}
[0m00:02:40.845605 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m00:02:41.071393 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:02:41.765567 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:02:41.767894 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:02:41.787182 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m00:02:41.928657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a8e6861d-8549-4db2-b548-41388dab353b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff99fdd4ca0>]}
[0m00:02:42.206765 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m00:02:42.218781 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m00:02:42.270713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a8e6861d-8549-4db2-b548-41388dab353b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff99fdd4880>]}
[0m00:02:42.273613 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m00:02:42.276434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a8e6861d-8549-4db2-b548-41388dab353b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff99fdd48b0>]}
[0m00:02:42.282626 [info ] [MainThread]: 
[0m00:02:42.291790 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:02:42.294069 [info ] [MainThread]: 
[0m00:02:42.297118 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:02:42.312722 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m00:02:42.487835 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m00:02:42.489815 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m00:02:42.491927 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:02:42.509321 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.017 seconds
[0m00:02:42.517053 [debug] [ThreadPool]: On list_staging: Close
[0m00:02:42.523788 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m00:02:42.542754 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m00:02:42.545111 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m00:02:42.547051 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:02:42.564530 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m00:02:42.566582 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m00:02:42.568604 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m00:02:42.577321 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m00:02:42.585579 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m00:02:42.587513 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m00:02:42.600662 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:42.602443 [debug] [MainThread]: On master: BEGIN
[0m00:02:42.606567 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:02:42.630728 [debug] [MainThread]: SQL status: BEGIN in 0.024 seconds
[0m00:02:42.632883 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:42.635250 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m00:02:42.644954 [debug] [MainThread]: SQL status: SELECT 0 in 0.007 seconds
[0m00:02:42.649012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a8e6861d-8549-4db2-b548-41388dab353b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9a45c04c0>]}
[0m00:02:42.656236 [debug] [MainThread]: On master: ROLLBACK
[0m00:02:42.659901 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:42.662727 [debug] [MainThread]: On master: BEGIN
[0m00:02:42.670823 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m00:02:42.674126 [debug] [MainThread]: On master: COMMIT
[0m00:02:42.677356 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:42.681051 [debug] [MainThread]: On master: COMMIT
[0m00:02:42.683332 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:02:42.686757 [debug] [MainThread]: On master: Close
[0m00:02:42.712553 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m00:02:42.720969 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m00:02:42.723650 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m00:02:42.725752 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m00:02:42.778191 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m00:02:42.805010 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m00:02:42.930849 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m00:02:42.945173 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m00:02:42.947741 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m00:02:42.949936 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:02:42.966764 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m00:02:42.968629 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m00:02:42.970625 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m00:02:42.989111 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.010 seconds
[0m00:02:43.007975 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m00:02:43.010543 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m00:02:43.013720 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:02:43.058481 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m00:02:43.060773 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m00:02:43.062926 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m00:02:43.066862 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m00:02:43.084063 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m00:02:43.098039 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m00:02:43.100003 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m00:02:43.104041 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.002 seconds
[0m00:02:43.115762 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m00:02:43.130890 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8e6861d-8549-4db2-b548-41388dab353b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff99f918d90>]}
[0m00:02:43.136974 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 0.40s]
[0m00:02:43.143564 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m00:02:43.147909 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m00:02:43.151070 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m00:02:43.157255 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m00:02:43.167500 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m00:02:43.184005 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m00:02:43.214210 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m00:02:43.321264 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m00:02:43.342515 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m00:02:43.344778 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m00:02:43.347913 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:02:43.365481 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m00:02:43.368737 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m00:02:43.371560 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m00:02:48.569880 [debug] [Thread-1 (]: SQL status: SELECT 1716 in 5.196 seconds
[0m00:02:48.605054 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m00:02:48.608615 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m00:02:48.616272 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:02:48.622869 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m00:02:48.633492 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m00:02:48.635491 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m00:02:48.639106 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m00:02:48.649013 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m00:02:48.657250 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m00:02:48.659553 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m00:02:48.662054 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m00:02:48.686160 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m00:02:48.696746 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8e6861d-8549-4db2-b548-41388dab353b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff99f92abf0>]}
[0m00:02:48.701980 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 1716[0m in 5.54s]
[0m00:02:48.704520 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m00:02:48.718197 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:48.746582 [debug] [MainThread]: On master: BEGIN
[0m00:02:48.750949 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:02:48.800953 [debug] [MainThread]: SQL status: BEGIN in 0.050 seconds
[0m00:02:48.808331 [debug] [MainThread]: On master: COMMIT
[0m00:02:48.813477 [debug] [MainThread]: Using postgres connection "master"
[0m00:02:48.815232 [debug] [MainThread]: On master: COMMIT
[0m00:02:48.827544 [debug] [MainThread]: SQL status: COMMIT in 0.007 seconds
[0m00:02:48.832649 [debug] [MainThread]: On master: Close
[0m00:02:48.844534 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:02:48.853988 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m00:02:48.860214 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m00:02:48.867162 [info ] [MainThread]: 
[0m00:02:48.870104 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 6.57 seconds (6.57s).
[0m00:02:48.874618 [debug] [MainThread]: Command end result
[0m00:02:49.120514 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m00:02:49.156675 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m00:02:49.236929 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m00:02:49.253165 [info ] [MainThread]: 
[0m00:02:49.259415 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:02:49.265010 [info ] [MainThread]: 
[0m00:02:49.272307 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m00:02:49.276777 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.647402, "process_in_blocks": "0", "process_kernel_time": 1.057722, "process_mem_max_rss": "119912", "process_out_blocks": "0", "process_user_time": 8.109208}
[0m00:02:49.280824 [debug] [MainThread]: Command `dbt run` succeeded at 00:02:49.280406 after 9.65 seconds
[0m00:02:49.289513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9a2a96530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff99fde4220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9a4318160>]}
[0m00:02:49.320142 [debug] [MainThread]: Flushing usage events
[0m00:02:50.468051 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:21:18.265380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5400e7e5c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53ffeacbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53ffeacb80>]}


============================== 00:21:18.274616 | 4ab85278-d0a2-4a04-878f-a2c99fa54e24 ==============================
[0m00:21:18.274616 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:21:18.287471 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'introspect': 'True', 'indirect_selection': 'eager', 'log_format': 'default', 'use_colors': 'True', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/dbt/logs', 'invocation_command': 'dbt run', 'quiet': 'False', 'printer_width': '80', 'no_print': 'None', 'target_path': 'None', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'write_json': 'True', 'profiles_dir': '/dbt', 'version_check': 'True'}
[0m00:21:18.973212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4ab85278-d0a2-4a04-878f-a2c99fa54e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54027001f0>]}
[0m00:21:19.243089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4ab85278-d0a2-4a04-878f-a2c99fa54e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53ffd6f9a0>]}
[0m00:21:19.246193 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m00:21:19.557614 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:21:20.153478 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:21:20.155312 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:21:20.183123 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m00:21:20.319885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4ab85278-d0a2-4a04-878f-a2c99fa54e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53fe1d4d30>]}
[0m00:21:20.699343 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m00:21:20.713922 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m00:21:20.770550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4ab85278-d0a2-4a04-878f-a2c99fa54e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53fe1d7a00>]}
[0m00:21:20.789594 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m00:21:20.795827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4ab85278-d0a2-4a04-878f-a2c99fa54e24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53fe1d79a0>]}
[0m00:21:20.803443 [info ] [MainThread]: 
[0m00:21:20.806214 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:21:20.808207 [info ] [MainThread]: 
[0m00:21:20.810851 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:21:20.821341 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m00:21:21.004362 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m00:21:21.006731 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m00:21:21.008318 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:26:06.667915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15e001a7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15df037490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15df037430>]}


============================== 00:26:06.696666 | 7aeffeed-d05a-40d0-8081-20b235360e5f ==============================
[0m00:26:06.696666 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:26:06.699259 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'target_path': 'None', 'profiles_dir': '/dbt', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_cache_events': 'False', 'log_path': '/dbt/logs', 'cache_selected_only': 'False', 'introspect': 'True', 'use_colors': 'True', 'log_format': 'default', 'quiet': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'write_json': 'True', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'False', 'fail_fast': 'False', 'no_print': 'None', 'version_check': 'True', 'printer_width': '80', 'partial_parse': 'True'}
[0m00:26:07.866938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7aeffeed-d05a-40d0-8081-20b235360e5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f15dfe3b430>]}
[0m01:59:06.007036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec97d3a830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec96d7f550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec96d7f4f0>]}


============================== 01:59:06.160126 | 7fc86daf-ac16-490f-8c56-1ae0c8ea7e29 ==============================
[0m01:59:06.160126 [info ] [MainThread]: Running with dbt=1.10.13
[0m01:59:06.172981 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'debug': 'False', 'introspect': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'target_path': 'None', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'partial_parse': 'True', 'quiet': 'False', 'invocation_command': 'dbt run', 'log_path': '/dbt/logs', 'version_check': 'True', 'static_parser': 'True', 'empty': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'profiles_dir': '/dbt'}
[0m01:59:08.700120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7fc86daf-ac16-490f-8c56-1ae0c8ea7e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec96d7efb0>]}
[0m01:59:09.292947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7fc86daf-ac16-490f-8c56-1ae0c8ea7e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec975d64d0>]}
[0m01:59:09.307659 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m01:59:11.417971 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m01:59:16.598252 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:59:16.601395 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:59:16.737321 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m01:59:17.455336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7fc86daf-ac16-490f-8c56-1ae0c8ea7e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec953d4f10>]}
[0m01:59:20.028310 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m01:59:20.178421 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m01:59:20.429414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7fc86daf-ac16-490f-8c56-1ae0c8ea7e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec94f908e0>]}
[0m01:59:20.434881 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m01:59:20.442169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7fc86daf-ac16-490f-8c56-1ae0c8ea7e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec94f90940>]}
[0m01:59:20.934186 [info ] [MainThread]: 
[0m01:59:21.080507 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:59:21.131214 [info ] [MainThread]: 
[0m01:59:21.201850 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:59:21.284327 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m01:59:22.044253 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m01:59:22.080768 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m01:59:22.087696 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:59:22.180495 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.082 seconds
[0m01:59:22.196282 [debug] [ThreadPool]: On list_staging: Close
[0m01:59:22.218040 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m01:59:22.330219 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m01:59:22.342121 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m01:59:22.344332 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:59:22.402564 [debug] [ThreadPool]: SQL status: BEGIN in 0.058 seconds
[0m01:59:22.410859 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m01:59:22.413174 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m01:59:22.466139 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.046 seconds
[0m01:59:22.471395 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m01:59:22.491770 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m01:59:22.584921 [debug] [MainThread]: Using postgres connection "master"
[0m01:59:22.591270 [debug] [MainThread]: On master: BEGIN
[0m01:59:22.595201 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:59:22.682691 [debug] [MainThread]: SQL status: BEGIN in 0.088 seconds
[0m01:59:22.689368 [debug] [MainThread]: Using postgres connection "master"
[0m01:59:22.693198 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m01:59:22.774325 [debug] [MainThread]: SQL status: SELECT 1 in 0.070 seconds
[0m01:59:22.781817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7fc86daf-ac16-490f-8c56-1ae0c8ea7e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec957ed1b0>]}
[0m01:59:22.784530 [debug] [MainThread]: On master: ROLLBACK
[0m01:59:22.795727 [debug] [MainThread]: Using postgres connection "master"
[0m01:59:22.797713 [debug] [MainThread]: On master: BEGIN
[0m01:59:22.801316 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m01:59:22.805363 [debug] [MainThread]: On master: COMMIT
[0m01:59:22.807606 [debug] [MainThread]: Using postgres connection "master"
[0m01:59:22.812904 [debug] [MainThread]: On master: COMMIT
[0m01:59:22.815270 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m01:59:22.818009 [debug] [MainThread]: On master: Close
[0m01:59:22.901178 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m01:59:22.912139 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m01:59:22.922506 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m01:59:22.932607 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m01:59:23.143099 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m01:59:23.181772 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m01:59:23.715002 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m01:59:23.753994 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m01:59:23.757901 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m01:59:23.761552 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:59:23.836278 [debug] [Thread-1 (]: SQL status: BEGIN in 0.076 seconds
[0m01:59:23.840890 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m01:59:23.868511 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m01:59:24.023223 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.117 seconds
[0m01:59:24.181162 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m01:59:24.197920 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales" rename to "stg_sales__dbt_backup"
[0m01:59:24.215908 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m01:59:24.249603 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m01:59:24.287080 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m01:59:24.291472 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m01:59:24.653016 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m01:59:24.682655 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m01:59:24.685188 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m01:59:24.706436 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m01:59:24.842565 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m01:59:24.948667 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m01:59:24.965409 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m01:59:24.977623 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.010 seconds
[0m01:59:25.001024 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m01:59:25.060969 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fc86daf-ac16-490f-8c56-1ae0c8ea7e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec953be1a0>]}
[0m01:59:25.080275 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 2.10s]
[0m01:59:25.129028 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m01:59:25.200727 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m01:59:25.204528 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m01:59:25.212094 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m01:59:25.214430 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m01:59:25.329212 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m01:59:25.367088 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m01:59:25.758159 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m01:59:25.794692 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m01:59:25.797356 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m01:59:25.799611 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:59:25.837235 [debug] [Thread-1 (]: SQL status: BEGIN in 0.038 seconds
[0m01:59:25.857259 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m01:59:25.904817 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m01:59:40.511435 [debug] [Thread-1 (]: SQL status: SELECT 1716 in 14.588 seconds
[0m01:59:40.567182 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m01:59:40.574084 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary" rename to "sales_summary__dbt_backup"
[0m01:59:40.586366 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m01:59:40.641785 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m01:59:40.648640 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m01:59:40.658831 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m01:59:40.670885 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m01:59:40.673778 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m01:59:40.676827 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m01:59:40.686370 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m01:59:40.803856 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m01:59:40.881768 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m01:59:40.894045 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m01:59:40.918589 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.012 seconds
[0m01:59:40.957956 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m01:59:40.972379 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fc86daf-ac16-490f-8c56-1ae0c8ea7e29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec9807c460>]}
[0m01:59:40.976735 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 1716[0m in 15.76s]
[0m01:59:41.010410 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m01:59:41.028841 [debug] [MainThread]: Using postgres connection "master"
[0m01:59:41.042505 [debug] [MainThread]: On master: BEGIN
[0m01:59:41.056796 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:59:41.116433 [debug] [MainThread]: SQL status: BEGIN in 0.060 seconds
[0m01:59:41.122511 [debug] [MainThread]: On master: COMMIT
[0m01:59:41.124959 [debug] [MainThread]: Using postgres connection "master"
[0m01:59:41.127082 [debug] [MainThread]: On master: COMMIT
[0m01:59:41.138383 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m01:59:41.166511 [debug] [MainThread]: On master: Close
[0m01:59:41.187278 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:59:41.210038 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m01:59:41.212717 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m01:59:41.219079 [info ] [MainThread]: 
[0m01:59:41.228623 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 20.02 seconds (20.02s).
[0m01:59:41.236021 [debug] [MainThread]: Command end result
[0m01:59:41.682359 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m01:59:41.718584 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m01:59:41.899314 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m01:59:41.904656 [info ] [MainThread]: 
[0m01:59:41.909754 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:59:41.918677 [info ] [MainThread]: 
[0m01:59:41.999205 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m01:59:42.051159 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 37.749203, "process_in_blocks": "72832", "process_kernel_time": 3.35797, "process_mem_max_rss": "118904", "process_out_blocks": "1504", "process_user_time": 12.309091}
[0m01:59:42.092823 [debug] [MainThread]: Command `dbt run` succeeded at 01:59:42.092463 after 37.79 seconds
[0m01:59:42.095217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec97d3a830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec99076cb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec98ab0d90>]}
[0m01:59:42.128901 [debug] [MainThread]: Flushing usage events
[0m01:59:43.269842 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:40:23.740330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba5902860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba467f640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba467f5e0>]}


============================== 10:40:24.118578 | 318b9974-ec5b-4a76-a399-30f66f5018fa ==============================
[0m10:40:24.118578 [info ] [MainThread]: Running with dbt=1.10.13
[0m10:40:24.187914 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'profiles_dir': '/dbt', 'warn_error': 'None', 'indirect_selection': 'eager', 'version_check': 'True', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'target_path': 'None', 'quiet': 'False', 'fail_fast': 'False', 'debug': 'False', 'invocation_command': 'dbt run', 'partial_parse': 'True', 'write_json': 'True', 'log_path': '/dbt/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'empty': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'log_format': 'default'}
[0m10:40:56.679320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '318b9974-ec5b-4a76-a399-30f66f5018fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba467f5e0>]}
[0m10:41:04.695814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '318b9974-ec5b-4a76-a399-30f66f5018fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba4f2a380>]}
[0m10:41:04.780096 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m10:41:16.074124 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m10:41:45.834163 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:41:46.032499 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:41:47.318698 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m10:41:56.581431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '318b9974-ec5b-4a76-a399-30f66f5018fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba29acf70>]}
[0m10:42:07.668732 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m10:42:08.026517 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m10:42:13.853677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '318b9974-ec5b-4a76-a399-30f66f5018fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba2568820>]}
[0m10:42:13.948538 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m10:42:14.012883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '318b9974-ec5b-4a76-a399-30f66f5018fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba2568880>]}
[0m10:42:16.494676 [info ] [MainThread]: 
[0m10:42:16.736707 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:42:16.827386 [info ] [MainThread]: 
[0m10:42:16.914409 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:42:17.298251 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m10:42:43.941682 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m10:42:43.989674 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m10:42:44.120435 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:42:45.663443 [debug] [ThreadPool]: SQL status: SELECT 5 in 1.560 seconds
[0m10:42:45.939329 [debug] [ThreadPool]: On list_staging: Close
[0m10:42:46.053250 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m10:42:46.432293 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m10:42:46.491137 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m10:42:46.537872 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:42:47.219368 [debug] [ThreadPool]: SQL status: BEGIN in 0.681 seconds
[0m10:42:47.361862 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m10:42:47.495838 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m10:42:49.529386 [debug] [ThreadPool]: SQL status: SELECT 2 in 1.982 seconds
[0m10:42:49.609469 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m10:42:49.715835 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m10:42:50.445025 [debug] [MainThread]: Using postgres connection "master"
[0m10:42:50.492022 [debug] [MainThread]: On master: BEGIN
[0m10:42:50.585611 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:42:51.442369 [debug] [MainThread]: SQL status: BEGIN in 0.856 seconds
[0m10:42:51.551500 [debug] [MainThread]: Using postgres connection "master"
[0m10:42:51.707163 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m10:42:53.656922 [debug] [MainThread]: SQL status: SELECT 1 in 1.595 seconds
[0m10:42:53.981974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '318b9974-ec5b-4a76-a399-30f66f5018fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba2dc5210>]}
[0m10:42:54.031724 [debug] [MainThread]: On master: ROLLBACK
[0m10:42:54.154987 [debug] [MainThread]: Using postgres connection "master"
[0m10:42:54.219140 [debug] [MainThread]: On master: BEGIN
[0m10:42:54.305062 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m10:42:54.380451 [debug] [MainThread]: On master: COMMIT
[0m10:42:54.517804 [debug] [MainThread]: Using postgres connection "master"
[0m10:42:54.692010 [debug] [MainThread]: On master: COMMIT
[0m10:42:54.867761 [debug] [MainThread]: SQL status: COMMIT in 0.101 seconds
[0m10:42:54.995980 [debug] [MainThread]: On master: Close
[0m10:42:55.958368 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m10:42:56.080379 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m10:42:56.097591 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m10:42:56.287832 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m10:42:57.725486 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m10:42:58.251495 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m10:43:00.273053 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m10:43:02.179032 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m10:43:02.301723 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m10:43:02.402112 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:43:03.372031 [debug] [Thread-1 (]: SQL status: BEGIN in 0.881 seconds
[0m10:43:03.713172 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m10:43:04.117606 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m10:43:08.941739 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 4.757 seconds
[0m10:43:09.551167 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m10:43:09.649714 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales" rename to "stg_sales__dbt_backup"
[0m10:43:10.129725 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.151 seconds
[0m10:43:10.282491 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m10:43:10.347529 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m10:43:10.393164 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m10:43:14.089224 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m10:43:14.195010 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m10:43:14.269348 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m10:43:14.503747 [debug] [Thread-1 (]: SQL status: COMMIT in 0.027 seconds
[0m10:43:14.820984 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m10:43:15.728598 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m10:43:15.778348 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m10:43:16.780087 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.954 seconds
[0m10:43:17.063535 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m10:43:17.734816 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '318b9974-ec5b-4a76-a399-30f66f5018fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba29357b0>]}
[0m10:43:18.106127 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 21.31s]
[0m10:43:18.723715 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m10:43:21.147364 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m10:43:21.349184 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m10:43:21.586662 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m10:43:22.476576 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m10:43:23.883183 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m10:43:26.282323 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m10:43:29.061152 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m10:43:29.859300 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m10:43:30.026264 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m10:43:30.072625 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:43:30.385700 [debug] [Thread-1 (]: SQL status: BEGIN in 0.313 seconds
[0m10:43:30.627547 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m10:43:30.846574 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m10:43:32.314805 [debug] [Thread-1 (]: SQL status: SELECT 0 in 1.338 seconds
[0m10:43:32.761583 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m10:43:33.017427 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary" rename to "sales_summary__dbt_backup"
[0m10:43:33.157996 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.017 seconds
[0m10:43:33.311510 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m10:43:33.494307 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m10:43:33.587763 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m10:43:33.739356 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m10:43:33.862234 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m10:43:33.971320 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m10:43:34.160406 [debug] [Thread-1 (]: SQL status: COMMIT in 0.062 seconds
[0m10:43:34.347134 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m10:43:34.465645 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m10:43:34.560838 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m10:43:34.893541 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.278 seconds
[0m10:43:35.198931 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m10:43:35.564644 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '318b9974-ec5b-4a76-a399-30f66f5018fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba166c0d0>]}
[0m10:43:35.648752 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 0[0m in 13.98s]
[0m10:43:35.876205 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m10:43:36.127801 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:36.327145 [debug] [MainThread]: On master: BEGIN
[0m10:43:36.468992 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:43:38.012320 [debug] [MainThread]: SQL status: BEGIN in 1.543 seconds
[0m10:43:38.149855 [debug] [MainThread]: On master: COMMIT
[0m10:43:38.489449 [debug] [MainThread]: Using postgres connection "master"
[0m10:43:38.594651 [debug] [MainThread]: On master: COMMIT
[0m10:43:38.699722 [debug] [MainThread]: SQL status: COMMIT in 0.016 seconds
[0m10:43:38.813362 [debug] [MainThread]: On master: Close
[0m10:43:38.992197 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:43:39.123256 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m10:43:39.248127 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m10:43:39.335641 [info ] [MainThread]: 
[0m10:43:39.448628 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 1 minutes and 22.41 seconds (82.41s).
[0m10:43:39.634073 [debug] [MainThread]: Command end result
[0m10:43:46.878004 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m10:43:47.192157 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m10:43:48.505958 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m10:43:48.588118 [info ] [MainThread]: 
[0m10:43:48.882189 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:43:49.314882 [info ] [MainThread]: 
[0m10:43:49.546503 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m10:43:50.528802 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 223.58727, "process_in_blocks": "35280", "process_kernel_time": 71.490265, "process_mem_max_rss": "119980", "process_out_blocks": "1504", "process_user_time": 47.616898}
[0m10:43:50.856451 [debug] [MainThread]: Command `dbt run` succeeded at 10:43:50.855760 after 223.92 seconds
[0m10:43:51.003564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba5902860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba39e0430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdba467ec20>]}
[0m10:43:51.080782 [debug] [MainThread]: Flushing usage events
[0m10:43:55.446577 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:15:48.111084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db2f36560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db1f44b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db1f44b20>]}


============================== 19:15:48.191983 | 01be8844-152e-4d7e-a3d9-4fd5d3f40954 ==============================
[0m19:15:48.191983 [info ] [MainThread]: Running with dbt=1.10.13
[0m19:15:48.200697 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'partial_parse': 'True', 'log_path': '/dbt/logs', 'introspect': 'True', 'empty': 'False', 'no_print': 'None', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'profiles_dir': '/dbt', 'log_cache_events': 'False', 'warn_error': 'None', 'static_parser': 'True', 'target_path': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run', 'write_json': 'True', 'printer_width': '80', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'version_check': 'True'}
[0m19:15:52.694691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '01be8844-152e-4d7e-a3d9-4fd5d3f40954', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db47c0190>]}
[0m19:15:54.096710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '01be8844-152e-4d7e-a3d9-4fd5d3f40954', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db213e5c0>]}
[0m19:15:54.131305 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m19:15:57.521679 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m19:16:02.098451 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:16:02.113214 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:16:02.246861 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m19:16:03.510132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '01be8844-152e-4d7e-a3d9-4fd5d3f40954', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db05b4ca0>]}
[0m19:16:11.783957 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:16:11.862134 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:16:12.710908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '01be8844-152e-4d7e-a3d9-4fd5d3f40954', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db05b7a00>]}
[0m19:16:12.722141 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m19:16:12.742469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '01be8844-152e-4d7e-a3d9-4fd5d3f40954', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db05b79a0>]}
[0m19:16:12.757652 [info ] [MainThread]: 
[0m19:16:12.857927 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:16:12.887894 [info ] [MainThread]: 
[0m19:16:12.891427 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:16:13.051749 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m19:16:15.404661 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m19:16:15.443666 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m19:16:15.479659 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:16:15.956819 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.477 seconds
[0m19:16:16.110431 [debug] [ThreadPool]: On list_staging: Close
[0m19:16:16.304770 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m19:16:17.066106 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m19:16:17.084207 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m19:16:17.087662 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:16:17.304042 [debug] [ThreadPool]: SQL status: BEGIN in 0.216 seconds
[0m19:16:17.312341 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m19:16:17.314849 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m19:16:17.401011 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.062 seconds
[0m19:16:17.405848 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m19:16:17.418230 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m19:16:17.486204 [debug] [MainThread]: Using postgres connection "master"
[0m19:16:17.548463 [debug] [MainThread]: On master: BEGIN
[0m19:16:17.550776 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:16:17.617971 [debug] [MainThread]: SQL status: BEGIN in 0.067 seconds
[0m19:16:17.631987 [debug] [MainThread]: Using postgres connection "master"
[0m19:16:17.634951 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m19:16:17.711989 [debug] [MainThread]: SQL status: SELECT 1 in 0.062 seconds
[0m19:16:17.747885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '01be8844-152e-4d7e-a3d9-4fd5d3f40954', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db4a56b60>]}
[0m19:16:17.760539 [debug] [MainThread]: On master: ROLLBACK
[0m19:16:17.772029 [debug] [MainThread]: Using postgres connection "master"
[0m19:16:17.789468 [debug] [MainThread]: On master: BEGIN
[0m19:16:17.795537 [debug] [MainThread]: SQL status: BEGIN in 0.003 seconds
[0m19:16:17.800899 [debug] [MainThread]: On master: COMMIT
[0m19:16:17.807460 [debug] [MainThread]: Using postgres connection "master"
[0m19:16:17.812789 [debug] [MainThread]: On master: COMMIT
[0m19:16:17.819724 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:16:17.822611 [debug] [MainThread]: On master: Close
[0m19:16:17.905902 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m19:16:17.941290 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m19:16:17.971339 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m19:16:17.978692 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m19:16:18.181090 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m19:16:18.211623 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m19:16:19.102387 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m19:16:19.291664 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m19:16:19.320091 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m19:16:19.324653 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:16:19.449507 [debug] [Thread-1 (]: SQL status: BEGIN in 0.125 seconds
[0m19:16:19.480488 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m19:16:19.512120 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m19:16:19.668978 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.125 seconds
[0m19:16:20.013989 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m19:16:20.038879 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales" rename to "stg_sales__dbt_backup"
[0m19:16:20.083714 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:16:20.315571 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m19:16:20.332756 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m19:16:20.343242 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.006 seconds
[0m19:16:20.818064 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m19:16:20.849123 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m19:16:20.863806 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m19:16:20.885675 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m19:16:21.023714 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m19:16:21.166554 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m19:16:21.197809 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m19:16:21.262471 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.029 seconds
[0m19:16:21.377653 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m19:16:21.705755 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01be8844-152e-4d7e-a3d9-4fd5d3f40954', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db05f8d90>]}
[0m19:16:21.791197 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 3.62s]
[0m19:16:21.927803 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m19:16:21.976577 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m19:16:22.045119 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m19:16:22.093581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m19:16:22.171247 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m19:16:22.558373 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m19:16:23.021520 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m19:16:23.516450 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m19:16:23.879767 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m19:16:23.976716 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m19:16:24.026854 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:16:24.163759 [debug] [Thread-1 (]: SQL status: BEGIN in 0.132 seconds
[0m19:16:24.180109 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m19:16:24.229879 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m19:16:24.515090 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.223 seconds
[0m19:16:24.667121 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m19:16:24.710494 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary" rename to "sales_summary__dbt_backup"
[0m19:16:24.807470 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.024 seconds
[0m19:16:24.856734 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m19:16:24.922079 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m19:16:24.939887 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.015 seconds
[0m19:16:25.042230 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m19:16:25.067886 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m19:16:25.125271 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m19:16:25.202508 [debug] [Thread-1 (]: SQL status: COMMIT in 0.044 seconds
[0m19:16:25.434943 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m19:16:25.501511 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m19:16:25.625061 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m19:16:25.698655 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.026 seconds
[0m19:16:26.005719 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m19:16:26.050248 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01be8844-152e-4d7e-a3d9-4fd5d3f40954', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db05f8d90>]}
[0m19:16:26.097615 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 0[0m in 3.96s]
[0m19:16:26.163220 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m19:16:26.209387 [debug] [MainThread]: Using postgres connection "master"
[0m19:16:26.243857 [debug] [MainThread]: On master: BEGIN
[0m19:16:26.273597 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:16:26.375348 [debug] [MainThread]: SQL status: BEGIN in 0.102 seconds
[0m19:16:26.702857 [debug] [MainThread]: On master: COMMIT
[0m19:16:26.793799 [debug] [MainThread]: Using postgres connection "master"
[0m19:16:26.888683 [debug] [MainThread]: On master: COMMIT
[0m19:16:26.925056 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:16:26.995325 [debug] [MainThread]: On master: Close
[0m19:16:27.027022 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:16:27.055360 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m19:16:27.084782 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m19:16:27.129300 [info ] [MainThread]: 
[0m19:16:27.173294 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 14.24 seconds (14.24s).
[0m19:16:27.198838 [debug] [MainThread]: Command end result
[0m19:16:28.640897 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m19:16:28.714940 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m19:16:28.856175 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m19:16:28.880866 [info ] [MainThread]: 
[0m19:16:28.899284 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:16:28.933620 [info ] [MainThread]: 
[0m19:16:28.939587 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m19:16:28.964997 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 43.260647, "process_in_blocks": "84288", "process_kernel_time": 13.998144, "process_mem_max_rss": "117728", "process_out_blocks": "0", "process_user_time": 15.769199}
[0m19:16:28.967330 [debug] [MainThread]: Command `dbt run` succeeded at 19:16:28.966961 after 43.26 seconds
[0m19:16:29.084225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db2f36560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db3b0f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0db213e5c0>]}
[0m19:16:29.099087 [debug] [MainThread]: Flushing usage events
[0m19:16:29.351852 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:41:04.381597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6eda25c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6ddb0be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6ddb0b80>]}


============================== 21:41:04.521371 | 2da29601-b5f7-4e33-8d2f-b00255523a97 ==============================
[0m21:41:04.521371 [info ] [MainThread]: Running with dbt=1.10.13
[0m21:41:04.551176 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'partial_parse': 'True', 'version_check': 'True', 'use_colors': 'True', 'profiles_dir': '/dbt', 'fail_fast': 'False', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'log_path': '/dbt/logs', 'no_print': 'None', 'introspect': 'True', 'static_parser': 'True', 'write_json': 'True', 'empty': 'False', 'indirect_selection': 'eager', 'debug': 'False', 'target_path': 'None', 'printer_width': '80', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'warn_error': 'None'}
[0m21:41:09.613319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2da29601-b5f7-4e33-8d2f-b00255523a97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f7062c1f0>]}
[0m21:41:11.020290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2da29601-b5f7-4e33-8d2f-b00255523a97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6dc6b9a0>]}
[0m21:41:11.331461 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m21:41:14.271627 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m21:41:32.229909 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:41:32.436758 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:41:32.949573 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m21:41:39.619919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2da29601-b5f7-4e33-8d2f-b00255523a97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6c3b0d00>]}
[0m21:41:52.022859 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m21:41:52.400924 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m21:41:54.260383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2da29601-b5f7-4e33-8d2f-b00255523a97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6c3b3a00>]}
[0m21:41:54.279064 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m21:41:54.324265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2da29601-b5f7-4e33-8d2f-b00255523a97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6c3b3970>]}
[0m21:41:54.447600 [info ] [MainThread]: 
[0m21:41:54.455477 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:41:54.469015 [info ] [MainThread]: 
[0m21:41:54.566361 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:41:55.240724 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m21:42:03.249303 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m21:42:03.294081 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m21:42:03.438137 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:42:05.984930 [debug] [ThreadPool]: SQL status: SELECT 5 in 2.543 seconds
[0m21:42:06.135749 [debug] [ThreadPool]: On list_staging: Close
[0m21:42:06.182928 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m21:42:07.223070 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m21:42:07.399361 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m21:42:07.563966 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:42:08.542471 [debug] [ThreadPool]: SQL status: BEGIN in 0.979 seconds
[0m21:42:08.719194 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m21:42:08.916530 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m21:42:09.186456 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.186 seconds
[0m21:42:09.438962 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m21:42:09.527260 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m21:42:10.108498 [debug] [MainThread]: Using postgres connection "master"
[0m21:42:10.227075 [debug] [MainThread]: On master: BEGIN
[0m21:42:10.316930 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:42:10.598770 [debug] [MainThread]: SQL status: BEGIN in 0.282 seconds
[0m21:42:10.751541 [debug] [MainThread]: Using postgres connection "master"
[0m21:42:11.149646 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m21:42:11.336662 [debug] [MainThread]: SQL status: SELECT 1 in 0.104 seconds
[0m21:42:11.386185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2da29601-b5f7-4e33-8d2f-b00255523a97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6c379840>]}
[0m21:42:11.415352 [debug] [MainThread]: On master: ROLLBACK
[0m21:42:11.427490 [debug] [MainThread]: Using postgres connection "master"
[0m21:42:11.475611 [debug] [MainThread]: On master: BEGIN
[0m21:42:11.479975 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:42:11.533875 [debug] [MainThread]: On master: COMMIT
[0m21:42:11.562544 [debug] [MainThread]: Using postgres connection "master"
[0m21:42:11.580938 [debug] [MainThread]: On master: COMMIT
[0m21:42:11.610903 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:42:11.614176 [debug] [MainThread]: On master: Close
[0m21:42:11.885388 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m21:42:11.974524 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m21:42:12.048559 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m21:42:12.052457 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m21:42:12.540817 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m21:42:13.399417 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m21:42:16.843223 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m21:42:17.401524 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:42:17.596598 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m21:42:17.657800 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:42:18.267241 [debug] [Thread-1 (]: SQL status: BEGIN in 0.664 seconds
[0m21:42:18.308393 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:42:18.322302 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m21:42:18.723982 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.309 seconds
[0m21:42:18.877734 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:42:18.915896 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales" rename to "stg_sales__dbt_backup"
[0m21:42:18.976846 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.029 seconds
[0m21:42:19.187499 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:42:19.281550 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m21:42:19.311048 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.013 seconds
[0m21:42:20.404077 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m21:42:20.421954 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:42:20.457500 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m21:42:20.551365 [debug] [Thread-1 (]: SQL status: COMMIT in 0.041 seconds
[0m21:42:20.837230 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m21:42:21.210346 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:42:21.394287 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m21:42:21.617043 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.058 seconds
[0m21:42:21.942684 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m21:42:22.096150 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2da29601-b5f7-4e33-8d2f-b00255523a97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6c3f8d90>]}
[0m21:42:22.194998 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 10.04s]
[0m21:42:22.228952 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m21:42:22.362662 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m21:42:22.420640 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m21:42:22.446224 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m21:42:22.459363 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m21:42:22.700590 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m21:42:23.234280 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m21:42:24.582355 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m21:42:25.014748 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:42:25.099582 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m21:42:25.142025 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:42:26.022532 [debug] [Thread-1 (]: SQL status: BEGIN in 0.845 seconds
[0m21:42:26.075376 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:42:26.242054 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m21:42:26.712164 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.454 seconds
[0m21:42:27.170811 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:42:27.514722 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary" rename to "sales_summary__dbt_backup"
[0m21:42:27.818592 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m21:42:28.272327 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:42:28.387056 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m21:42:28.471794 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m21:42:28.738621 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m21:42:29.046001 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:42:29.121959 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m21:42:29.317762 [debug] [Thread-1 (]: SQL status: COMMIT in 0.102 seconds
[0m21:42:29.817737 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m21:42:30.120536 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:42:30.165731 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m21:42:31.177278 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.171 seconds
[0m21:42:31.304969 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m21:42:32.557574 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2da29601-b5f7-4e33-8d2f-b00255523a97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6c3f8b50>]}
[0m21:42:32.764050 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 0[0m in 10.11s]
[0m21:42:32.783027 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m21:42:32.941408 [debug] [MainThread]: Using postgres connection "master"
[0m21:42:33.150021 [debug] [MainThread]: On master: BEGIN
[0m21:42:33.310018 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:42:34.221533 [debug] [MainThread]: SQL status: BEGIN in 0.926 seconds
[0m21:42:34.231549 [debug] [MainThread]: On master: COMMIT
[0m21:42:34.268509 [debug] [MainThread]: Using postgres connection "master"
[0m21:42:34.322094 [debug] [MainThread]: On master: COMMIT
[0m21:42:34.350074 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:42:34.438778 [debug] [MainThread]: On master: Close
[0m21:42:34.458695 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:42:34.545980 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m21:42:34.563527 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m21:42:34.680742 [info ] [MainThread]: 
[0m21:42:34.722420 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 40.11 seconds (40.11s).
[0m21:42:34.778767 [debug] [MainThread]: Command end result
[0m21:42:40.762826 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m21:42:41.650196 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m21:42:42.994074 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m21:42:43.030043 [info ] [MainThread]: 
[0m21:42:43.146262 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:42:43.315723 [info ] [MainThread]: 
[0m21:42:43.578363 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m21:42:43.719071 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 95.82727, "process_in_blocks": "0", "process_kernel_time": 33.74801, "process_mem_max_rss": "118204", "process_out_blocks": "0", "process_user_time": 30.7433}
[0m21:42:43.890588 [debug] [MainThread]: Command `dbt run` succeeded at 21:42:43.890084 after 96.00 seconds
[0m21:42:44.031712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6eda25c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6ed23010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f6dc6b9a0>]}
[0m21:42:44.280332 [debug] [MainThread]: Flushing usage events
[0m21:42:47.268692 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:49:32.778675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1f932590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1e940be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1e940b80>]}


============================== 21:49:32.928647 | 14af5f68-7fea-43ae-a4a8-d4385d348472 ==============================
[0m21:49:32.928647 [info ] [MainThread]: Running with dbt=1.10.13
[0m21:49:33.032693 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'write_json': 'True', 'quiet': 'False', 'static_parser': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'log_cache_events': 'False', 'log_path': '/dbt/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'profiles_dir': '/dbt', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'debug': 'False', 'invocation_command': 'dbt run', 'version_check': 'True', 'log_format': 'default', 'printer_width': '80'}
[0m21:49:37.997759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '14af5f68-7fea-43ae-a4a8-d4385d348472', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1f7470d0>]}
[0m21:49:39.731949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '14af5f68-7fea-43ae-a4a8-d4385d348472', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1f0eabc0>]}
[0m21:49:39.887183 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m21:49:42.001461 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m21:49:59.160307 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:49:59.269703 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:50:00.410254 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m21:50:02.843883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '14af5f68-7fea-43ae-a4a8-d4385d348472', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1cfb4cd0>]}
[0m21:50:09.272211 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m21:50:10.127016 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m21:50:11.809417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '14af5f68-7fea-43ae-a4a8-d4385d348472', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1cfb7a30>]}
[0m21:50:11.886191 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m21:50:11.975374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '14af5f68-7fea-43ae-a4a8-d4385d348472', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1cfb79a0>]}
[0m21:50:12.112172 [info ] [MainThread]: 
[0m21:50:12.447044 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:50:12.673023 [info ] [MainThread]: 
[0m21:50:12.811902 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:50:13.056185 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m21:50:15.877190 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m21:50:15.976913 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m21:50:16.049524 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:50:16.302856 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.253 seconds
[0m21:50:16.386619 [debug] [ThreadPool]: On list_staging: Close
[0m21:50:16.524101 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bankole_store)
[0m21:50:16.702275 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m21:50:16.786403 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m21:50:16.877949 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:50:17.099577 [debug] [ThreadPool]: SQL status: BEGIN in 0.197 seconds
[0m21:50:17.188782 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m21:50:17.282408 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m21:50:17.428430 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.029 seconds
[0m21:50:17.596370 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m21:50:17.673918 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m21:50:17.889379 [debug] [MainThread]: Using postgres connection "master"
[0m21:50:17.985778 [debug] [MainThread]: On master: BEGIN
[0m21:50:18.075221 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:50:18.253955 [debug] [MainThread]: SQL status: BEGIN in 0.179 seconds
[0m21:50:18.359281 [debug] [MainThread]: Using postgres connection "master"
[0m21:50:18.585122 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m21:50:18.814708 [debug] [MainThread]: SQL status: SELECT 1 in 0.036 seconds
[0m21:50:19.060160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '14af5f68-7fea-43ae-a4a8-d4385d348472', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1cfdd9c0>]}
[0m21:50:19.327905 [debug] [MainThread]: On master: ROLLBACK
[0m21:50:19.470150 [debug] [MainThread]: Using postgres connection "master"
[0m21:50:19.678024 [debug] [MainThread]: On master: BEGIN
[0m21:50:20.130304 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:50:20.236851 [debug] [MainThread]: On master: COMMIT
[0m21:50:20.314467 [debug] [MainThread]: Using postgres connection "master"
[0m21:50:20.438877 [debug] [MainThread]: On master: COMMIT
[0m21:50:20.586413 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:50:20.847680 [debug] [MainThread]: On master: Close
[0m21:50:20.990327 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m21:50:21.227166 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m21:50:21.422896 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m21:50:21.598538 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m21:50:22.001459 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m21:50:23.254100 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m21:50:24.388819 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m21:50:25.738553 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:50:25.813109 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m21:50:25.952953 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:50:26.129516 [debug] [Thread-1 (]: SQL status: BEGIN in 0.177 seconds
[0m21:50:26.315623 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:50:26.542957 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m21:50:26.809182 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.118 seconds
[0m21:50:27.059969 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:50:27.154516 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales" rename to "stg_sales__dbt_backup"
[0m21:50:27.251016 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m21:50:27.357036 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:50:27.482997 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m21:50:27.699404 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m21:50:28.103256 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m21:50:28.205954 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:50:28.418856 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m21:50:28.767855 [debug] [Thread-1 (]: SQL status: COMMIT in 0.051 seconds
[0m21:50:28.995769 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m21:50:29.360498 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m21:50:29.519448 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m21:50:29.700638 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.058 seconds
[0m21:50:29.893435 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m21:50:30.071959 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14af5f68-7fea-43ae-a4a8-d4385d348472', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1cff8dc0>]}
[0m21:50:30.153019 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 8.63s]
[0m21:50:30.289883 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m21:50:30.353178 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m21:50:30.459776 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m21:50:30.661850 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m21:50:30.783569 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m21:50:30.978645 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m21:50:33.801061 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m21:50:34.457383 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m21:50:35.613419 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:50:35.707657 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m21:50:35.824279 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:50:36.061268 [debug] [Thread-1 (]: SQL status: BEGIN in 0.237 seconds
[0m21:50:36.151877 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:50:36.322175 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m21:51:00.382537 [debug] [Thread-1 (]: SQL status: SELECT 1716 in 23.837 seconds
[0m21:51:01.007654 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:51:01.165133 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary" rename to "sales_summary__dbt_backup"
[0m21:51:01.419241 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m21:51:01.624152 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:51:01.744893 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m21:51:01.932065 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:51:02.072644 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m21:51:02.182802 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:51:02.279369 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m21:51:02.628733 [debug] [Thread-1 (]: SQL status: COMMIT in 0.115 seconds
[0m21:51:03.064074 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m21:51:03.273706 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m21:51:03.585586 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m21:51:03.772309 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.080 seconds
[0m21:51:04.835692 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m21:51:04.939809 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14af5f68-7fea-43ae-a4a8-d4385d348472', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1cff8dc0>]}
[0m21:51:06.286945 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 1716[0m in 34.28s]
[0m21:51:06.378990 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m21:51:06.508904 [debug] [MainThread]: Using postgres connection "master"
[0m21:51:06.596198 [debug] [MainThread]: On master: BEGIN
[0m21:51:06.705723 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:51:06.814295 [debug] [MainThread]: SQL status: BEGIN in 0.109 seconds
[0m21:51:06.957776 [debug] [MainThread]: On master: COMMIT
[0m21:51:07.053642 [debug] [MainThread]: Using postgres connection "master"
[0m21:51:07.259090 [debug] [MainThread]: On master: COMMIT
[0m21:51:07.351984 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:51:07.407057 [debug] [MainThread]: On master: Close
[0m21:51:07.471391 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:51:07.524181 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m21:51:07.607990 [info ] [MainThread]: 
[0m21:51:07.679568 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 54.80 seconds (54.80s).
[0m21:51:07.731396 [debug] [MainThread]: Command end result
[0m21:51:13.254015 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m21:51:13.964672 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m21:51:14.543062 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m21:51:14.659019 [info ] [MainThread]: 
[0m21:51:14.726138 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:51:14.860664 [info ] [MainThread]: 
[0m21:51:14.939709 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m21:51:15.141867 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 101.151405, "process_in_blocks": "0", "process_kernel_time": 12.8349, "process_mem_max_rss": "118132", "process_out_blocks": "0", "process_user_time": 47.878784}
[0m21:51:15.221759 [debug] [MainThread]: Command `dbt run` succeeded at 21:51:15.221190 after 101.23 seconds
[0m21:51:15.294492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1f932590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e1cfd3e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e211bc1c0>]}
[0m21:51:15.462652 [debug] [MainThread]: Flushing usage events
[0m21:51:17.943168 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:36:54.054929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d334e800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d2397550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d23974f0>]}


============================== 22:36:54.373017 | a4d48f88-46f9-4704-ac85-2f3ddd27e915 ==============================
[0m22:36:54.373017 [info ] [MainThread]: Running with dbt=1.10.13
[0m22:36:54.420451 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'target_path': 'None', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'quiet': 'False', 'log_format': 'default', 'debug': 'False', 'use_experimental_parser': 'False', 'introspect': 'True', 'write_json': 'True', 'profiles_dir': '/dbt', 'use_colors': 'True', 'partial_parse': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'log_path': '/dbt/logs', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'empty': 'False'}
[0m22:36:57.935185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a4d48f88-46f9-4704-ac85-2f3ddd27e915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d32d47f0>]}
[0m22:36:58.565421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a4d48f88-46f9-4704-ac85-2f3ddd27e915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d2bb8790>]}
[0m22:36:58.584092 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m22:36:59.743228 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m22:37:01.860709 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:37:01.877093 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:37:01.952484 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m22:37:05.490213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a4d48f88-46f9-4704-ac85-2f3ddd27e915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d09d4f10>]}
[0m22:37:06.980385 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:37:07.124189 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:37:07.391803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a4d48f88-46f9-4704-ac85-2f3ddd27e915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d05908b0>]}
[0m22:37:07.405832 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m22:37:07.430186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a4d48f88-46f9-4704-ac85-2f3ddd27e915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d0590910>]}
[0m22:37:07.738716 [info ] [MainThread]: 
[0m22:37:07.812057 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:37:07.869934 [info ] [MainThread]: 
[0m22:37:07.933038 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:37:08.028047 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m22:37:09.177751 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m22:37:09.207052 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m22:37:09.225623 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:37:09.533686 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.308 seconds
[0m22:37:09.550199 [debug] [ThreadPool]: On list_staging: Close
[0m22:37:09.586823 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging_bankole_store'
[0m22:37:09.813556 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:37:09.856114 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m22:37:09.901374 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:37:10.131861 [debug] [ThreadPool]: SQL status: BEGIN in 0.230 seconds
[0m22:37:10.234953 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:37:10.296858 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m22:37:10.475806 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.120 seconds
[0m22:37:10.555160 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m22:37:10.702512 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m22:37:11.126459 [debug] [MainThread]: Using postgres connection "master"
[0m22:37:11.276117 [debug] [MainThread]: On master: BEGIN
[0m22:37:11.381628 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:37:11.640716 [debug] [MainThread]: SQL status: BEGIN in 0.259 seconds
[0m22:37:11.742082 [debug] [MainThread]: Using postgres connection "master"
[0m22:37:11.787807 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m22:37:11.970354 [debug] [MainThread]: SQL status: SELECT 1 in 0.153 seconds
[0m22:37:11.988563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a4d48f88-46f9-4704-ac85-2f3ddd27e915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d0ded1b0>]}
[0m22:37:12.002689 [debug] [MainThread]: On master: ROLLBACK
[0m22:37:12.005986 [debug] [MainThread]: Using postgres connection "master"
[0m22:37:12.021356 [debug] [MainThread]: On master: BEGIN
[0m22:37:12.074159 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m22:37:12.107630 [debug] [MainThread]: On master: COMMIT
[0m22:37:12.168174 [debug] [MainThread]: Using postgres connection "master"
[0m22:37:12.243561 [debug] [MainThread]: On master: COMMIT
[0m22:37:12.289618 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:37:12.304827 [debug] [MainThread]: On master: Close
[0m22:37:12.437220 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m22:37:12.445839 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m22:37:12.488147 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m22:37:12.547739 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m22:37:12.894036 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m22:37:13.265256 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m22:37:13.926581 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m22:37:14.330153 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:37:14.417011 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m22:37:14.493144 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:37:14.733901 [debug] [Thread-1 (]: SQL status: BEGIN in 0.241 seconds
[0m22:37:15.034178 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:37:15.179261 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m22:37:15.550110 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.296 seconds
[0m22:37:15.760901 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:37:15.833873 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales" rename to "stg_sales__dbt_backup"
[0m22:37:15.944507 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.033 seconds
[0m22:37:16.169883 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:37:16.302163 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m22:37:16.447509 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.038 seconds
[0m22:37:16.987495 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m22:37:17.091282 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:37:17.195581 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m22:37:17.346072 [debug] [Thread-1 (]: SQL status: COMMIT in 0.045 seconds
[0m22:37:17.690749 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m22:37:18.014506 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:37:18.132939 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m22:37:18.337244 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.061 seconds
[0m22:37:18.628384 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m22:37:18.933237 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4d48f88-46f9-4704-ac85-2f3ddd27e915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d09be0b0>]}
[0m22:37:19.039372 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 6.31s]
[0m22:37:19.173368 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m22:37:19.284301 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m22:37:19.433467 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m22:37:19.550125 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m22:37:19.622562 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m22:37:19.805048 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m22:37:20.629918 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m22:37:21.516624 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m22:37:22.506356 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:37:22.610422 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m22:37:22.742755 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:37:22.982973 [debug] [Thread-1 (]: SQL status: BEGIN in 0.240 seconds
[0m22:37:23.132715 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:37:23.236468 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m22:37:41.920427 [debug] [Thread-1 (]: SQL status: SELECT 1716 in 16.675 seconds
[0m22:37:42.085202 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:37:42.099357 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary" rename to "sales_summary__dbt_backup"
[0m22:37:42.131279 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:37:42.184415 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:37:42.194494 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m22:37:42.219965 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:37:42.286839 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m22:37:42.318079 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:37:42.347934 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m22:37:42.382039 [debug] [Thread-1 (]: SQL status: COMMIT in 0.020 seconds
[0m22:37:42.434124 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m22:37:42.466018 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:37:42.472486 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m22:37:42.524829 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.048 seconds
[0m22:37:42.544529 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m22:37:42.563311 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4d48f88-46f9-4704-ac85-2f3ddd27e915', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d22640a0>]}
[0m22:37:42.595582 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 1716[0m in 23.01s]
[0m22:37:42.633592 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m22:37:42.805492 [debug] [MainThread]: Using postgres connection "master"
[0m22:37:43.100950 [debug] [MainThread]: On master: BEGIN
[0m22:37:43.341064 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:37:43.588474 [debug] [MainThread]: SQL status: BEGIN in 0.247 seconds
[0m22:37:43.718278 [debug] [MainThread]: On master: COMMIT
[0m22:37:43.837857 [debug] [MainThread]: Using postgres connection "master"
[0m22:37:43.958583 [debug] [MainThread]: On master: COMMIT
[0m22:37:44.022951 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:37:44.108076 [debug] [MainThread]: On master: Close
[0m22:37:44.168385 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:37:44.212883 [debug] [MainThread]: Connection 'list_staging' was properly closed.
[0m22:37:44.272544 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m22:37:44.317937 [info ] [MainThread]: 
[0m22:37:44.392699 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 36.39 seconds (36.39s).
[0m22:37:44.470075 [debug] [MainThread]: Command end result
[0m22:37:46.013851 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:37:46.358763 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:37:46.551299 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m22:37:46.562115 [info ] [MainThread]: 
[0m22:37:46.567418 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:37:46.636638 [info ] [MainThread]: 
[0m22:37:46.738905 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m22:37:46.823400 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 50.95486, "process_in_blocks": "1648", "process_kernel_time": 7.039479, "process_mem_max_rss": "118828", "process_out_blocks": "1504", "process_user_time": 22.428354}
[0m22:37:46.873048 [debug] [MainThread]: Command `dbt run` succeeded at 22:37:46.871904 after 51.01 seconds
[0m22:37:46.952778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d334e800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d40c4520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53d2be9e40>]}
[0m22:37:47.092748 [debug] [MainThread]: Flushing usage events
[0m22:37:52.125194 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:46:02.524252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819e9f2860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819da1f640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819da1f5e0>]}


============================== 22:46:02.686801 | 1fed3423-b320-404f-88da-e4859b6ee3d6 ==============================
[0m22:46:02.686801 [info ] [MainThread]: Running with dbt=1.10.13
[0m22:46:02.702885 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'introspect': 'True', 'log_format': 'default', 'log_cache_events': 'False', 'fail_fast': 'False', 'target_path': 'None', 'static_parser': 'True', 'quiet': 'False', 'indirect_selection': 'eager', 'warn_error': 'None', 'cache_selected_only': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'use_colors': 'True', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'log_path': '/dbt/logs', 'write_json': 'True', 'empty': 'False', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run', 'profiles_dir': '/dbt'}
[0m22:46:10.422114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1fed3423-b320-404f-88da-e4859b6ee3d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819da1f5e0>]}
[0m22:46:11.299043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1fed3423-b320-404f-88da-e4859b6ee3d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819e0ea380>]}
[0m22:46:11.304909 [info ] [MainThread]: Registered adapter: postgres=1.9.1
[0m22:46:12.580015 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m22:46:15.805412 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:46:15.895971 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:46:16.174360 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_transform.example
[0m22:46:18.461099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1fed3423-b320-404f-88da-e4859b6ee3d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819c3bcf70>]}
[0m22:46:24.005285 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:46:24.294640 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:46:24.787950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1fed3423-b320-404f-88da-e4859b6ee3d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819bf74820>]}
[0m22:46:24.832571 [info ] [MainThread]: Found 2 models, 4 data tests, 1 source, 447 macros
[0m22:46:24.848250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1fed3423-b320-404f-88da-e4859b6ee3d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819bf74880>]}
[0m22:46:25.379583 [info ] [MainThread]: 
[0m22:46:25.436849 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:46:25.496680 [info ] [MainThread]: 
[0m22:46:25.618589 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:46:26.251122 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m22:46:28.209631 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m22:46:28.216274 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m22:46:28.246734 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:46:28.510233 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.263 seconds
[0m22:46:28.598077 [debug] [ThreadPool]: On list_staging: Close
[0m22:46:28.693641 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now create_staging_bankole_store)
[0m22:46:28.823400 [debug] [ThreadPool]: Creating schema "database: "staging"
schema: "bankole_store"
"
[0m22:46:29.047290 [debug] [ThreadPool]: Using postgres connection "create_staging_bankole_store"
[0m22:46:29.129029 [debug] [ThreadPool]: On create_staging_bankole_store: BEGIN
[0m22:46:29.232228 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:46:29.712391 [debug] [ThreadPool]: SQL status: BEGIN in 0.481 seconds
[0m22:46:29.820901 [debug] [ThreadPool]: Using postgres connection "create_staging_bankole_store"
[0m22:46:30.126590 [debug] [ThreadPool]: On create_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "create_staging_bankole_store"} */
create schema if not exists "bankole_store"
[0m22:46:30.244064 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.002 seconds
[0m22:46:30.504371 [debug] [ThreadPool]: On create_staging_bankole_store: COMMIT
[0m22:46:30.790450 [debug] [ThreadPool]: Using postgres connection "create_staging_bankole_store"
[0m22:46:30.879751 [debug] [ThreadPool]: On create_staging_bankole_store: COMMIT
[0m22:46:31.194249 [debug] [ThreadPool]: SQL status: COMMIT in 0.125 seconds
[0m22:46:31.461609 [debug] [ThreadPool]: On create_staging_bankole_store: Close
[0m22:46:31.745784 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_staging_bankole_store, now list_staging_bankole_store)
[0m22:46:32.298695 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:46:32.462564 [debug] [ThreadPool]: On list_staging_bankole_store: BEGIN
[0m22:46:32.571777 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:46:33.030057 [debug] [ThreadPool]: SQL status: BEGIN in 0.458 seconds
[0m22:46:33.176041 [debug] [ThreadPool]: Using postgres connection "list_staging_bankole_store"
[0m22:46:33.289894 [debug] [ThreadPool]: On list_staging_bankole_store: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "list_staging_bankole_store"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bankole_store'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bankole_store'
  
[0m22:46:33.480133 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.101 seconds
[0m22:46:33.753736 [debug] [ThreadPool]: On list_staging_bankole_store: ROLLBACK
[0m22:46:33.872725 [debug] [ThreadPool]: On list_staging_bankole_store: Close
[0m22:46:34.218796 [debug] [MainThread]: Using postgres connection "master"
[0m22:46:34.412238 [debug] [MainThread]: On master: BEGIN
[0m22:46:34.499794 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:46:34.682424 [debug] [MainThread]: SQL status: BEGIN in 0.183 seconds
[0m22:46:34.770023 [debug] [MainThread]: Using postgres connection "master"
[0m22:46:34.845463 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m22:46:35.088623 [debug] [MainThread]: SQL status: SELECT 0 in 0.184 seconds
[0m22:46:35.164053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1fed3423-b320-404f-88da-e4859b6ee3d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819e139180>]}
[0m22:46:35.282721 [debug] [MainThread]: On master: ROLLBACK
[0m22:46:35.402305 [debug] [MainThread]: Using postgres connection "master"
[0m22:46:35.509933 [debug] [MainThread]: On master: BEGIN
[0m22:46:35.687928 [debug] [MainThread]: SQL status: BEGIN in 0.058 seconds
[0m22:46:35.806528 [debug] [MainThread]: On master: COMMIT
[0m22:46:35.869890 [debug] [MainThread]: Using postgres connection "master"
[0m22:46:35.990050 [debug] [MainThread]: On master: COMMIT
[0m22:46:36.064719 [debug] [MainThread]: SQL status: COMMIT in 0.019 seconds
[0m22:46:36.139483 [debug] [MainThread]: On master: Close
[0m22:46:36.320132 [debug] [Thread-1 (]: Began running node model.dbt_transform.stg_sales
[0m22:46:36.437876 [info ] [Thread-1 (]: 1 of 2 START sql view model bankole_store.stg_sales ............................ [RUN]
[0m22:46:36.545018 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bankole_store, now model.dbt_transform.stg_sales)
[0m22:46:36.635143 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.stg_sales
[0m22:46:37.232804 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.stg_sales"
[0m22:46:38.639268 [debug] [Thread-1 (]: Began executing node model.dbt_transform.stg_sales
[0m22:46:42.403911 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.stg_sales"
[0m22:46:43.494114 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:46:43.553824 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: BEGIN
[0m22:46:43.628972 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:46:43.841079 [debug] [Thread-1 (]: SQL status: BEGIN in 0.170 seconds
[0m22:46:43.901934 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:46:43.918540 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */

  create view "staging"."bankole_store"."stg_sales__dbt_tmp"
    
    
  as (
    


with source as (
    select * from "staging"."public"."bankole_store"
),

staged as 
(
select
"InvoiceNo" as invoice_no,
trim("StockCode") as stock_code,
upper("Description") as description,
cast("Quantity" as int) as quantity,
cast(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI') AS date) as invoice_date,
to_char(to_timestamp("InvoiceDate", 'MM/DD/YYYY HH24:MI'), 'HH24:MI') as invoice_time,
"UnitPrice" as unit_price,
"CustomerID" AS customer_id,
Upper("Country") as Country
from source
)

select * from staged
  );
[0m22:46:43.980077 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.047 seconds
[0m22:46:44.294811 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:46:44.339379 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
alter table "staging"."bankole_store"."stg_sales__dbt_tmp" rename to "stg_sales"
[0m22:46:44.387239 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:46:45.518177 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m22:46:45.585322 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:46:45.593433 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: COMMIT
[0m22:46:45.632763 [debug] [Thread-1 (]: SQL status: COMMIT in 0.029 seconds
[0m22:46:45.896324 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."stg_sales__dbt_backup"
[0m22:46:46.167023 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.stg_sales"
[0m22:46:46.201053 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.stg_sales"} */
drop view if exists "staging"."bankole_store"."stg_sales__dbt_backup" cascade
[0m22:46:46.264495 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.004 seconds
[0m22:46:46.365353 [debug] [Thread-1 (]: On model.dbt_transform.stg_sales: Close
[0m22:46:46.461139 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fed3423-b320-404f-88da-e4859b6ee3d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819c3c3b20>]}
[0m22:46:46.527357 [info ] [Thread-1 (]: 1 of 2 OK created sql view model bankole_store.stg_sales ....................... [[32mCREATE VIEW[0m in 9.86s]
[0m22:46:46.618726 [debug] [Thread-1 (]: Finished running node model.dbt_transform.stg_sales
[0m22:46:46.753539 [debug] [Thread-1 (]: Began running node model.dbt_transform.sales_summary
[0m22:46:46.800311 [info ] [Thread-1 (]: 2 of 2 START sql table model bankole_store.sales_summary ....................... [RUN]
[0m22:46:46.819360 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_transform.stg_sales, now model.dbt_transform.sales_summary)
[0m22:46:46.836459 [debug] [Thread-1 (]: Began compiling node model.dbt_transform.sales_summary
[0m22:46:47.012941 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_transform.sales_summary"
[0m22:46:47.615874 [debug] [Thread-1 (]: Began executing node model.dbt_transform.sales_summary
[0m22:46:48.579404 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_transform.sales_summary"
[0m22:46:49.160759 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:46:49.220411 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: BEGIN
[0m22:46:49.265918 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:46:49.498545 [debug] [Thread-1 (]: SQL status: BEGIN in 0.233 seconds
[0m22:46:49.541038 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:46:49.631364 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */

  
    

  create  table "staging"."bankole_store"."sales_summary__dbt_tmp"
  
  
    as
  
  (
    

with source as (
    select * from "staging"."bankole_store"."stg_sales"
),


transformed as (
select 
country,
invoice_date,
round(cast(sum(quantity * unit_price) as numeric), 2) as total_sales,
count(distinct invoice_no) as num_invoices,
count(distinct customer_id) as num_customers
from source
group by country, invoice_date
)

select * from transformed
  );
  
[0m22:47:30.636059 [debug] [Thread-1 (]: SQL status: SELECT 1716 in 38.865 seconds
[0m22:47:30.844987 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:47:30.853766 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
alter table "staging"."bankole_store"."sales_summary__dbt_tmp" rename to "sales_summary"
[0m22:47:30.907583 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:47:30.949031 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m22:47:30.964259 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:47:31.007012 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: COMMIT
[0m22:47:31.051303 [debug] [Thread-1 (]: SQL status: COMMIT in 0.022 seconds
[0m22:47:31.102988 [debug] [Thread-1 (]: Applying DROP to: "staging"."bankole_store"."sales_summary__dbt_backup"
[0m22:47:31.149689 [debug] [Thread-1 (]: Using postgres connection "model.dbt_transform.sales_summary"
[0m22:47:31.177111 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "dbt_transform", "target_name": "dev", "node_id": "model.dbt_transform.sales_summary"} */
drop table if exists "staging"."bankole_store"."sales_summary__dbt_backup" cascade
[0m22:47:31.207664 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.011 seconds
[0m22:47:31.227390 [debug] [Thread-1 (]: On model.dbt_transform.sales_summary: Close
[0m22:47:31.245812 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fed3423-b320-404f-88da-e4859b6ee3d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819ab76e90>]}
[0m22:47:31.291460 [info ] [Thread-1 (]: 2 of 2 OK created sql table model bankole_store.sales_summary .................. [[32mSELECT 1716[0m in 44.43s]
[0m22:47:31.333203 [debug] [Thread-1 (]: Finished running node model.dbt_transform.sales_summary
[0m22:47:31.398410 [debug] [MainThread]: Using postgres connection "master"
[0m22:47:31.452683 [debug] [MainThread]: On master: BEGIN
[0m22:47:31.474924 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:47:31.548446 [debug] [MainThread]: SQL status: BEGIN in 0.073 seconds
[0m22:47:31.591847 [debug] [MainThread]: On master: COMMIT
[0m22:47:31.627546 [debug] [MainThread]: Using postgres connection "master"
[0m22:47:31.632758 [debug] [MainThread]: On master: COMMIT
[0m22:47:31.658548 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:47:31.661514 [debug] [MainThread]: On master: Close
[0m22:47:31.675315 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:47:31.708804 [debug] [MainThread]: Connection 'model.dbt_transform.sales_summary' was properly closed.
[0m22:47:31.758287 [info ] [MainThread]: 
[0m22:47:31.774653 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 1 minutes and 6.14 seconds (66.14s).
[0m22:47:31.817551 [debug] [MainThread]: Command end result
[0m22:47:33.918469 [debug] [MainThread]: Wrote artifact WritableManifest to /dbt/target/manifest.json
[0m22:47:34.236732 [debug] [MainThread]: Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[0m22:47:34.579463 [debug] [MainThread]: Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[0m22:47:34.623873 [info ] [MainThread]: 
[0m22:47:34.671029 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:47:34.790345 [info ] [MainThread]: 
[0m22:47:34.952942 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m22:47:35.108895 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 88.44437, "process_in_blocks": "0", "process_kernel_time": 13.777001, "process_mem_max_rss": "120216", "process_out_blocks": "1504", "process_user_time": 33.976986}
[0m22:47:35.154254 [debug] [MainThread]: Command `dbt run` succeeded at 22:47:35.153367 after 88.50 seconds
[0m22:47:35.228415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819e9f2860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819ed315d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f819da1ec20>]}
[0m22:47:35.291017 [debug] [MainThread]: Flushing usage events
[0m22:47:39.472716 [debug] [MainThread]: An error was encountered while trying to flush usage events
